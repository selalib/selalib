
!!------------------------------------------------------------------------------
!! <auto-generated>
!!     This code was generated by a tool.
!!     Changes to this file may cause incorrect behavior and will be lost if
!!     the code is regenerated.
!! </auto-generated>
!!------------------------------------------------------------------------------




!> @ingroup remap
!> @brief
!> Module for remapping
module sll_m_remapper
!+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++













    ! Note the semicolon when the SLL_ASSERT() macro gets expanded. We need
    ! that this be a part of the macro since we also want to be able to
    ! use this macro call within other macros. If the expansion yields 
    ! nothing (second case) then we don't want dangling semicolons...









use sll_m_assert







 
use sll_m_memory, only : sll_s_test_error_code

































 


















  




use sll_m_working_precision











































  use iso_fortran_env, only: &
    output_unit

  use sll_m_collective, only: &
    sll_f_collectives_are_same, &
    sll_o_collective_allgather, &
    sll_o_collective_allreduce, &
    sll_o_collective_alltoall, &
    sll_o_collective_alltoallv, &
    sll_t_collective_t, &
    sll_f_get_collective_rank, &
    sll_f_get_collective_size, &
    sll_f_new_collective

  use sll_m_utilities, only: &
    sll_s_int2string, &
    sll_f_is_even, &
    sll_f_is_power_of_two

  use sll_mpi, only: &
    mpi_land

  implicit none

  public :: &
    sll_o_apply_remap_2d, &
    sll_o_apply_remap_3d, &
    sll_o_apply_remap_4d, &
    sll_o_apply_remap_5d, &
    sll_o_apply_remap_6d, &
    sll_o_compute_local_sizes, &
    sll_s_factorize_in_three_powers_of_two, &
    sll_s_factorize_in_two_powers_of_two, &
    sll_o_get_layout_collective, &
    sll_o_get_layout_global_size_j, &
    sll_o_get_layout_global_size_k, &
    sll_o_get_layout_global_size_l, &
    sll_o_get_layout_i_max, &
    sll_o_get_layout_i_min, &
    sll_o_get_layout_j_max, &
    sll_o_get_layout_j_min, &
    sll_o_get_layout_k_max, &
    sll_o_get_layout_k_min, &
    sll_o_get_layout_l_max, &
    sll_o_get_layout_l_min, &
    sll_o_get_layout_m_max, &
    sll_o_get_layout_m_min, &
    sll_o_get_layout_n_max, &
    sll_o_get_layout_n_min, &
    sll_o_get_layout_local_sizes, &
    sll_o_get_layout_min_indices, &
    sll_o_get_layout_max_indices, &
    sll_o_global_to_local, &
    sll_o_initialize_layout_with_distributed_array, &
    sll_t_layout_2d, &
    sll_t_layout_2d_ptr, &
    sll_t_layout_3d, &
    sll_t_layout_4d, &
    sll_t_layout_4d_ptr, &
    sll_t_layout_5d, &
    sll_t_layout_6d, &
    sll_o_local_to_global, &
    sll_f_new_layout_2d, &
    sll_f_new_layout_2d_from_layout_4d, &
    sll_f_new_layout_3d, &
    sll_f_new_layout_3d_from_layout_4d, &
    sll_f_new_layout_4d, &
    sll_f_new_layout_5d, &
    sll_f_new_layout_6d, &
    sll_o_new_remap_plan, &
    sll_t_remap_plan_2d_comp64, &
    sll_t_remap_plan_2d_real64, &
    sll_t_remap_plan_2d_real64_ptr, &
    sll_t_remap_plan_3d_comp64, &
    sll_t_remap_plan_3d_real64, &
    sll_t_remap_plan_4d_real64, &
    sll_t_remap_plan_4d_real64_ptr, &
    sll_t_remap_plan_5d_real64, &
    sll_t_remap_plan_6d_real64, &
    sll_o_set_layout_i_max, &
    sll_o_set_layout_i_min, &
    sll_o_set_layout_j_max, &
    sll_o_set_layout_j_min, &
    sll_o_set_layout_k_max, &
    sll_o_set_layout_k_min, &
    sll_o_set_layout_l_max, &
    sll_o_set_layout_l_min, &
    sll_o_set_layout_m_max, &
    sll_o_set_layout_m_min, &
    sll_o_set_layout_n_max, &
    sll_o_set_layout_n_min, &
    sll_o_delete, &
    sll_o_get_num_nodes, &
    sll_o_view_lims

  private
!+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
  
  !> @brief Index limits contained        
  !> in a given processor.
  type :: box_2D
     integer(kind=i32), private :: i_min, i_max
     integer(kind=i32), private :: j_min, j_max
  end type box_2D

  !> @brief Index limits contained        
  !> in a given processor.
  type :: box_3D
     integer(kind=i32), private :: i_min, i_max
     integer(kind=i32), private :: j_min, j_max
     integer(kind=i32), private :: k_min, k_max
  end type box_3D

  !> @brief Index limits contained        
  !> in a given processor.
  type :: box_4D
     integer(kind=i32), private :: i_min, i_max
     integer(kind=i32), private :: j_min, j_max
     integer(kind=i32), private :: k_min, k_max
     integer(kind=i32), private :: l_min, l_max
  end type box_4D

  !> @brief Index limits contained        
  !> in a given processor.
  type :: box_5D
     integer(kind=i32), private :: i_min, i_max
     integer(kind=i32), private :: j_min, j_max
     integer(kind=i32), private :: k_min, k_max
     integer(kind=i32), private :: l_min, l_max
     integer(kind=i32), private :: m_min, m_max
  end type box_5D

  !> @brief Index limits contained        
  !> in a given processor.
  type :: box_6D
     integer(kind=i32), private :: i_min, i_max
     integer(kind=i32), private :: j_min, j_max
     integer(kind=i32), private :: k_min, k_max
     integer(kind=i32), private :: l_min, l_max
     integer(kind=i32), private :: m_min, m_max
     integer(kind=i32), private :: n_min, n_max
  end type box_6D


  
  !> @brief Information on a collective and an
  !> array of boxes 
  !> @details that describes the distribution of data among
  !> different nodes. We are also adding some auxiliary fields, like the
  !> global dimensions of a given dataset distributed as per the information
  !> in the layout.
  type :: sll_t_layout_2d
     type(sll_t_collective_t), pointer, private     :: collective
     integer(kind=i32), private                           :: global_sz1 !< size
     integer(kind=i32), private                           :: global_sz2 !< size
     type(box_2D), dimension(:), pointer, private :: boxes
  end type sll_t_layout_2d

  !> @brief Information on a collective and an
  !> array of boxes 
  !> @details that describes the distribution of data among
  !> different nodes. We are also adding some auxiliary fields, like the
  !> global dimensions of a given dataset distributed as per the information
  !> in the layout.
  type :: sll_t_layout_3d
     type(sll_t_collective_t), pointer, private     :: collective
     integer(kind=i32), private                           :: global_sz1 !< size
     integer(kind=i32), private                           :: global_sz2 !< size
     integer(kind=i32), private                           :: global_sz3 !< size
     type(box_3D), dimension(:), pointer, private :: boxes
  end type sll_t_layout_3d

  !> @brief Information on a collective and an
  !> array of boxes 
  !> @details that describes the distribution of data among
  !> different nodes. We are also adding some auxiliary fields, like the
  !> global dimensions of a given dataset distributed as per the information
  !> in the layout.
  type :: sll_t_layout_4d
     type(sll_t_collective_t), pointer , private    :: collective
     integer(kind=i32), private                           :: global_sz1 !< size
     integer(kind=i32), private                           :: global_sz2 !< size
     integer(kind=i32), private                           :: global_sz3 !< size
     integer(kind=i32), private                           :: global_sz4 !< size
     type(box_4D), dimension(:), pointer, private :: boxes
  end type sll_t_layout_4d

  !> @brief Information on a collective and an
  !> array of boxes 
  !> @details that describes the distribution of data among
  !> different nodes. We are also adding some auxiliary fields, like the
  !> global dimensions of a given dataset distributed as per the information
  !> in the layout.
  type :: sll_t_layout_5d
     type(sll_t_collective_t), pointer , private    :: collective
     integer(kind=i32), private                           :: global_sz1 !< size
     integer(kind=i32), private                           :: global_sz2 !< size
     integer(kind=i32), private                           :: global_sz3 !< size
     integer(kind=i32), private                           :: global_sz4 !< size
     integer(kind=i32), private                           :: global_sz5 !< size
     type(box_5D), dimension(:), pointer, private:: boxes
  end type sll_t_layout_5d

  !> @brief Information on a collective and an
  !> array of boxes 
  !> @details that describes the distribution of data among
  !> different nodes. We are also adding some auxiliary fields, like the
  !> global dimensions of a given dataset distributed as per the information
  !> in the layout.
  type :: sll_t_layout_6d
     type(sll_t_collective_t), pointer , private    :: collective
     integer(kind=i32), private                           :: global_sz1 !< size
     integer(kind=i32), private                           :: global_sz2 !< size
     integer(kind=i32), private                           :: global_sz3 !< size
     integer(kind=i32), private                           :: global_sz4 !< size
     integer(kind=i32), private                           :: global_sz5 !< size
     integer(kind=i32), private                           :: global_sz6 !< size
     type(box_6D), dimension(:), pointer, private :: boxes
  end type sll_t_layout_6d






type ::  sll_t_layout_2d_ptr
 type( sll_t_layout_2d ), pointer :: l
 end type  sll_t_layout_2d_ptr
type ::  layout_3d_ptr
 type( sll_t_layout_3d ), pointer :: l
 end type  layout_3d_ptr
type ::  sll_t_layout_4d_ptr
 type( sll_t_layout_4d ), pointer :: l
 end type  sll_t_layout_4d_ptr
type ::  layout_5d_ptr
 type( sll_t_layout_5d ), pointer :: l
 end type  layout_5d_ptr
type ::  layout_6d_ptr
 type( sll_t_layout_6d ), pointer :: l
 end type  layout_6d_ptr






type ::  sll_t_remap_plan_2d_real64_ptr
 type( sll_t_remap_plan_2d_real64 ), pointer :: r
 end type  sll_t_remap_plan_2d_real64_ptr
type ::  sll_t_remap_plan_4d_real64_ptr
 type( sll_t_remap_plan_4d_real64 ), pointer :: r
 end type  sll_t_remap_plan_4d_real64_ptr 

  ! Since the plan stores the information on box intersections, now
  ! we need a different type of plan for every dimension. It is also
  ! wasteful to allocate a full array of size(collective_size) to store
  ! the intersection information. Eventually this has to be made leaner
  ! by storing only pointers to boxes and possibly a linked list.
  !
  ! Coalesce with a macro. Note that regardless of the dimensionality of the
  ! data, the arrays are always linear. This implies manual packing/unpacking.
  !
  ! The 'is_uniform' slot is a logical flag that indicates whether the same
  ! amount of data is going to be sent to all the processes in a 
  ! communicator (sender included). This is important to know because we can
  ! then replace the call to alltoallv by a call to alltoall.




  ! 2D Remap types:

  !> @brief basic type for 2D remap for the 32-bit integer type.
  type :: remap_plan_2D_int32
 type( sll_t_layout_2d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_2d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_2D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_2D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  integer(kind=i32), dimension(:), pointer, private :: send_buffer=>null()
  integer(kind=i32), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_2D_int32
  !> @brief basic type for 2D remap for the 64-bit real type.
  type :: sll_t_remap_plan_2d_real64
 type( sll_t_layout_2d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_2d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_2D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_2D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  real(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  real(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_2d_real64
  !> @brief basic type for 2D remap for the 64-bit complex type.
  type :: sll_t_remap_plan_2d_comp64
 type( sll_t_layout_2d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_2d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_2D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_2D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  complex(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  complex(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_2d_comp64

  ! 3D Remap types:

  !> @brief basic type for 3D remap for the 32-bit integer type.
  type :: remap_plan_3D_int32
 type( sll_t_layout_3d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_3d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_3D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_3D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  integer(kind=i32), dimension(:), pointer, private :: send_buffer=>null()
  integer(kind=i32), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_3D_int32
  !> @brief basic type for 3D remap for the 64-bit real type.
  type :: sll_t_remap_plan_3d_real64
 type( sll_t_layout_3d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_3d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_3D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_3D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  real(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  real(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_3d_real64
  !> @brief basic type for 3D remap for the 64-bit complex type.
  type :: sll_t_remap_plan_3d_comp64
 type( sll_t_layout_3d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_3d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_3D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_3D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  complex(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  complex(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_3d_comp64

  ! 4D Remap types:

  !> @brief basic type for 4D remap for the 32-bit integer type.
  type :: remap_plan_4D_int32
 type( sll_t_layout_4d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_4d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_4D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_4D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  integer(kind=i32), dimension(:), pointer, private :: send_buffer=>null()
  integer(kind=i32), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_4D_int32
  type :: sll_t_remap_plan_4d_real64
 type( sll_t_layout_4d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_4d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_4D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_4D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  real(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  real(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_4d_real64
  type :: remap_plan_4D_comp64
 type( sll_t_layout_4d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_4d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_4D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_4D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  complex(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  complex(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_4D_comp64

  ! 5D Remap types:

  !> @brief basic type for 5D remap for the 32-bit integer type.
  type :: remap_plan_5D_int32
 type( sll_t_layout_5d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_5d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_5D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_5D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  integer(kind=i32), dimension(:), pointer, private :: send_buffer=>null()
  integer(kind=i32), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_5D_int32
  type :: sll_t_remap_plan_5d_real64
 type( sll_t_layout_5d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_5d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_5D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_5D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  real(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  real(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_5d_real64
  type :: remap_plan_5D_comp64
 type( sll_t_layout_5d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_5d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_5D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_5D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  complex(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  complex(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_5D_comp64

  ! 6D Remap types:

  type :: remap_plan_6D_int32
 type( sll_t_layout_6d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_6d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_6D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_6D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  integer(kind=i32), dimension(:), pointer, private :: send_buffer=>null()
  integer(kind=i32), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_6D_int32
  type :: sll_t_remap_plan_6d_real64
 type( sll_t_layout_6d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_6d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_6D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_6D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  real(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  real(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type sll_t_remap_plan_6d_real64
  type :: remap_plan_6D_comp64
 type( sll_t_layout_6d), pointer, private :: initial_layout=>null()
 type( sll_t_layout_6d), pointer, private :: final_layout=>null()
 integer, dimension(:), pointer, private :: send_displs=>null()
 integer, dimension(:), pointer, private :: send_counts=>null()
 integer, dimension(:), pointer, private :: recv_displs=>null()
 integer, dimension(:), pointer, private :: recv_counts=>null()
 type( box_6D), dimension(:), pointer, private :: send_boxes=>null()
 type( box_6D), dimension(:), pointer, private :: recv_boxes=>null()
 type(sll_t_collective_t), pointer, private :: collective=>null()
  complex(kind=f64), dimension(:), pointer, private :: send_buffer=>null()
  complex(kind=f64), dimension(:), pointer, private :: recv_buffer=>null()
 logical, private :: is_uniform=.false.
 end type remap_plan_6D_comp64

  !> Get corner indices
  interface sll_o_get_layout_min_indices
     module procedure get_layout_min_indices_6d
  end interface sll_o_get_layout_min_indices

  !> Get corner indices
  interface sll_o_get_layout_max_indices
     module procedure get_layout_max_indices_6d
  end interface sll_o_get_layout_max_indices

  !> Get local sizes
  interface sll_o_get_layout_local_sizes
     module procedure get_layout_local_sizes_6d
  end interface sll_o_get_layout_local_sizes

  !> Get corner index
  interface sll_o_get_layout_i_min
     module procedure get_layout_2D_i_min, get_layout_3D_i_min, &
          get_layout_4D_i_min, get_layout_5D_i_min, get_layout_6D_i_min
  end interface

  !> Set layout index
  interface sll_o_set_layout_i_min
     module procedure set_layout_2D_i_min, set_layout_3D_i_min, &
          set_layout_4D_i_min, set_layout_5D_i_min, set_layout_6D_i_min
  end interface

  !> Get corner index
  interface sll_o_get_layout_i_max
     module procedure get_layout_2D_i_max, get_layout_3D_i_max, &
          get_layout_4D_i_max, get_layout_5D_i_max, get_layout_6D_i_max
  end interface

  !> Set layout index
  interface sll_o_set_layout_i_max
     module procedure set_layout_2D_i_max, set_layout_3D_i_max, &
          set_layout_4D_i_max, set_layout_5D_i_max, set_layout_6D_i_max
  end interface

  !> Get corner index
  interface sll_o_get_layout_j_min
     module procedure get_layout_2D_j_min, get_layout_3D_j_min, &
          get_layout_4D_j_min, get_layout_5D_j_min, get_layout_6D_j_min
  end interface

  !> Set layout index
  interface sll_o_set_layout_j_min
     module procedure set_layout_2D_j_min, set_layout_3D_j_min, &
          set_layout_4D_j_min, set_layout_5D_j_min, set_layout_6D_j_min  
  end interface

  !> Get corner index
  interface sll_o_get_layout_j_max
     module procedure get_layout_2D_j_max, get_layout_3D_j_max, &
          get_layout_4D_j_max, get_layout_5D_j_max, get_layout_6D_j_max
  end interface

  !> Set layout index
  interface sll_o_set_layout_j_max
     module procedure set_layout_2D_j_max, set_layout_3D_j_max, &
          set_layout_4D_j_max, set_layout_5D_j_max, set_layout_6D_j_max
  end interface

  !> Get corner index
  interface sll_o_get_layout_k_min
    module procedure get_layout_3D_k_min, get_layout_4D_k_min, &
         get_layout_5D_k_min, get_layout_6D_k_min
  end interface

  !> Set layout index
  interface sll_o_set_layout_k_min
     module procedure set_layout_3D_k_min, set_layout_4D_k_min, &
          set_layout_5D_k_min, set_layout_6D_k_min
  end interface

  !> Get corner index
  interface sll_o_get_layout_k_max
     module procedure get_layout_3D_k_max, get_layout_4D_k_max, &
          get_layout_5D_k_max, get_layout_6D_k_max
  end interface

  !> Set layout index
  interface sll_o_set_layout_k_max
     module procedure set_layout_3D_k_max, set_layout_4D_k_max, &
          set_layout_5D_k_max, set_layout_6D_k_max
  end interface

  !> Get corner index
  interface sll_o_get_layout_l_min
     module procedure get_layout_4D_l_min, get_layout_5D_l_min, &
          get_layout_6D_l_min
  end interface sll_o_get_layout_l_min

  !> Set layout index
  interface sll_o_set_layout_l_min
     module procedure set_layout_4D_l_min, set_layout_5D_l_min, &
          set_layout_6D_l_min
  end interface sll_o_set_layout_l_min

  !> Get corner index
  interface sll_o_get_layout_l_max
     module procedure get_layout_4D_l_max, get_layout_5D_l_max, &
          get_layout_6D_l_max 
  end interface sll_o_get_layout_l_max

  !> Set layout index
  interface sll_o_set_layout_l_max
     module procedure set_layout_4D_l_max, set_layout_5D_l_max, &
          set_layout_6D_l_max
  end interface sll_o_set_layout_l_max

  !> Get corner index
  interface sll_o_get_layout_m_min
     module procedure get_layout_5D_m_min, get_layout_6D_m_min
  end interface sll_o_get_layout_m_min

  !> Get corner index
  interface sll_o_get_layout_m_max
     module procedure get_layout_5D_m_max, get_layout_6D_m_max
  end interface sll_o_get_layout_m_max

  !> Set layout index
  interface sll_o_set_layout_m_min
     module procedure set_layout_5D_m_min, set_layout_6D_m_min
  end interface sll_o_set_layout_m_min

  !> Set layout index
  interface sll_o_set_layout_m_max
     module procedure set_layout_5D_m_max, set_layout_6D_m_max
  end interface sll_o_set_layout_m_max

  !> Get corner index
  interface sll_o_get_layout_n_min
     module procedure get_layout_6D_n_min
  end interface sll_o_get_layout_n_min

  !> Get corner index
  interface sll_o_get_layout_n_max
     module procedure get_layout_6D_n_max
  end interface sll_o_get_layout_n_max

  !> Set layout index
  interface sll_o_set_layout_n_min
     module procedure set_layout_6D_n_min
  end interface sll_o_set_layout_n_min

  !> Set layout index
  interface sll_o_set_layout_n_max
     module procedure set_layout_6D_n_max
  end interface sll_o_set_layout_n_max

  !> Display indices of the layout by processors
  interface sll_o_view_lims
     module procedure &
          sll_view_lims_2d, &
          sll_view_lims_3d, &
          sll_view_lims_4d, &
          sll_view_lims_5d, &
          sll_view_lims_6d
  end interface

  !> Get box nodes number
  interface get_layout_num_nodes
     module procedure &
          get_layout_2D_num_nodes, &
          get_layout_3D_num_nodes, &
          get_layout_4D_num_nodes, &
          get_layout_5D_num_nodes, &
          get_layout_6D_num_nodes
  end interface

  !> Get box size
  interface get_layout_box
     module procedure &
          get_layout_2D_box, &
          get_layout_3D_box, &
          get_layout_4D_box, &
          get_layout_5D_box, &
          get_layout_6D_box
  end interface

  !> Get parallel info
  interface sll_o_get_layout_collective
     module procedure &
          get_layout_2D_collective, &
          get_layout_3D_collective, &
          get_layout_4D_collective, &
          get_layout_5D_collective, &
          get_layout_6D_collective
  end interface sll_o_get_layout_collective

  !> Get nodes number
  interface sll_o_get_num_nodes
     module procedure &
          sll_get_num_nodes_2D, &
          sll_get_num_nodes_3D, &
          sll_get_num_nodes_4D, &
          sll_get_num_nodes_5D, &
          sll_get_num_nodes_6D
   end interface

   !> Get global size
   interface get_layout_global_size_i
      module procedure &
           get_layout_2d_global_size_1, &
           get_layout_3d_global_size_1, &
           get_layout_4d_global_size_1, &
           get_layout_5d_global_size_1, &
           get_layout_6d_global_size_1
   end interface get_layout_global_size_i

   !> Get global size
   interface sll_o_get_layout_global_size_j
      module procedure &
           get_layout_2d_global_size_2, &
           get_layout_3d_global_size_2, &
           get_layout_4d_global_size_2, &
           get_layout_5d_global_size_2, &
           get_layout_6d_global_size_2
   end interface sll_o_get_layout_global_size_j

   !> Get global size
   interface sll_o_get_layout_global_size_k
      module procedure &
           get_layout_3d_global_size_3, &
           get_layout_4d_global_size_3, &
           get_layout_5d_global_size_3, &
           get_layout_6d_global_size_3
   end interface sll_o_get_layout_global_size_k

   !> Get global size
   interface sll_o_get_layout_global_size_l
      module procedure &
           get_layout_4d_global_size_4, &
           get_layout_5d_global_size_4, &
           get_layout_6d_global_size_4
   end interface sll_o_get_layout_global_size_l

   !> Get global size
   interface get_layout_global_size_m
      module procedure &
           get_layout_5d_global_size_5, &
           get_layout_6d_global_size_5
   end interface get_layout_global_size_m

   !> Get global size
   interface get_layout_global_size_n
      module procedure get_layout_6d_global_size_6
   end interface get_layout_global_size_n

   !> Count elements
   interface count_elements_in_box
     module procedure count_elements_in_box_2D, count_elements_in_box_3D, &
          count_elements_in_box_4D, count_elements_in_box_5D, &
          count_elements_in_box_6D
   end interface count_elements_in_box

   !> Intersection
   interface intersect_boxes
     module procedure intersect_boxes_2D, intersect_boxes_3D, &
          intersect_boxes_4D, intersect_boxes_5D, intersect_boxes_6D
   end interface intersect_boxes

   !> Optimization
   interface optimize_remap_plan
     module procedure &
          optimize_remap_plan_2D_int32, &
          optimize_remap_plan_2D_real64, &
          optimize_remap_plan_2D_comp64, &
          optimize_remap_plan_3D_int32, &
          optimize_remap_plan_3D_real64, &
          optimize_remap_plan_3D_comp64, &
          optimize_remap_plan_4D_int32, &
          optimize_remap_plan_4D_real64, &
          optimize_remap_plan_4D_comp64, &
          optimize_remap_plan_5D_int32, &
          optimize_remap_plan_5D_real64, &
          optimize_remap_plan_5D_comp64, &
          optimize_remap_plan_6D_int32, &
          optimize_remap_plan_6D_real64, &
          optimize_remap_plan_6D_comp64
   end interface optimize_remap_plan

  !> Plan to apply remap
  interface sll_o_new_remap_plan
     module procedure &
          new_remap_plan_2d_int32, &
          new_remap_plan_2d_real64, &
          new_remap_plan_2d_comp64, &
          new_remap_plan_3d_int32, &
          new_remap_plan_3d_real64, &
          new_remap_plan_3d_comp64, &
          new_remap_plan_4d_int32, &
          new_remap_plan_4d_real64, &
          new_remap_plan_4d_comp64, &
          new_remap_plan_5d_int32, &
          new_remap_plan_5d_real64, &
          new_remap_plan_5d_comp64, &
          new_remap_plan_6d_int32, &
          new_remap_plan_6d_real64, &
          new_remap_plan_6d_comp64
  end interface sll_o_new_remap_plan

  !> Execute plan
  interface sll_o_apply_remap_2d
     module procedure apply_remap_2D_double, apply_remap_2d_complex !, &
!          apply_remap_2d_efield
  end interface sll_o_apply_remap_2d

  !> Execute plan
  interface sll_o_apply_remap_3d
     module procedure apply_remap_3D_int, apply_remap_3D_double, &
          apply_remap_3D_complex
  end interface

  !> Execute plan
  interface sll_o_apply_remap_4d
     module procedure apply_remap_4D_double
  end interface sll_o_apply_remap_4d

  !> Execute plan
  interface sll_o_apply_remap_5d
     module procedure apply_remap_5D_double, apply_remap_5D_int
  end interface sll_o_apply_remap_5d


  !> Execute plan
  interface sll_o_apply_remap_6d
     module procedure apply_remap_6D_double, apply_remap_6D_int
  end interface sll_o_apply_remap_6d

  !> Deallocate
  interface sll_o_delete
     module procedure delete_layout_2D, delete_layout_3D, delete_layout_4D, &
          delete_layout_5D, delete_layout_6D, &
          delete_remap_2D_int32,  &
          delete_remap_2D_real64, &
          delete_remap_2D_comp64, &
          delete_remap_3D_int32,  &
          delete_remap_3D_real64, &
          delete_remap_3D_comp64, &
          delete_remap_4D_int32,  &
          delete_remap_4D_real64, &
          delete_remap_4D_comp64, &
          delete_remap_5D_int32,  &
          delete_remap_5D_real64, &
          delete_remap_5D_comp64, &
          delete_remap_6D_int32,  &
          delete_remap_6D_real64, &
          delete_remap_6D_comp64
  end interface sll_o_delete

  !> Get local sizes
  interface sll_o_compute_local_sizes
     module procedure compute_local_sizes_2d, compute_local_sizes_3d, &
          compute_local_sizes_4d, compute_local_sizes_5d, compute_local_sizes_6d
  end interface sll_o_compute_local_sizes

  !> Get global indices
  interface sll_o_local_to_global
     module procedure local_to_global_2D,local_to_global_3D, &
          local_to_global_4D, local_to_global_5D, local_to_global_6D
  end interface sll_o_local_to_global

  !> Get local indices
  interface sll_o_global_to_local
     module procedure global_to_local_2D,global_to_local_3D, &
          global_to_local_4D, global_to_local_5D, global_to_local_6D
  end interface sll_o_global_to_local

  !> @brief Initialize layout 
  !> @details It should have been allocated with new(), which means that
  !> its memory is allocated in accordance with the size of collective.
  interface sll_o_initialize_layout_with_distributed_array
     module procedure initialize_layout_with_distributed_2d_array
     module procedure initialize_layout_with_distributed_3d_array
     module procedure initialize_layout_with_distributed_4d_array
     module procedure initialize_layout_with_distributed_5d_array
     module procedure initialize_layout_with_distributed_6d_array
  end interface sll_o_initialize_layout_with_distributed_array


contains  !******************************************************************


  ! EXPERIMENTAL (in the Fortran context, that is)
  ! Here we explore how to address some code redundancies with a macro.
  ! This may come in handy when we can parametrize the creation of functions
  ! and thus centralize the code generation. The macro must be essentially
  ! bug-free lest it becomes a headache. In case that this is considered
  ! an abuse of the macro facility, we can convert into the multiple
  ! explicit declarations. But the centralized nature of the macro should
  ! not be discounted easily.
  ! 
  ! One thing learned from this is that the macros called from inside a
  ! macro like this (like ), don't need the semicolon, as they
  ! already have one themselves... it might be a good idea to remove the
  ! semicolon from the last line of all macros, so that they don't introduce
  ! this type of inconsistencies...



  function  sll_f_new_layout_2d( col )
 intrinsic :: associated
 type( sll_t_layout_2d ), pointer ::  sll_f_new_layout_2d
 type(sll_t_collective_t), pointer :: col
 integer(kind=i32) :: n_nodes
 integer(kind=i32) :: ierr
 if( .not. associated(col) ) then
 write (*,'(a)') 'ERROR: uninitialized collective'
 STOP 'NEW_LAYOUT_FUNCTION'
 end if
 allocate( sll_f_new_layout_2d, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 757)
  sll_f_new_layout_2d%collective => col
 n_nodes = sll_f_get_collective_size(col)
 allocate( sll_f_new_layout_2d%boxes(0:(n_nodes-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 757)
 end function  sll_f_new_layout_2d
  function  sll_f_new_layout_3d( col )
 intrinsic :: associated
 type( sll_t_layout_3d ), pointer ::  sll_f_new_layout_3d
 type(sll_t_collective_t), pointer :: col
 integer(kind=i32) :: n_nodes
 integer(kind=i32) :: ierr
 if( .not. associated(col) ) then
 write (*,'(a)') 'ERROR: uninitialized collective'
 STOP 'NEW_LAYOUT_FUNCTION'
 end if
 allocate( sll_f_new_layout_3d, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 758)
  sll_f_new_layout_3d%collective => col
 n_nodes = sll_f_get_collective_size(col)
 allocate( sll_f_new_layout_3d%boxes(0:(n_nodes-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 758)
 end function  sll_f_new_layout_3d
  function  sll_f_new_layout_4d( col )
 intrinsic :: associated
 type( sll_t_layout_4d ), pointer ::  sll_f_new_layout_4d
 type(sll_t_collective_t), pointer :: col
 integer(kind=i32) :: n_nodes
 integer(kind=i32) :: ierr
 if( .not. associated(col) ) then
 write (*,'(a)') 'ERROR: uninitialized collective'
 STOP 'NEW_LAYOUT_FUNCTION'
 end if
 allocate( sll_f_new_layout_4d, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 759)
  sll_f_new_layout_4d%collective => col
 n_nodes = sll_f_get_collective_size(col)
 allocate( sll_f_new_layout_4d%boxes(0:(n_nodes-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 759)
 end function  sll_f_new_layout_4d
  function  sll_f_new_layout_5d( col )
 intrinsic :: associated
 type( sll_t_layout_5d ), pointer ::  sll_f_new_layout_5d
 type(sll_t_collective_t), pointer :: col
 integer(kind=i32) :: n_nodes
 integer(kind=i32) :: ierr
 if( .not. associated(col) ) then
 write (*,'(a)') 'ERROR: uninitialized collective'
 STOP 'NEW_LAYOUT_FUNCTION'
 end if
 allocate( sll_f_new_layout_5d, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 760)
  sll_f_new_layout_5d%collective => col
 n_nodes = sll_f_get_collective_size(col)
 allocate( sll_f_new_layout_5d%boxes(0:(n_nodes-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 760)
 end function  sll_f_new_layout_5d
  function  sll_f_new_layout_6d( col )
 intrinsic :: associated
 type( sll_t_layout_6d ), pointer ::  sll_f_new_layout_6d
 type(sll_t_collective_t), pointer :: col
 integer(kind=i32) :: n_nodes
 integer(kind=i32) :: ierr
 if( .not. associated(col) ) then
 write (*,'(a)') 'ERROR: uninitialized collective'
 STOP 'NEW_LAYOUT_FUNCTION'
 end if
 allocate( sll_f_new_layout_6d, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 761)
  sll_f_new_layout_6d%collective => col
 n_nodes = sll_f_get_collective_size(col)
 allocate( sll_f_new_layout_6d%boxes(0:(n_nodes-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 761)
 end function  sll_f_new_layout_6d










  subroutine  delete_layout_2D( layout )
 type( sll_t_layout_2d ), pointer :: layout
 integer(kind=i32) :: ierr
 nullify( layout%collective )
 deallocate(layout%boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 772)
 nullify(layout%boxes)

 deallocate(layout, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 772)
 nullify(layout)

 end subroutine  delete_layout_2D
  subroutine  delete_layout_3D( layout )
 type( sll_t_layout_3d ), pointer :: layout
 integer(kind=i32) :: ierr
 nullify( layout%collective )
 deallocate(layout%boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 773)
 nullify(layout%boxes)

 deallocate(layout, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 773)
 nullify(layout)

 end subroutine  delete_layout_3D
  subroutine  delete_layout_4D( layout )
 type( sll_t_layout_4d ), pointer :: layout
 integer(kind=i32) :: ierr
 nullify( layout%collective )
 deallocate(layout%boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 774)
 nullify(layout%boxes)

 deallocate(layout, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 774)
 nullify(layout)

 end subroutine  delete_layout_4D
  subroutine  delete_layout_5D( layout )
 type( sll_t_layout_5d ), pointer :: layout
 integer(kind=i32) :: ierr
 nullify( layout%collective )
 deallocate(layout%boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 775)
 nullify(layout%boxes)

 deallocate(layout, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 775)
 nullify(layout)

 end subroutine  delete_layout_5D
  subroutine  delete_layout_6D( layout )
 type( sll_t_layout_6d ), pointer :: layout
 integer(kind=i32) :: ierr
 nullify( layout%collective )
 deallocate(layout%boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 776)
 nullify(layout%boxes)

 deallocate(layout, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 776)
 nullify(layout)

 end subroutine  delete_layout_6D

  ! Access functions for the boxes. This is really an overkill... On one hand,
  ! it is nice to hide everything behind access functions so that we 
  ! preserve the freedom of changing the representation of the types if
  ! needed. Also, this is not a performance-critical process. On the other
  ! hand, the only thing there is to hide here is a pair of chained %'s...
  ! All these could be greatly reduced by a few one-line macros, but at least
  ! for now we choose the conventional approach with access functions.







  function  get_layout_2D_num_nodes( layout )
 integer(kind=i32) ::  get_layout_2D_num_nodes
 type( sll_t_layout_2d ), pointer :: layout
  get_layout_2D_num_nodes = sll_f_get_collective_size( layout%collective )
 end function  get_layout_2D_num_nodes
  function  get_layout_3D_num_nodes( layout )
 integer(kind=i32) ::  get_layout_3D_num_nodes
 type( sll_t_layout_3d ), pointer :: layout
  get_layout_3D_num_nodes = sll_f_get_collective_size( layout%collective )
 end function  get_layout_3D_num_nodes
  function  get_layout_4D_num_nodes( layout )
 integer(kind=i32) ::  get_layout_4D_num_nodes
 type( sll_t_layout_4d ), pointer :: layout
  get_layout_4D_num_nodes = sll_f_get_collective_size( layout%collective )
 end function  get_layout_4D_num_nodes
  function  get_layout_5D_num_nodes( layout )
 integer(kind=i32) ::  get_layout_5D_num_nodes
 type( sll_t_layout_5d ), pointer :: layout
  get_layout_5D_num_nodes = sll_f_get_collective_size( layout%collective )
 end function  get_layout_5D_num_nodes
  function  get_layout_6D_num_nodes( layout )
 integer(kind=i32) ::  get_layout_6D_num_nodes
 type( sll_t_layout_6d ), pointer :: layout
  get_layout_6D_num_nodes = sll_f_get_collective_size( layout%collective )
 end function  get_layout_6D_num_nodes










  function  get_layout_2D_box( layout, rank )
 type( box_2D ) ::  get_layout_2D_box
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 
  get_layout_2D_box = layout%boxes(rank)
 end function  get_layout_2D_box
  function  get_layout_3D_box( layout, rank )
 type( box_3D ) ::  get_layout_3D_box
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 
  get_layout_3D_box = layout%boxes(rank)
 end function  get_layout_3D_box
  function  get_layout_4D_box( layout, rank )
 type( box_4D ) ::  get_layout_4D_box
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 
  get_layout_4D_box = layout%boxes(rank)
 end function  get_layout_4D_box
  function  get_layout_5D_box( layout, rank )
 type( box_5D ) ::  get_layout_5D_box
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 
  get_layout_5D_box = layout%boxes(rank)
 end function  get_layout_5D_box
  function  get_layout_6D_box( layout, rank )
 type( box_6D ) ::  get_layout_6D_box
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 
  get_layout_6D_box = layout%boxes(rank)
 end function  get_layout_6D_box









  ! This macro is not well named, it accesses the slot of a box, not a layout.








  ! Macro to permit access to a layout slot, but only works for Fortran-native
  ! types.







  ! We use the macros to write the set_ get_ functions for the different 
  ! dimensions.

  ! 2D case:
  function  get_layout_2D_i_min( layout, rank )
 integer(kind=i32) ::  get_layout_2D_i_min
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_2D_i_min = layout%boxes(rank)% i_min 
 end function  get_layout_2D_i_min
  function  get_layout_2D_i_max( layout, rank )
 integer(kind=i32) ::  get_layout_2D_i_max
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_2D_i_max = layout%boxes(rank)% i_max 
 end function  get_layout_2D_i_max
  function  get_layout_2D_j_min( layout, rank )
 integer(kind=i32) ::  get_layout_2D_j_min
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_2D_j_min = layout%boxes(rank)% j_min 
 end function  get_layout_2D_j_min
  function  get_layout_2D_j_max( layout, rank )
 integer(kind=i32) ::  get_layout_2D_j_max
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_2D_j_max = layout%boxes(rank)% j_max 
 end function  get_layout_2D_j_max

  function get_layout_2d_global_size_1( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_2d), pointer :: layout
 res = layout%global_sz1
 end function get_layout_2d_global_size_1
  function get_layout_2d_global_size_2( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_2d), pointer :: layout
 res = layout%global_sz2
 end function get_layout_2d_global_size_2

  subroutine  set_layout_2D_i_min( layout, rank, val )
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_min  = val
 end subroutine  set_layout_2D_i_min
  subroutine  set_layout_2D_i_max( layout, rank, val )
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_max  = val
 end subroutine  set_layout_2D_i_max
  subroutine  set_layout_2D_j_min( layout, rank, val )
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_min  = val
 end subroutine  set_layout_2D_j_min
  subroutine  set_layout_2D_j_max( layout, rank, val )
 type( sll_t_layout_2d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_max  = val
 end subroutine  set_layout_2D_j_max

  ! 3D case:
  function  get_layout_3D_i_min( layout, rank )
 integer(kind=i32) ::  get_layout_3D_i_min
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_i_min = layout%boxes(rank)% i_min 
 end function  get_layout_3D_i_min
  function  get_layout_3D_i_max( layout, rank )
 integer(kind=i32) ::  get_layout_3D_i_max
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_i_max = layout%boxes(rank)% i_max 
 end function  get_layout_3D_i_max
  function  get_layout_3D_j_min( layout, rank )
 integer(kind=i32) ::  get_layout_3D_j_min
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_j_min = layout%boxes(rank)% j_min 
 end function  get_layout_3D_j_min
  function  get_layout_3D_j_max( layout, rank )
 integer(kind=i32) ::  get_layout_3D_j_max
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_j_max = layout%boxes(rank)% j_max 
 end function  get_layout_3D_j_max
  function  get_layout_3D_k_min( layout, rank )
 integer(kind=i32) ::  get_layout_3D_k_min
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_k_min = layout%boxes(rank)% k_min 
 end function  get_layout_3D_k_min
  function  get_layout_3D_k_max( layout, rank )
 integer(kind=i32) ::  get_layout_3D_k_max
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_3D_k_max = layout%boxes(rank)% k_max 
 end function  get_layout_3D_k_max

  function get_layout_3d_global_size_1( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_3d), pointer :: layout
 res = layout%global_sz1
 end function get_layout_3d_global_size_1
  function get_layout_3d_global_size_2( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_3d), pointer :: layout
 res = layout%global_sz2
 end function get_layout_3d_global_size_2
  function get_layout_3d_global_size_3( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_3d), pointer :: layout
 res = layout%global_sz3
 end function get_layout_3d_global_size_3

  subroutine  set_layout_3D_i_min( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_min  = val
 end subroutine  set_layout_3D_i_min
  subroutine  set_layout_3D_i_max( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_max  = val
 end subroutine  set_layout_3D_i_max
  subroutine  set_layout_3D_j_min( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_min  = val
 end subroutine  set_layout_3D_j_min
  subroutine  set_layout_3D_j_max( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_max  = val
 end subroutine  set_layout_3D_j_max
  subroutine  set_layout_3D_k_min( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_min  = val
 end subroutine  set_layout_3D_k_min
  subroutine  set_layout_3D_k_max( layout, rank, val )
 type( sll_t_layout_3d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_max  = val
 end subroutine  set_layout_3D_k_max

  ! 4D case:
  function  get_layout_4D_i_min( layout, rank )
 integer(kind=i32) ::  get_layout_4D_i_min
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_i_min = layout%boxes(rank)% i_min 
 end function  get_layout_4D_i_min
  function  get_layout_4D_i_max( layout, rank )
 integer(kind=i32) ::  get_layout_4D_i_max
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_i_max = layout%boxes(rank)% i_max 
 end function  get_layout_4D_i_max
  function  get_layout_4D_j_min( layout, rank )
 integer(kind=i32) ::  get_layout_4D_j_min
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_j_min = layout%boxes(rank)% j_min 
 end function  get_layout_4D_j_min
  function  get_layout_4D_j_max( layout, rank )
 integer(kind=i32) ::  get_layout_4D_j_max
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_j_max = layout%boxes(rank)% j_max 
 end function  get_layout_4D_j_max
  function  get_layout_4D_k_min( layout, rank )
 integer(kind=i32) ::  get_layout_4D_k_min
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_k_min = layout%boxes(rank)% k_min 
 end function  get_layout_4D_k_min
  function  get_layout_4D_k_max( layout, rank )
 integer(kind=i32) ::  get_layout_4D_k_max
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_k_max = layout%boxes(rank)% k_max 
 end function  get_layout_4D_k_max
  function  get_layout_4D_l_min( layout, rank )
 integer(kind=i32) ::  get_layout_4D_l_min
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_l_min = layout%boxes(rank)% l_min 
 end function  get_layout_4D_l_min
  function  get_layout_4D_l_max( layout, rank )
 integer(kind=i32) ::  get_layout_4D_l_max
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_4D_l_max = layout%boxes(rank)% l_max 
 end function  get_layout_4D_l_max

  function get_layout_4d_global_size_1( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_4d), pointer :: layout
 res = layout%global_sz1
 end function get_layout_4d_global_size_1
  function get_layout_4d_global_size_2( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_4d), pointer :: layout
 res = layout%global_sz2
 end function get_layout_4d_global_size_2
  function get_layout_4d_global_size_3( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_4d), pointer :: layout
 res = layout%global_sz3
 end function get_layout_4d_global_size_3
  function get_layout_4d_global_size_4( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_4d), pointer :: layout
 res = layout%global_sz4
 end function get_layout_4d_global_size_4

  subroutine  set_layout_4D_i_min( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_min  = val
 end subroutine  set_layout_4D_i_min
  subroutine  set_layout_4D_i_max( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_max  = val
 end subroutine  set_layout_4D_i_max
  subroutine  set_layout_4D_j_min( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_min  = val
 end subroutine  set_layout_4D_j_min
  subroutine  set_layout_4D_j_max( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_max  = val
 end subroutine  set_layout_4D_j_max
  subroutine  set_layout_4D_k_min( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_min  = val
 end subroutine  set_layout_4D_k_min
  subroutine  set_layout_4D_k_max( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_max  = val
 end subroutine  set_layout_4D_k_max
  subroutine  set_layout_4D_l_min( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_min  = val
 end subroutine  set_layout_4D_l_min
  subroutine  set_layout_4D_l_max( layout, rank, val )
 type( sll_t_layout_4d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_max  = val
 end subroutine  set_layout_4D_l_max

  ! 5D case:
  function  get_layout_5D_i_min( layout, rank )
 integer(kind=i32) ::  get_layout_5D_i_min
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_i_min = layout%boxes(rank)% i_min 
 end function  get_layout_5D_i_min
  function  get_layout_5D_i_max( layout, rank )
 integer(kind=i32) ::  get_layout_5D_i_max
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_i_max = layout%boxes(rank)% i_max 
 end function  get_layout_5D_i_max
  function  get_layout_5D_j_min( layout, rank )
 integer(kind=i32) ::  get_layout_5D_j_min
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_j_min = layout%boxes(rank)% j_min 
 end function  get_layout_5D_j_min
  function  get_layout_5D_j_max( layout, rank )
 integer(kind=i32) ::  get_layout_5D_j_max
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_j_max = layout%boxes(rank)% j_max 
 end function  get_layout_5D_j_max
  function  get_layout_5D_k_min( layout, rank )
 integer(kind=i32) ::  get_layout_5D_k_min
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_k_min = layout%boxes(rank)% k_min 
 end function  get_layout_5D_k_min
  function  get_layout_5D_k_max( layout, rank )
 integer(kind=i32) ::  get_layout_5D_k_max
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_k_max = layout%boxes(rank)% k_max 
 end function  get_layout_5D_k_max
  function  get_layout_5D_l_min( layout, rank )
 integer(kind=i32) ::  get_layout_5D_l_min
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_l_min = layout%boxes(rank)% l_min 
 end function  get_layout_5D_l_min
  function  get_layout_5D_l_max( layout, rank )
 integer(kind=i32) ::  get_layout_5D_l_max
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_l_max = layout%boxes(rank)% l_max 
 end function  get_layout_5D_l_max
  function  get_layout_5D_m_min( layout, rank )
 integer(kind=i32) ::  get_layout_5D_m_min
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_m_min = layout%boxes(rank)% m_min 
 end function  get_layout_5D_m_min
  function  get_layout_5D_m_max( layout, rank )
 integer(kind=i32) ::  get_layout_5D_m_max
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_5D_m_max = layout%boxes(rank)% m_max 
 end function  get_layout_5D_m_max

  function get_layout_5d_global_size_1( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_5d), pointer :: layout
 res = layout%global_sz1
 end function get_layout_5d_global_size_1
  function get_layout_5d_global_size_2( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_5d), pointer :: layout
 res = layout%global_sz2
 end function get_layout_5d_global_size_2
  function get_layout_5d_global_size_3( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_5d), pointer :: layout
 res = layout%global_sz3
 end function get_layout_5d_global_size_3
  function get_layout_5d_global_size_4( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_5d), pointer :: layout
 res = layout%global_sz4
 end function get_layout_5d_global_size_4
  function get_layout_5d_global_size_5( layout ) result(res)
 integer(kind=i32) :: res
 type( sll_t_layout_5d), pointer :: layout
 res = layout%global_sz5
 end function get_layout_5d_global_size_5

  subroutine  set_layout_5D_i_min( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_min  = val
 end subroutine  set_layout_5D_i_min
  subroutine  set_layout_5D_i_max( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_max  = val
 end subroutine  set_layout_5D_i_max
  subroutine  set_layout_5D_j_min( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_min  = val
 end subroutine  set_layout_5D_j_min
  subroutine  set_layout_5D_j_max( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_max  = val
 end subroutine  set_layout_5D_j_max
  subroutine  set_layout_5D_k_min( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_min  = val
 end subroutine  set_layout_5D_k_min
  subroutine  set_layout_5D_k_max( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_max  = val
 end subroutine  set_layout_5D_k_max
  subroutine  set_layout_5D_l_min( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_min  = val
 end subroutine  set_layout_5D_l_min
  subroutine  set_layout_5D_l_max( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_max  = val
 end subroutine  set_layout_5D_l_max
  subroutine  set_layout_5D_m_min( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% m_min  = val
 end subroutine  set_layout_5D_m_min
  subroutine  set_layout_5D_m_max( layout, rank, val )
 type( sll_t_layout_5d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% m_max  = val
 end subroutine  set_layout_5D_m_max

  ! 6D case:
  function  get_layout_6D_i_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_i_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_i_min = layout%boxes(rank)% i_min 
 end function  get_layout_6D_i_min
  function  get_layout_6D_i_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_i_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_i_max = layout%boxes(rank)% i_max 
 end function  get_layout_6D_i_max
  function  get_layout_6D_j_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_j_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_j_min = layout%boxes(rank)% j_min 
 end function  get_layout_6D_j_min
  function  get_layout_6D_j_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_j_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_j_max = layout%boxes(rank)% j_max 
 end function  get_layout_6D_j_max
  function  get_layout_6D_k_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_k_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_k_min = layout%boxes(rank)% k_min 
 end function  get_layout_6D_k_min
  function  get_layout_6D_k_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_k_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_k_max = layout%boxes(rank)% k_max 
 end function  get_layout_6D_k_max
  function  get_layout_6D_l_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_l_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_l_min = layout%boxes(rank)% l_min 
 end function  get_layout_6D_l_min
  function  get_layout_6D_l_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_l_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_l_max = layout%boxes(rank)% l_max 
 end function  get_layout_6D_l_max
  function  get_layout_6D_m_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_m_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_m_min = layout%boxes(rank)% m_min 
 end function  get_layout_6D_m_min
  function  get_layout_6D_m_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_m_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_m_max = layout%boxes(rank)% m_max 
 end function  get_layout_6D_m_max
  function  get_layout_6D_n_min( layout, rank )
 integer(kind=i32) ::  get_layout_6D_n_min
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_n_min = layout%boxes(rank)% n_min 
 end function  get_layout_6D_n_min
  function  get_layout_6D_n_max( layout, rank )
 integer(kind=i32) ::  get_layout_6D_n_max
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
  get_layout_6D_n_max = layout%boxes(rank)% n_max 
 end function  get_layout_6D_n_max

  function get_layout_6d_global_size_1( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz1
 end function get_layout_6d_global_size_1
  function get_layout_6d_global_size_2( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz2
 end function get_layout_6d_global_size_2
  function get_layout_6d_global_size_3( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz3
 end function get_layout_6d_global_size_3
  function get_layout_6d_global_size_4( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz4
 end function get_layout_6d_global_size_4
  function get_layout_6d_global_size_5( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz5
 end function get_layout_6d_global_size_5
  function get_layout_6d_global_size_6( layout ) result(res)
 integer(kind=i32) :: res
 type(sll_t_layout_6d), pointer :: layout
 res = layout%global_sz6
 end function get_layout_6d_global_size_6

  subroutine  set_layout_6D_i_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_min  = val
 end subroutine  set_layout_6D_i_min
  subroutine  set_layout_6D_i_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% i_max  = val
 end subroutine  set_layout_6D_i_max
  subroutine  set_layout_6D_j_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_min  = val
 end subroutine  set_layout_6D_j_min
  subroutine  set_layout_6D_j_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% j_max  = val
 end subroutine  set_layout_6D_j_max
  subroutine  set_layout_6D_k_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_min  = val
 end subroutine  set_layout_6D_k_min
  subroutine  set_layout_6D_k_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% k_max  = val
 end subroutine  set_layout_6D_k_max
  subroutine  set_layout_6D_l_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_min  = val
 end subroutine  set_layout_6D_l_min
  subroutine  set_layout_6D_l_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% l_max  = val
 end subroutine  set_layout_6D_l_max
  subroutine  set_layout_6D_m_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% m_min  = val
 end subroutine  set_layout_6D_m_min
  subroutine  set_layout_6D_m_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% m_max  = val
 end subroutine  set_layout_6D_m_max
  subroutine  set_layout_6D_n_min( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% n_min  = val
 end subroutine  set_layout_6D_n_min
  subroutine  set_layout_6D_n_max( layout, rank, val )
 type( sll_t_layout_6d), pointer :: layout
 integer(kind=i32), intent(in) :: rank
 integer(kind=i32), intent(in) :: val
 layout%boxes(rank)% n_max  = val
 end subroutine  set_layout_6D_n_max

  ! Why should lims just give its collective nilly-willy? This is not 
  ! pretty but I have the suspicion that direct access of the collective 
  ! will be needed.


  function  get_layout_2D_collective( layout )
 intrinsic :: associated
 type(sll_t_collective_t), pointer ::  get_layout_2D_collective
 type( sll_t_layout_2d ), pointer :: layout
 if( .not. associated(layout) ) then
 stop 'ERROR: uninitialized argument, get_layout_XD_collective()'
 end if
  get_layout_2D_collective => layout%collective
 end function  get_layout_2D_collective
  function  get_layout_3D_collective( layout )
 intrinsic :: associated
 type(sll_t_collective_t), pointer ::  get_layout_3D_collective
 type( sll_t_layout_3d ), pointer :: layout
 if( .not. associated(layout) ) then
 stop 'ERROR: uninitialized argument, get_layout_XD_collective()'
 end if
  get_layout_3D_collective => layout%collective
 end function  get_layout_3D_collective
  function  get_layout_4D_collective( layout )
 intrinsic :: associated
 type(sll_t_collective_t), pointer ::  get_layout_4D_collective
 type( sll_t_layout_4d ), pointer :: layout
 if( .not. associated(layout) ) then
 stop 'ERROR: uninitialized argument, get_layout_XD_collective()'
 end if
  get_layout_4D_collective => layout%collective
 end function  get_layout_4D_collective
  function  get_layout_5D_collective( layout )
 intrinsic :: associated
 type(sll_t_collective_t), pointer ::  get_layout_5D_collective
 type( sll_t_layout_5d ), pointer :: layout
 if( .not. associated(layout) ) then
 stop 'ERROR: uninitialized argument, get_layout_XD_collective()'
 end if
  get_layout_5D_collective => layout%collective
 end function  get_layout_5D_collective
  function  get_layout_6D_collective( layout )
 intrinsic :: associated
 type(sll_t_collective_t), pointer ::  get_layout_6D_collective
 type( sll_t_layout_6d ), pointer :: layout
 if( .not. associated(layout) ) then
 stop 'ERROR: uninitialized argument, get_layout_XD_collective()'
 end if
  get_layout_6D_collective => layout%collective
 end function  get_layout_6D_collective

  ! get_layout_XD_size() returns the size of the collective associated
  ! with a given layout.


  function get_layout_2D_size( layout )
 intrinsic :: associated
 integer(kind=i32) :: get_layout_2D_size
 type( sll_t_layout_2d), pointer :: layout
 if( .not. associated(layout) ) then
 STOP 'ERROR: not associated argument passed to get_layout_size().'
 end if
 get_layout_2D_size = sll_f_get_collective_size( layout%collective )
 end function get_layout_2D_size
  function get_layout_3D_size( layout )
 intrinsic :: associated
 integer(kind=i32) :: get_layout_3D_size
 type( sll_t_layout_3d), pointer :: layout
 if( .not. associated(layout) ) then
 STOP 'ERROR: not associated argument passed to get_layout_size().'
 end if
 get_layout_3D_size = sll_f_get_collective_size( layout%collective )
 end function get_layout_3D_size
  function get_layout_4D_size( layout )
 intrinsic :: associated
 integer(kind=i32) :: get_layout_4D_size
 type( sll_t_layout_4d), pointer :: layout
 if( .not. associated(layout) ) then
 STOP 'ERROR: not associated argument passed to get_layout_size().'
 end if
 get_layout_4D_size = sll_f_get_collective_size( layout%collective )
 end function get_layout_4D_size
  function get_layout_5D_size( layout )
 intrinsic :: associated
 integer(kind=i32) :: get_layout_5D_size
 type( sll_t_layout_5d), pointer :: layout
 if( .not. associated(layout) ) then
 STOP 'ERROR: not associated argument passed to get_layout_size().'
 end if
 get_layout_5D_size = sll_f_get_collective_size( layout%collective )
 end function get_layout_5D_size
  function get_layout_6D_size( layout )
 intrinsic :: associated
 integer(kind=i32) :: get_layout_6D_size
 type( sll_t_layout_6d), pointer :: layout
 if( .not. associated(layout) ) then
 STOP 'ERROR: not associated argument passed to get_layout_size().'
 end if
 get_layout_6D_size = sll_f_get_collective_size( layout%collective )
 end function get_layout_6D_size

  ! Utility functions to help build layouts.
  function linear_index_2D(npx1, i, j)
    integer(kind=i32), intent(in) :: npx1
    integer(kind=i32), intent(in) :: i
    integer(kind=i32), intent(in) :: j
    integer(kind=i32) :: linear_index_2D
    linear_index_2D = i + npx1*j
  end function linear_index_2D

  function linear_index_3D(npx1, npx2, i, j, k)
    integer(kind=i32), intent(in) :: npx1
    integer(kind=i32), intent(in) :: npx2
    integer(kind=i32), intent(in) :: i
    integer(kind=i32), intent(in) :: j
    integer(kind=i32), intent(in) :: k
    integer(kind=i32) :: linear_index_3D
    linear_index_3D = i + npx1*(j + npx2*k)
  end function linear_index_3D

  function linear_index_4D(npx1, npx2, npx3, i, j, k, l)
    integer(kind=i32), intent(in) :: npx1
    integer(kind=i32), intent(in) :: npx2
    integer(kind=i32), intent(in) :: npx3
    integer(kind=i32), intent(in) :: i
    integer(kind=i32), intent(in) :: j
    integer(kind=i32), intent(in) :: k
    integer(kind=i32), intent(in) :: l
    integer(kind=i32) :: linear_index_4D
    linear_index_4D = i + npx1*(j + npx2*(k + npx3*l))
  end function linear_index_4D

  function linear_index_5D(npx1, npx2, npx3, npx4,  i, j, k, l, m)
    integer(kind=i32), intent(in) :: npx1
    integer(kind=i32), intent(in) :: npx2
    integer(kind=i32), intent(in) :: npx3
    integer(kind=i32), intent(in) :: npx4
    integer(kind=i32), intent(in) :: i
    integer(kind=i32), intent(in) :: j
    integer(kind=i32), intent(in) :: k
    integer(kind=i32), intent(in) :: l
    integer(kind=i32), intent(in) :: m
    integer(kind=i32) :: linear_index_5D
    linear_index_5D = i + npx1*(j + npx2*(k + npx3*(l + npx4*m)))
  end function linear_index_5D

  function linear_index_6D(npx1, npx2, npx3, npx4, npx5, i, j, k, l, m, n)
    integer(kind=i32), intent(in) :: npx1
    integer(kind=i32), intent(in) :: npx2
    integer(kind=i32), intent(in) :: npx3
    integer(kind=i32), intent(in) :: npx4
    integer(kind=i32), intent(in) :: npx5
    integer(kind=i32), intent(in) :: i
    integer(kind=i32), intent(in) :: j
    integer(kind=i32), intent(in) :: k
    integer(kind=i32), intent(in) :: l
    integer(kind=i32), intent(in) :: m
    integer(kind=i32), intent(in) :: n
    integer(kind=i32) :: linear_index_6D
    linear_index_6D = i + npx1*(j + npx2*(k + npx3*(l + npx4*(m + npx5*n))))
  end function linear_index_6D

  subroutine initialize_layout_with_distributed_2d_array( &
    global_npx1, &  
    global_npx2, &
    num_proc_x1, &
    num_proc_x2, &
    layout )
    
    ! sll_t_layout_2d should have been allocated with new(), which means that
    ! its memory is allocated in accordance with the size of collective.
    ! This should be error-checked below for consistency.
    integer(kind=i32), intent(in) :: global_npx1
    integer(kind=i32), intent(in) :: global_npx2
    integer(kind=i32), intent(in) :: num_proc_x1
    integer(kind=i32), intent(in) :: num_proc_x2
    type(sll_t_layout_2d), pointer :: layout
    integer(kind=i32) :: i
    integer(kind=i32) :: j
    integer(kind=i32) :: total_num_processors
    integer(kind=i32) :: node
    integer(kind=i32) :: collective_size
    integer(kind=i32) :: err
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x1
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x2

    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max

    if( &
       .not. sll_f_is_power_of_two(int(num_proc_x1,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x2,i64)) ) then
       print *, 'ERROR: distribute_2D_array() needs that the integers that',&
            'describe the process mesh are powers of 2.'
       STOP
    end if

    if( &
       .not. (global_npx1 .gt. 0) .or. &
       .not. (global_npx2 .gt. 0) ) then
       print *, 'ERROR: distribute_2D_array() needs that the array dimensions',&
            'be greater than zero.'
       STOP
    end if

    layout%global_sz1 = global_npx1
    layout%global_sz2 = global_npx2

    ! FIXME: add further error checking, like a minimum number of points
    ! needed given a processor number along a dimension. Also, num_proc_xi
    ! should be different than zero.
    allocate( intervals_x1(0:1,0:num_proc_x1-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1113)

    allocate( intervals_x2(0:1,0:num_proc_x2-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1114)


    ! Allocate the layout to be returned.    
    total_num_processors = num_proc_x1*num_proc_x2
    collective_size = get_layout_2D_size(layout)
    if( total_num_processors .ne. collective_size ) then
       print *, 'ERROR, initialize_layout_with_distributed_2d_array(): ',&
            'requested size of the processor mesh is inconsistent with ', &
            'the size of the collective.', 'number of processors = ', &
            total_num_processors, ' collective size = ', collective_size
       STOP
    end if

    ! Compute the arrays with the split index information along the different
    ! dimensions.
    intervals_x1(0:1,0:num_proc_x1-1) = &
         split_array_indices( 1, global_npx1, num_proc_x1 )

    intervals_x2(0:1,0:num_proc_x2-1) = &
         split_array_indices( 1, global_npx2, num_proc_x2 )

    ! Fill the layout array.
    do j=0, num_proc_x2-1
       do i=0, num_proc_x1-1
          node = linear_index_2D( num_proc_x1, i, j )
          i_min = intervals_x1(0,i)
          i_max = intervals_x1(1,i)
          j_min = intervals_x2(0,j)
          j_max = intervals_x2(1,j)
          call sll_o_set_layout_i_min( layout, node, i_min )
          call sll_o_set_layout_i_max( layout, node, i_max )
          call sll_o_set_layout_j_min( layout, node, j_min )
          call sll_o_set_layout_j_max( layout, node, j_max )
       end do
    end do
    deallocate( intervals_x1, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1149 )

    deallocate( intervals_x2, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1150 )

  end subroutine initialize_layout_with_distributed_2d_array

  subroutine initialize_layout_with_distributed_3D_array( &
    global_npx1, &  
    global_npx2, &
    global_npx3, &
    num_proc_x1, &
    num_proc_x2, &
    num_proc_x3, &
    layout )
    
    ! layout should have been allocated with new(), which means that
    ! its memory is allocated in accordance with the size of collective.
    ! This should be error-checked below for consistency.
    integer(kind=i32), intent(in) :: global_npx1
    integer(kind=i32), intent(in) :: global_npx2
    integer(kind=i32), intent(in) :: global_npx3
    integer(kind=i32), intent(in) :: num_proc_x1
    integer(kind=i32), intent(in) :: num_proc_x2
    integer(kind=i32), intent(in) :: num_proc_x3
    type(sll_t_layout_3d), pointer :: layout


    integer(kind=i32) :: i
    integer(kind=i32) :: j
    integer(kind=i32) :: k
    integer(kind=i32) :: total_num_processors
    integer(kind=i32) :: node
    integer(kind=i32) :: collective_size
    integer(kind=i32) :: err
!    integer(kind=i32), dimension(0:1,0:num_proc_x1-1) :: intervals_x1
!    integer(kind=i32), dimension(0:1,0:num_proc_x2-1) :: intervals_x2
!    integer(kind=i32), dimension(0:1,0:num_proc_x3-1) :: intervals_x3
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x1
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x2
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x3

    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max

    if( &
       .not. sll_f_is_power_of_two(int(num_proc_x1,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x2,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x3,i64)) ) then
       print *, 'ERROR: distribute_3D_array() needs that the integers that',&
            'describe the process mesh are powers of 2.'
       STOP
    end if

    if( &
       .not. (global_npx1 .gt. 0) .or. &
       .not. (global_npx2 .gt. 0) .or. &
       .not. (global_npx3 .gt. 0) ) then
       print *, 'ERROR: distribute_3D_array() needs that the array dimensions',&
            'be greater than zero.'
       STOP
    end if

    layout%global_sz1 = global_npx1
    layout%global_sz2 = global_npx2
    layout%global_sz3 = global_npx3

    ! FIXME: add further error checking, like a minimum number of points
    ! needed given a processor number along a dimension. Also, num_proc_xi
    ! should be different than zero.
    allocate( intervals_x1(0:1,0:num_proc_x1-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1220)

    allocate( intervals_x2(0:1,0:num_proc_x2-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1221)

    allocate( intervals_x3(0:1,0:num_proc_x3-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1222)


    ! Allocate the layout to be returned.    
    total_num_processors = num_proc_x1*num_proc_x2*num_proc_x3
    collective_size = get_layout_3D_size(layout)
    if( total_num_processors .ne. collective_size ) then
       print *, 'ERROR, initialize_layout_with_distributed_3D_array(): ', &
            'requested size of the processor mesh is inconsistent with ', &
            'the size of the collective.', 'number of processors = ', &
            total_num_processors, ' collective size = ', collective_size
       STOP
    end if

    ! Compute the arrays with the split index information along the different
    ! dimensions.
    intervals_x1(0:1,0:num_proc_x1-1) = &
         split_array_indices( 1, global_npx1, num_proc_x1 )

    intervals_x2(0:1,0:num_proc_x2-1) = &
         split_array_indices( 1, global_npx2, num_proc_x2 )

    intervals_x3(0:1,0:num_proc_x3-1) = &
         split_array_indices( 1, global_npx3, num_proc_x3 )

    ! Fill the layout array.
    do k=0, num_proc_x3-1
       do j=0, num_proc_x2-1
          do i=0, num_proc_x1-1
             node = linear_index_3D( num_proc_x1, num_proc_x2, i, j, k )
             i_min = intervals_x1(0,i)
             i_max = intervals_x1(1,i)
             j_min = intervals_x2(0,j)
             j_max = intervals_x2(1,j)
             k_min = intervals_x3(0,k)
             k_max = intervals_x3(1,k)
             call sll_o_set_layout_i_min( layout, node, i_min )
             call sll_o_set_layout_i_max( layout, node, i_max )
             call sll_o_set_layout_j_min( layout, node, j_min )
             call sll_o_set_layout_j_max( layout, node, j_max )
             call sll_o_set_layout_k_min( layout, node, k_min )
             call sll_o_set_layout_k_max( layout, node, k_max )
          end do
       end do
    end do
    deallocate( intervals_x1, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1266 )

    deallocate( intervals_x2, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1267 )

    deallocate( intervals_x3, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1268 )

   end subroutine initialize_layout_with_distributed_3D_array


  subroutine initialize_layout_with_distributed_4D_array( &
    global_npx1, &  
    global_npx2, &
    global_npx3, &
    global_npx4, &
    num_proc_x1, &
    num_proc_x2, &
    num_proc_x3, &
    num_proc_x4, &
    layout )
    
    ! sll_t_layout_4d should have been allocated with new(), which means that
    ! its memory is allocated in accordance with the size of collective.
    ! This should be error-checked below for consistency.
    integer(kind=i32), intent(in) :: global_npx1
    integer(kind=i32), intent(in) :: global_npx2
    integer(kind=i32), intent(in) :: global_npx3
    integer(kind=i32), intent(in) :: global_npx4
    integer(kind=i32), intent(in) :: num_proc_x1
    integer(kind=i32), intent(in) :: num_proc_x2
    integer(kind=i32), intent(in) :: num_proc_x3
    integer(kind=i32), intent(in) :: num_proc_x4
    type(sll_t_layout_4d), pointer :: layout
    integer(kind=i32) :: i
    integer(kind=i32) :: j
    integer(kind=i32) :: k
    integer(kind=i32) :: l
    integer(kind=i32) :: total_num_processors
    integer(kind=i32) :: node
    integer(kind=i32) :: collective_size
    integer(kind=i32) :: err
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x1
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x2
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x3
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x4
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max

    if( &
       .not. sll_f_is_power_of_two(int(num_proc_x1,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x2,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x3,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x4,i64)) ) then
       print *, 'ERROR: distribute_4D_array() needs that the integers that',&
            'describe the process mesh are powers of 2.'
       STOP
    end if

    if( &
       .not. (global_npx1 .gt. 0) .or. &
       .not. (global_npx2 .gt. 0) .or. &
       .not. (global_npx3 .gt. 0) .or. &
       .not. (global_npx4 .gt. 0) ) then
       print *, 'ERROR: distribute_4D_array() needs that the array dimensions',&
            'be greater than zero.'
       STOP
    end if

    layout%global_sz1 = global_npx1
    layout%global_sz2 = global_npx2
    layout%global_sz3 = global_npx3
    layout%global_sz4 = global_npx4

    ! FIXME: add further error checking, like a minimum number of points
    ! needed given a processor number along a dimension. Also, num_proc_xi
    ! should be different than zero.
    allocate( intervals_x1(0:1,0:num_proc_x1-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1344)

    allocate( intervals_x2(0:1,0:num_proc_x2-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1345)

    allocate( intervals_x3(0:1,0:num_proc_x3-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1346)

    allocate( intervals_x4(0:1,0:num_proc_x4-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1347)


    ! Allocate the layout to be returned.    
    total_num_processors = num_proc_x1*num_proc_x2*num_proc_x3*num_proc_x4
    collective_size = get_layout_4D_size(layout)
    if( total_num_processors .ne. collective_size ) then
       print *, 'ERROR, initialize_layout_with_distributed_4D_array():', &
            'requested size of the processor mesh is inconsistent with ', &
            'the size of the collective.', 'number of processors = ', &
            total_num_processors, ' collective size = ', collective_size
       STOP
    end if

    ! Compute the arrays with the split index information along the different
    ! dimensions.
    intervals_x1(0:1,0:num_proc_x1-1) = &
         split_array_indices( 1, global_npx1, num_proc_x1 )

    intervals_x2(0:1,0:num_proc_x2-1) = &
         split_array_indices( 1, global_npx2, num_proc_x2 )

    intervals_x3(0:1,0:num_proc_x3-1) = &
         split_array_indices( 1, global_npx3, num_proc_x3 )

    intervals_x4(0:1,0:num_proc_x4-1) = &
         split_array_indices( 1, global_npx4, num_proc_x4 )

    ! Fill the layout array.
    do l=0, num_proc_x4-1
       do k=0, num_proc_x3-1
          do j=0, num_proc_x2-1
             do i=0, num_proc_x1-1
                node = linear_index_4D( &
                     num_proc_x1, &
                     num_proc_x2, &
                     num_proc_x3, &
                     i, &
                     j, &
                     k, &
                     l )
                i_min = intervals_x1(0,i)
                i_max = intervals_x1(1,i)

                j_min = intervals_x2(0,j)
                j_max = intervals_x2(1,j)

                k_min = intervals_x3(0,k)
                k_max = intervals_x3(1,k)

                l_min = intervals_x4(0,l)
                l_max = intervals_x4(1,l)
                call sll_o_set_layout_i_min( layout, node, i_min )
                call sll_o_set_layout_i_max( layout, node, i_max )
                call sll_o_set_layout_j_min( layout, node, j_min )
                call sll_o_set_layout_j_max( layout, node, j_max )
                call sll_o_set_layout_k_min( layout, node, k_min )
                call sll_o_set_layout_k_max( layout, node, k_max )
                call sll_o_set_layout_l_min( layout, node, l_min )
                call sll_o_set_layout_l_max( layout, node, l_max )
             end do
          end do
       end do
    end do
    deallocate( intervals_x1, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1410 )

    deallocate( intervals_x2, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1411 )

    deallocate( intervals_x3, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1412 )

    deallocate( intervals_x4, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1413 )

  end subroutine initialize_layout_with_distributed_4D_array


  subroutine initialize_layout_with_distributed_5D_array( &
    global_npx1, &  
    global_npx2, &
    global_npx3, &
    global_npx4, &
    global_npx5, &
    num_proc_x1, &
    num_proc_x2, &
    num_proc_x3, &
    num_proc_x4, &
    num_proc_x5, &
    layout )
    
    ! sll_t_layout_5d should have been allocated with new(), which means that
    ! its memory is allocated in accordance with the size of collective.
    ! This should be error-checked below for consistency.
    integer(kind=i32), intent(in) :: global_npx1
    integer(kind=i32), intent(in) :: global_npx2
    integer(kind=i32), intent(in) :: global_npx3
    integer(kind=i32), intent(in) :: global_npx4
    integer(kind=i32), intent(in) :: global_npx5
    integer(kind=i32), intent(in) :: num_proc_x1
    integer(kind=i32), intent(in) :: num_proc_x2
    integer(kind=i32), intent(in) :: num_proc_x3
    integer(kind=i32), intent(in) :: num_proc_x4
    integer(kind=i32), intent(in) :: num_proc_x5

    type(sll_t_layout_5d), pointer :: layout
    integer(kind=i32) :: i
    integer(kind=i32) :: j
    integer(kind=i32) :: k
    integer(kind=i32) :: l
    integer(kind=i32) :: m
    integer(kind=i32) :: total_num_processors
    integer(kind=i32) :: node
    integer(kind=i32) :: collective_size
    integer(kind=i32) :: err
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x1
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x2
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x3
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x4
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x5
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max
    integer(kind=i32) :: m_min
    integer(kind=i32) :: m_max

    if( &
       .not. sll_f_is_power_of_two(int(num_proc_x1,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x2,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x3,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x4,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x5,i64)) ) then
       print *, 'ERROR: distribute_5D_array() needs that the integers that',&
            'describe the process mesh are powers of 2.'
       STOP
    end if

    if( &
       .not. (global_npx1 .gt. 0) .or. &
       .not. (global_npx2 .gt. 0) .or. &
       .not. (global_npx3 .gt. 0) .or. &
       .not. (global_npx4 .gt. 0) .or. &
       .not. (global_npx5 .gt. 0) ) then
       print *, 'ERROR: distribute_5D_array() needs that the array ', &
            'dimensions be greater than zero. Passed:', global_npx1, &
            global_npx2, global_npx3, global_npx4, global_npx5
       STOP
    end if

    layout%global_sz1 = global_npx1
    layout%global_sz2 = global_npx2
    layout%global_sz3 = global_npx3
    layout%global_sz4 = global_npx4
    layout%global_sz5 = global_npx5

    ! FIXME: add further error checking, like a minimum number of points
    ! needed given a processor number along a dimension. Also, num_proc_xi
    ! should be different than zero.
    allocate( intervals_x1(0:1,0:num_proc_x1-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1502)

    allocate( intervals_x2(0:1,0:num_proc_x2-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1503)

    allocate( intervals_x3(0:1,0:num_proc_x3-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1504)

    allocate( intervals_x4(0:1,0:num_proc_x4-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1505)

    allocate( intervals_x5(0:1,0:num_proc_x5-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1506)


    ! Allocate the layout to be returned.    
    total_num_processors = &
         num_proc_x1*num_proc_x2*num_proc_x3*num_proc_x4*num_proc_x5
    collective_size = get_layout_5D_size(layout)
    if( total_num_processors .ne. collective_size ) then
       print *, 'ERROR, initialize_layout_with_distributed_5D_array():', &
            'requested size of the processor mesh is inconsistent with ', &
            'the size of the collective.', 'number of processors = ', &
            total_num_processors, ' collective size = ', collective_size
       STOP
    end if

    ! Compute the arrays with the split index information along the different
    ! dimensions.
    intervals_x1(0:1,0:num_proc_x1-1) = &
         split_array_indices( 1, global_npx1, num_proc_x1 )

    intervals_x2(0:1,0:num_proc_x2-1) = &
         split_array_indices( 1, global_npx2, num_proc_x2 )

    intervals_x3(0:1,0:num_proc_x3-1) = &
         split_array_indices( 1, global_npx3, num_proc_x3 )

    intervals_x4(0:1,0:num_proc_x4-1) = &
         split_array_indices( 1, global_npx4, num_proc_x4 )

    intervals_x5(0:1,0:num_proc_x5-1) = &
         split_array_indices( 1, global_npx5, num_proc_x5 )

    ! Fill the layout array.
       do m=0, num_proc_x5-1
          do l=0, num_proc_x4-1
             do k=0, num_proc_x3-1
                do j=0, num_proc_x2-1
                   do i=0, num_proc_x1-1
                      node = linear_index_5D( &
                           num_proc_x1, &
                           num_proc_x2, &
                           num_proc_x3, &
                           num_proc_x4, &
                           i, &
                           j, &
                           k, &
                           l, &
                           m )
                      i_min = intervals_x1(0,i)
                      i_max = intervals_x1(1,i)
                      
                      j_min = intervals_x2(0,j)
                      j_max = intervals_x2(1,j)
                      
                      k_min = intervals_x3(0,k)
                      k_max = intervals_x3(1,k)
                      
                      l_min = intervals_x4(0,l)
                      l_max = intervals_x4(1,l)
                      
                      m_min = intervals_x5(0,m)
                      m_max = intervals_x5(1,m)
                                            
                      call sll_o_set_layout_i_min( layout, node, i_min )
                      call sll_o_set_layout_i_max( layout, node, i_max )
                      call sll_o_set_layout_j_min( layout, node, j_min )
                      call sll_o_set_layout_j_max( layout, node, j_max )
                      call sll_o_set_layout_k_min( layout, node, k_min )
                      call sll_o_set_layout_k_max( layout, node, k_max )
                      call sll_o_set_layout_l_min( layout, node, l_min )
                      call sll_o_set_layout_l_max( layout, node, l_max )
                      call sll_o_set_layout_m_min( layout, node, m_min )
                      call sll_o_set_layout_m_max( layout, node, m_max )
                   end do
                end do
             end do
          end do
       end do
    deallocate( intervals_x1, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1583 )

    deallocate( intervals_x2, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1584 )

    deallocate( intervals_x3, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1585 )

    deallocate( intervals_x4, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1586 )

    deallocate( intervals_x5, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1587 )

  end subroutine initialize_layout_with_distributed_5D_array



  subroutine initialize_layout_with_distributed_6D_array( &
    global_npx1, &  
    global_npx2, &
    global_npx3, &
    global_npx4, &
    global_npx5, &
    global_npx6, &
    num_proc_x1, &
    num_proc_x2, &
    num_proc_x3, &
    num_proc_x4, &
    num_proc_x5, &
    num_proc_x6, &
    layout )
    
    ! sll_t_layout_6d should have been allocated with new(), which means that
    ! its memory is allocated in accordance with the size of collective.
    ! This should be error-checked below for consistency.
    integer(kind=i32), intent(in) :: global_npx1
    integer(kind=i32), intent(in) :: global_npx2
    integer(kind=i32), intent(in) :: global_npx3
    integer(kind=i32), intent(in) :: global_npx4
    integer(kind=i32), intent(in) :: global_npx5
    integer(kind=i32), intent(in) :: global_npx6
    integer(kind=i32), intent(in) :: num_proc_x1
    integer(kind=i32), intent(in) :: num_proc_x2
    integer(kind=i32), intent(in) :: num_proc_x3
    integer(kind=i32), intent(in) :: num_proc_x4
    integer(kind=i32), intent(in) :: num_proc_x5
    integer(kind=i32), intent(in) :: num_proc_x6

    type(sll_t_layout_6d), pointer :: layout
    integer(kind=i32) :: i
    integer(kind=i32) :: j
    integer(kind=i32) :: k
    integer(kind=i32) :: l
    integer(kind=i32) :: m
    integer(kind=i32) :: n
    integer(kind=i32) :: total_num_processors
    integer(kind=i32) :: node
    integer(kind=i32) :: collective_size
    integer(kind=i32) :: err
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x1
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x2
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x3
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x4
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x5
    integer(kind=i32), dimension(:,:), allocatable :: intervals_x6
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max
    integer(kind=i32) :: m_min
    integer(kind=i32) :: m_max
    integer(kind=i32) :: n_min
    integer(kind=i32) :: n_max

    if( &
       .not. sll_f_is_power_of_two(int(num_proc_x1,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x2,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x3,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x4,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x5,i64)) .or. &
       .not. sll_f_is_power_of_two(int(num_proc_x6,i64)) ) then
       print *, 'ERROR: distribute_6D_array() needs that the integers that',&
            'describe the process mesh are powers of 2.'
       STOP
    end if

    if( &
       .not. (global_npx1 .gt. 0) .or. &
       .not. (global_npx2 .gt. 0) .or. &
       .not. (global_npx3 .gt. 0) .or. &
       .not. (global_npx4 .gt. 0) .or. &
       .not. (global_npx5 .gt. 0) .or. &
       .not. (global_npx6 .gt. 0) ) then
       print *, 'ERROR: distribute_6D_array() needs that the array ', &
            'dimensions be greater than zero. Passed:', global_npx1, &
            global_npx2, global_npx3, global_npx4, global_npx5, global_npx6
       STOP
    end if

    layout%global_sz1 = global_npx1
    layout%global_sz2 = global_npx2
    layout%global_sz3 = global_npx3
    layout%global_sz4 = global_npx4
    layout%global_sz5 = global_npx5
    layout%global_sz6 = global_npx6

    ! FIXME: add further error checking, like a minimum number of points
    ! needed given a processor number along a dimension. Also, num_proc_xi
    ! should be different than zero.
    allocate( intervals_x1(0:1,0:num_proc_x1-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1688)

    allocate( intervals_x2(0:1,0:num_proc_x2-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1689)

    allocate( intervals_x3(0:1,0:num_proc_x3-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1690)

    allocate( intervals_x4(0:1,0:num_proc_x4-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1691)

    allocate( intervals_x5(0:1,0:num_proc_x5-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1692)

    allocate( intervals_x6(0:1,0:num_proc_x6-1), stat= err )
 call sll_s_test_error_code( err , 'Memory allocation Failure.', "<stdin>", 1693)


    ! Allocate the layout to be returned.    
    total_num_processors = &
         num_proc_x1*num_proc_x2*num_proc_x3*num_proc_x4*num_proc_x5*num_proc_x6
    collective_size = get_layout_6D_size(layout)
    if( total_num_processors .ne. collective_size ) then
       print *, 'ERROR, initialize_layout_with_distributed_6D_array():', &
            'requested size of the processor mesh is inconsistent with ', &
            'the size of the collective.', 'number of processors = ', &
            total_num_processors, ' collective size = ', collective_size
       STOP
    end if

    ! Compute the arrays with the split index information along the different
    ! dimensions.
    intervals_x1(0:1,0:num_proc_x1-1) = &
         split_array_indices( 1, global_npx1, num_proc_x1 )

    intervals_x2(0:1,0:num_proc_x2-1) = &
         split_array_indices( 1, global_npx2, num_proc_x2 )

    intervals_x3(0:1,0:num_proc_x3-1) = &
         split_array_indices( 1, global_npx3, num_proc_x3 )

    intervals_x4(0:1,0:num_proc_x4-1) = &
         split_array_indices( 1, global_npx4, num_proc_x4 )

    intervals_x5(0:1,0:num_proc_x5-1) = &
         split_array_indices( 1, global_npx5, num_proc_x5 )

    intervals_x6(0:1,0:num_proc_x6-1) = &
         split_array_indices( 1, global_npx6, num_proc_x6 )

    ! Fill the layout array.
    do n=0, num_proc_x6-1
       do m=0, num_proc_x5-1
          do l=0, num_proc_x4-1
             do k=0, num_proc_x3-1
                do j=0, num_proc_x2-1
                   do i=0, num_proc_x1-1
                      node = linear_index_6D( &
                           num_proc_x1, &
                           num_proc_x2, &
                           num_proc_x3, &
                           num_proc_x4, &
                           num_proc_x5, &
                           i, &
                           j, &
                           k, &
                           l, &
                           m, &
                           n )
                      i_min = intervals_x1(0,i)
                      i_max = intervals_x1(1,i)
                      
                      j_min = intervals_x2(0,j)
                      j_max = intervals_x2(1,j)
                      
                      k_min = intervals_x3(0,k)
                      k_max = intervals_x3(1,k)
                      
                      l_min = intervals_x4(0,l)
                      l_max = intervals_x4(1,l)
                      
                      m_min = intervals_x5(0,m)
                      m_max = intervals_x5(1,m)
                      
                      n_min = intervals_x6(0,n)
                      n_max = intervals_x6(1,n)
                      
                      call sll_o_set_layout_i_min( layout, node, i_min )
                      call sll_o_set_layout_i_max( layout, node, i_max )
                      call sll_o_set_layout_j_min( layout, node, j_min )
                      call sll_o_set_layout_j_max( layout, node, j_max )
                      call sll_o_set_layout_k_min( layout, node, k_min )
                      call sll_o_set_layout_k_max( layout, node, k_max )
                      call sll_o_set_layout_l_min( layout, node, l_min )
                      call sll_o_set_layout_l_max( layout, node, l_max )
                      call sll_o_set_layout_m_min( layout, node, m_min )
                      call sll_o_set_layout_m_max( layout, node, m_max )
                      call sll_o_set_layout_n_min( layout, node, n_min )
                      call sll_o_set_layout_n_max( layout, node, n_max )
                   end do
                end do
             end do
          end do
       end do
    end do
    deallocate( intervals_x1, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1782 )

    deallocate( intervals_x2, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1783 )

    deallocate( intervals_x3, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1784 )

    deallocate( intervals_x4, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1785 )

    deallocate( intervals_x5, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1786 )

    deallocate( intervals_x6, stat= err )
 call sll_s_test_error_code( err , 'Failed array deallocation: ', "<stdin>", 1787 )

  end subroutine initialize_layout_with_distributed_6D_array

  function split_array_indices( min, max, num_intervals )
    integer(kind=i32), intent(in)                       :: num_intervals
    integer(kind=i32), dimension(0:1,0:num_intervals-1) :: split_array_indices
    integer(kind=i32), intent(in)                       :: min
    integer(kind=i32), intent(in)                       :: max
    integer(kind=i32)                                   :: num_elements
    num_elements = max - min + 1
    if( num_elements < num_intervals ) then
       print *, 'ERROR, split_array_indices(): the array given to split ', &
            'has less elements than the number of intervals requested. ', &
            'We have not implemented how to handle this case.'
       print *, 'number of elements: ', num_elements
       print *, 'number of intervals: ', num_intervals
       STOP 
    end if
    call split_array_indices_aux( &
      split_array_indices, &
      0, &
      num_intervals, &
      min, &
      max, &
      num_intervals )
  end function split_array_indices

  ! split_array_indices_aux() is an auxiliary function that splits a range
  ! of indices described by 2 integers into a given number of intervals, the
  ! function tries to partition the original interval equitably. 
  recursive subroutine split_array_indices_aux( &
    intervals_array, &
    start_index, &
    interval_segment_length, &
    min, &
    max, &
    total_intervals )

    integer(kind=i32), intent(in) :: total_intervals
    integer(kind=i32), intent(in) :: start_index
    integer(kind=i32), intent(in) :: interval_segment_length
    integer(kind=i32), intent(inout), dimension(0:1,0:total_intervals-1) :: &
         intervals_array
    integer(kind=i32), intent(in) :: min
    integer(kind=i32), intent(in) :: max
    integer(kind=i32) :: num_elems
    integer(kind=i32) :: new_min1
    integer(kind=i32) :: new_max1
    integer(kind=i32) :: new_min2
    integer(kind=i32) :: new_max2
    if( interval_segment_length .eq. 1 ) then
       ! terminate recursion by filling values for this interval
       intervals_array(0,start_index) = min
       intervals_array(1,start_index) = max
    else
       ! split this interval and launch new recursions
       num_elems = max - min + 1
       if( sll_f_is_even(num_elems) ) then
          new_min1 = min
          new_max1 = min + (max-min+1)/2 - 1
          new_min2 = new_max1 + 1
          new_max2 = max
       else
          new_min1 = min
          new_max1 = min + int((max-min+1)/2)
          new_min2 = new_max1 + 1
          new_max2 = max
       end if
       call split_array_indices_aux( &
          intervals_array, &
          start_index, &
          interval_segment_length/2, &
          new_min1, &
          new_max1, &
          total_intervals )
       call split_array_indices_aux( &
          intervals_array, &
          start_index + interval_segment_length/2, &
          interval_segment_length/2, &
          new_min2,  &
          new_max2,  &
          total_intervals )
    end if
  end subroutine split_array_indices_aux


  ! The sll_o_new_remap_plan() functions define the communication pattern in a 
  ! collective. From the perspective of an individual process, they examines
  ! the communication needs in a one-to-many and many-to-one sense. The
  ! plan produces information needed to feed a lower level function that
  ! will actually take care of the communications.
  !
  ! To achieve this, sll_o_new_remap_plan examines two things:
  ! - to whom does an individual process need to send its information, and
  ! - from whom does a process need to receive its information.
  ! Thus, while all processes make this call, the resulting plan will be
  ! different among the processes, but the plan will be consistent in terms 
  ! of which process is expecting what from whom.
  !
  ! The remap plan stores the buffers where the data to be sent/received
  ! are kept. This raises the issue of type dependence. We want to make this
  ! facility as general as possible. Here we try the approach of having a
  ! single, standard format for data storage, i.e. an integer. This means
  ! that we would need to use the transfer() function to store and retrieve
  ! data from the buffers, which is inefficient. The alternative is to
  ! have type-dependent plans...


  ! 2D remaps
  function new_remap_plan_2D_int32( initial, final, array )
 intrinsic :: associated
 type(remap_plan_2D_int32), pointer :: new_remap_plan_2D_int32
 type(sll_t_layout_2d), pointer :: initial
 type(sll_t_layout_2d), pointer :: final
  integer(kind=i32),  dimension(:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_2D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_2D_int32, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 allocate(new_remap_plan_2D_int32%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%send_displs(:) = 0
 allocate(new_remap_plan_2D_int32%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%send_counts(:) = 0
 allocate(new_remap_plan_2D_int32%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%recv_displs(:) = 0
 allocate(new_remap_plan_2D_int32%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%recv_counts(:) = 0
 allocate(new_remap_plan_2D_int32%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 allocate(new_remap_plan_2D_int32%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_2D_int32%initial_layout => initial
 new_remap_plan_2D_int32%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_2D_int32%send_counts(f) = send_counter
 new_remap_plan_2D_int32%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_2D_int32%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_2D_int32%send_counts(f) = 0
 new_remap_plan_2D_int32%send_displs(f) = disp_counter
 new_remap_plan_2D_int32%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_2D_int32%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_2D_int32%recv_counts(i) = recv_counter
 new_remap_plan_2D_int32%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_2D_int32%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_2D_int32%recv_counts(i) = 0
 new_remap_plan_2D_int32%recv_displs(i) = disp_counter
 new_remap_plan_2D_int32%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_2D_int32%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1983)

 new_remap_plan_2D_int32%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_2D_int32)
 end function new_remap_plan_2D_int32
  function new_remap_plan_2D_real64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_2d_real64), pointer :: new_remap_plan_2D_real64
 type(sll_t_layout_2d), pointer :: initial
 type(sll_t_layout_2d), pointer :: final
  real(kind=f64),  dimension(:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_2D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_2D_real64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 allocate(new_remap_plan_2D_real64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%send_displs(:) = 0
 allocate(new_remap_plan_2D_real64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%send_counts(:) = 0
 allocate(new_remap_plan_2D_real64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%recv_displs(:) = 0
 allocate(new_remap_plan_2D_real64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%recv_counts(:) = 0
 allocate(new_remap_plan_2D_real64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 allocate(new_remap_plan_2D_real64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_2D_real64%initial_layout => initial
 new_remap_plan_2D_real64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_2D_real64%send_counts(f) = send_counter
 new_remap_plan_2D_real64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_2D_real64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_2D_real64%send_counts(f) = 0
 new_remap_plan_2D_real64%send_displs(f) = disp_counter
 new_remap_plan_2D_real64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_2D_real64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_2D_real64%recv_counts(i) = recv_counter
 new_remap_plan_2D_real64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_2D_real64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_2D_real64%recv_counts(i) = 0
 new_remap_plan_2D_real64%recv_displs(i) = disp_counter
 new_remap_plan_2D_real64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_2D_real64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1984)

 new_remap_plan_2D_real64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_2D_real64)
 end function new_remap_plan_2D_real64
  function new_remap_plan_2D_comp64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_2d_comp64), pointer :: new_remap_plan_2D_comp64
 type(sll_t_layout_2d), pointer :: initial
 type(sll_t_layout_2d), pointer :: final
  complex(kind=f64),  dimension(:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_2D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_2D_comp64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 allocate(new_remap_plan_2D_comp64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%send_displs(:) = 0
 allocate(new_remap_plan_2D_comp64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%send_counts(:) = 0
 allocate(new_remap_plan_2D_comp64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%recv_displs(:) = 0
 allocate(new_remap_plan_2D_comp64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%recv_counts(:) = 0
 allocate(new_remap_plan_2D_comp64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 allocate(new_remap_plan_2D_comp64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_2D_comp64%initial_layout => initial
 new_remap_plan_2D_comp64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_2D_comp64%send_counts(f) = send_counter
 new_remap_plan_2D_comp64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_2D_comp64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_2D_comp64%send_counts(f) = 0
 new_remap_plan_2D_comp64%send_displs(f) = disp_counter
 new_remap_plan_2D_comp64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_2D_comp64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_2D_comp64%recv_counts(i) = recv_counter
 new_remap_plan_2D_comp64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_2D_comp64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_2D_comp64%recv_counts(i) = 0
 new_remap_plan_2D_comp64%recv_displs(i) = disp_counter
 new_remap_plan_2D_comp64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_2D_comp64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1985)

 new_remap_plan_2D_comp64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_2D_comp64)
 end function new_remap_plan_2D_comp64
  ! 3D remaps
  function new_remap_plan_3D_int32( initial, final, array )
 intrinsic :: associated
 type(remap_plan_3D_int32), pointer :: new_remap_plan_3D_int32
 type(sll_t_layout_3d), pointer :: initial
 type(sll_t_layout_3d), pointer :: final
  integer(kind=i32),  dimension(:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_3D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_3D_int32, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 allocate(new_remap_plan_3D_int32%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%send_displs(:) = 0
 allocate(new_remap_plan_3D_int32%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%send_counts(:) = 0
 allocate(new_remap_plan_3D_int32%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%recv_displs(:) = 0
 allocate(new_remap_plan_3D_int32%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%recv_counts(:) = 0
 allocate(new_remap_plan_3D_int32%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 allocate(new_remap_plan_3D_int32%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_3D_int32%initial_layout => initial
 new_remap_plan_3D_int32%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_3D_int32%send_counts(f) = send_counter
 new_remap_plan_3D_int32%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_3D_int32%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_3D_int32%send_counts(f) = 0
 new_remap_plan_3D_int32%send_displs(f) = disp_counter
 new_remap_plan_3D_int32%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_3D_int32%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_3D_int32%recv_counts(i) = recv_counter
 new_remap_plan_3D_int32%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_3D_int32%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_3D_int32%recv_counts(i) = 0
 new_remap_plan_3D_int32%recv_displs(i) = disp_counter
 new_remap_plan_3D_int32%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_3D_int32%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1987)

 new_remap_plan_3D_int32%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_3D_int32)
 end function new_remap_plan_3D_int32
  function new_remap_plan_3D_real64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_3d_real64), pointer :: new_remap_plan_3D_real64
 type(sll_t_layout_3d), pointer :: initial
 type(sll_t_layout_3d), pointer :: final
  real(kind=f64),  dimension(:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type( box_3D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_3D_real64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 allocate(new_remap_plan_3D_real64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%send_displs(:) = 0
 allocate(new_remap_plan_3D_real64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%send_counts(:) = 0
 allocate(new_remap_plan_3D_real64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%recv_displs(:) = 0
 allocate(new_remap_plan_3D_real64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%recv_counts(:) = 0
 allocate(new_remap_plan_3D_real64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 allocate(new_remap_plan_3D_real64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_3D_real64%initial_layout => initial
 new_remap_plan_3D_real64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_3D_real64%send_counts(f) = send_counter
 new_remap_plan_3D_real64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_3D_real64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_3D_real64%send_counts(f) = 0
 new_remap_plan_3D_real64%send_displs(f) = disp_counter
 new_remap_plan_3D_real64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_3D_real64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_3D_real64%recv_counts(i) = recv_counter
 new_remap_plan_3D_real64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_3D_real64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_3D_real64%recv_counts(i) = 0
 new_remap_plan_3D_real64%recv_displs(i) = disp_counter
 new_remap_plan_3D_real64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_3D_real64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1988)

 new_remap_plan_3D_real64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_3D_real64)
 end function new_remap_plan_3D_real64
  function new_remap_plan_3D_comp64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_3d_comp64), pointer :: new_remap_plan_3D_comp64
 type(sll_t_layout_3d), pointer :: initial
 type(sll_t_layout_3d), pointer :: final
  complex(kind=f64),  dimension(:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_3D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_3D_comp64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 allocate(new_remap_plan_3D_comp64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%send_displs(:) = 0
 allocate(new_remap_plan_3D_comp64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%send_counts(:) = 0
 allocate(new_remap_plan_3D_comp64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%recv_displs(:) = 0
 allocate(new_remap_plan_3D_comp64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%recv_counts(:) = 0
 allocate(new_remap_plan_3D_comp64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 allocate(new_remap_plan_3D_comp64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_3D_comp64%initial_layout => initial
 new_remap_plan_3D_comp64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_3D_comp64%send_counts(f) = send_counter
 new_remap_plan_3D_comp64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_3D_comp64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_3D_comp64%send_counts(f) = 0
 new_remap_plan_3D_comp64%send_displs(f) = disp_counter
 new_remap_plan_3D_comp64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_3D_comp64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_3D_comp64%recv_counts(i) = recv_counter
 new_remap_plan_3D_comp64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_3D_comp64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_3D_comp64%recv_counts(i) = 0
 new_remap_plan_3D_comp64%recv_displs(i) = disp_counter
 new_remap_plan_3D_comp64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_3D_comp64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1989)

 new_remap_plan_3D_comp64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_3D_comp64)
 end function new_remap_plan_3D_comp64
  ! 4D remaps
  function new_remap_plan_4D_int32( initial, final, array )
 intrinsic :: associated
 type(remap_plan_4D_int32), pointer :: new_remap_plan_4D_int32
 type(sll_t_layout_4d), pointer :: initial
 type(sll_t_layout_4d), pointer :: final
  integer(kind=i32),  dimension(:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_4D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_4D_int32, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 allocate(new_remap_plan_4D_int32%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%send_displs(:) = 0
 allocate(new_remap_plan_4D_int32%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%send_counts(:) = 0
 allocate(new_remap_plan_4D_int32%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%recv_displs(:) = 0
 allocate(new_remap_plan_4D_int32%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%recv_counts(:) = 0
 allocate(new_remap_plan_4D_int32%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 allocate(new_remap_plan_4D_int32%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_4D_int32%initial_layout => initial
 new_remap_plan_4D_int32%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_4D_int32%send_counts(f) = send_counter
 new_remap_plan_4D_int32%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_4D_int32%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_4D_int32%send_counts(f) = 0
 new_remap_plan_4D_int32%send_displs(f) = disp_counter
 new_remap_plan_4D_int32%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_4D_int32%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_4D_int32%recv_counts(i) = recv_counter
 new_remap_plan_4D_int32%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_4D_int32%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_4D_int32%recv_counts(i) = 0
 new_remap_plan_4D_int32%recv_displs(i) = disp_counter
 new_remap_plan_4D_int32%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_4D_int32%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1991)

 new_remap_plan_4D_int32%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_4D_int32)
 end function new_remap_plan_4D_int32
  function new_remap_plan_4D_real64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_4d_real64), pointer :: new_remap_plan_4D_real64
 type(sll_t_layout_4d), pointer :: initial
 type(sll_t_layout_4d), pointer :: final
  real(kind=f64),  dimension(:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_4D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_4D_real64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 allocate(new_remap_plan_4D_real64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%send_displs(:) = 0
 allocate(new_remap_plan_4D_real64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%send_counts(:) = 0
 allocate(new_remap_plan_4D_real64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%recv_displs(:) = 0
 allocate(new_remap_plan_4D_real64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%recv_counts(:) = 0
 allocate(new_remap_plan_4D_real64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 allocate(new_remap_plan_4D_real64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_4D_real64%initial_layout => initial
 new_remap_plan_4D_real64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_4D_real64%send_counts(f) = send_counter
 new_remap_plan_4D_real64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_4D_real64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_4D_real64%send_counts(f) = 0
 new_remap_plan_4D_real64%send_displs(f) = disp_counter
 new_remap_plan_4D_real64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_4D_real64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_4D_real64%recv_counts(i) = recv_counter
 new_remap_plan_4D_real64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_4D_real64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_4D_real64%recv_counts(i) = 0
 new_remap_plan_4D_real64%recv_displs(i) = disp_counter
 new_remap_plan_4D_real64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_4D_real64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1992)

 new_remap_plan_4D_real64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_4D_real64)
 end function new_remap_plan_4D_real64
  function new_remap_plan_4D_comp64( initial, final, array )
 intrinsic :: associated
 type(remap_plan_4D_comp64), pointer :: new_remap_plan_4D_comp64
 type(sll_t_layout_4d), pointer :: initial
 type(sll_t_layout_4d), pointer :: final
  complex(kind=f64),  dimension(:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_4D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_4D_comp64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 allocate(new_remap_plan_4D_comp64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%send_displs(:) = 0
 allocate(new_remap_plan_4D_comp64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%send_counts(:) = 0
 allocate(new_remap_plan_4D_comp64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%recv_displs(:) = 0
 allocate(new_remap_plan_4D_comp64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%recv_counts(:) = 0
 allocate(new_remap_plan_4D_comp64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 allocate(new_remap_plan_4D_comp64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_4D_comp64%initial_layout => initial
 new_remap_plan_4D_comp64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_4D_comp64%send_counts(f) = send_counter
 new_remap_plan_4D_comp64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_4D_comp64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_4D_comp64%send_counts(f) = 0
 new_remap_plan_4D_comp64%send_displs(f) = disp_counter
 new_remap_plan_4D_comp64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_4D_comp64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_4D_comp64%recv_counts(i) = recv_counter
 new_remap_plan_4D_comp64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_4D_comp64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_4D_comp64%recv_counts(i) = 0
 new_remap_plan_4D_comp64%recv_displs(i) = disp_counter
 new_remap_plan_4D_comp64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_4D_comp64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1993)

 new_remap_plan_4D_comp64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_4D_comp64)
 end function new_remap_plan_4D_comp64
  ! 5D remaps
  function new_remap_plan_5D_int32( initial, final, array )
 intrinsic :: associated
 type(remap_plan_5D_int32), pointer :: new_remap_plan_5D_int32
 type(sll_t_layout_5d), pointer :: initial
 type(sll_t_layout_5d), pointer :: final
  integer(kind=i32),  dimension(:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_5D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_5D_int32, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 allocate(new_remap_plan_5D_int32%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%send_displs(:) = 0
 allocate(new_remap_plan_5D_int32%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%send_counts(:) = 0
 allocate(new_remap_plan_5D_int32%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%recv_displs(:) = 0
 allocate(new_remap_plan_5D_int32%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%recv_counts(:) = 0
 allocate(new_remap_plan_5D_int32%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 allocate(new_remap_plan_5D_int32%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_5D_int32%initial_layout => initial
 new_remap_plan_5D_int32%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_5D_int32%send_counts(f) = send_counter
 new_remap_plan_5D_int32%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_5D_int32%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_5D_int32%send_counts(f) = 0
 new_remap_plan_5D_int32%send_displs(f) = disp_counter
 new_remap_plan_5D_int32%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_5D_int32%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_5D_int32%recv_counts(i) = recv_counter
 new_remap_plan_5D_int32%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_5D_int32%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_5D_int32%recv_counts(i) = 0
 new_remap_plan_5D_int32%recv_displs(i) = disp_counter
 new_remap_plan_5D_int32%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_5D_int32%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1995)

 new_remap_plan_5D_int32%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_5D_int32)
 end function new_remap_plan_5D_int32
  function new_remap_plan_5D_real64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_5d_real64), pointer :: new_remap_plan_5D_real64
 type(sll_t_layout_5d), pointer :: initial
 type(sll_t_layout_5d), pointer :: final
  real(kind=f64),  dimension(:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_5D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_5D_real64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 allocate(new_remap_plan_5D_real64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%send_displs(:) = 0
 allocate(new_remap_plan_5D_real64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%send_counts(:) = 0
 allocate(new_remap_plan_5D_real64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%recv_displs(:) = 0
 allocate(new_remap_plan_5D_real64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%recv_counts(:) = 0
 allocate(new_remap_plan_5D_real64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 allocate(new_remap_plan_5D_real64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_5D_real64%initial_layout => initial
 new_remap_plan_5D_real64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_5D_real64%send_counts(f) = send_counter
 new_remap_plan_5D_real64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_5D_real64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_5D_real64%send_counts(f) = 0
 new_remap_plan_5D_real64%send_displs(f) = disp_counter
 new_remap_plan_5D_real64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_5D_real64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_5D_real64%recv_counts(i) = recv_counter
 new_remap_plan_5D_real64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_5D_real64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_5D_real64%recv_counts(i) = 0
 new_remap_plan_5D_real64%recv_displs(i) = disp_counter
 new_remap_plan_5D_real64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_5D_real64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1996)

 new_remap_plan_5D_real64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_5D_real64)
 end function new_remap_plan_5D_real64
  function new_remap_plan_5D_comp64( initial, final, array )
 intrinsic :: associated
 type(remap_plan_5D_comp64), pointer :: new_remap_plan_5D_comp64
 type(sll_t_layout_5d), pointer :: initial
 type(sll_t_layout_5d), pointer :: final
  complex(kind=f64),  dimension(:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_5D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_5D_comp64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 allocate(new_remap_plan_5D_comp64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%send_displs(:) = 0
 allocate(new_remap_plan_5D_comp64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%send_counts(:) = 0
 allocate(new_remap_plan_5D_comp64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%recv_displs(:) = 0
 allocate(new_remap_plan_5D_comp64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%recv_counts(:) = 0
 allocate(new_remap_plan_5D_comp64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 allocate(new_remap_plan_5D_comp64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_5D_comp64%initial_layout => initial
 new_remap_plan_5D_comp64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_5D_comp64%send_counts(f) = send_counter
 new_remap_plan_5D_comp64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_5D_comp64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_5D_comp64%send_counts(f) = 0
 new_remap_plan_5D_comp64%send_displs(f) = disp_counter
 new_remap_plan_5D_comp64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_5D_comp64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_5D_comp64%recv_counts(i) = recv_counter
 new_remap_plan_5D_comp64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_5D_comp64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_5D_comp64%recv_counts(i) = 0
 new_remap_plan_5D_comp64%recv_displs(i) = disp_counter
 new_remap_plan_5D_comp64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_5D_comp64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1997)

 new_remap_plan_5D_comp64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_5D_comp64)
 end function new_remap_plan_5D_comp64
  ! 6D remaps
  function new_remap_plan_6D_int32( initial, final, array )
 intrinsic :: associated
 type(remap_plan_6D_int32), pointer :: new_remap_plan_6D_int32
 type(sll_t_layout_6d), pointer :: initial
 type(sll_t_layout_6d), pointer :: final
  integer(kind=i32),  dimension(:,:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_6D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_6D_int32, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 allocate(new_remap_plan_6D_int32%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%send_displs(:) = 0
 allocate(new_remap_plan_6D_int32%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%send_counts(:) = 0
 allocate(new_remap_plan_6D_int32%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%recv_displs(:) = 0
 allocate(new_remap_plan_6D_int32%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%recv_counts(:) = 0
 allocate(new_remap_plan_6D_int32%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 allocate(new_remap_plan_6D_int32%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_6D_int32%initial_layout => initial
 new_remap_plan_6D_int32%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_6D_int32%send_counts(f) = send_counter
 new_remap_plan_6D_int32%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_6D_int32%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_6D_int32%send_counts(f) = 0
 new_remap_plan_6D_int32%send_displs(f) = disp_counter
 new_remap_plan_6D_int32%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_6D_int32%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_6D_int32%recv_counts(i) = recv_counter
 new_remap_plan_6D_int32%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_6D_int32%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_6D_int32%recv_counts(i) = 0
 new_remap_plan_6D_int32%recv_displs(i) = disp_counter
 new_remap_plan_6D_int32%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_6D_int32%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 1999)

 new_remap_plan_6D_int32%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_6D_int32)
 end function new_remap_plan_6D_int32
  function new_remap_plan_6D_real64( initial, final, array )
 intrinsic :: associated
 type(sll_t_remap_plan_6d_real64), pointer :: new_remap_plan_6D_real64
 type(sll_t_layout_6d), pointer :: initial
 type(sll_t_layout_6d), pointer :: final
  real(kind=f64),  dimension(:,:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_6D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_6D_real64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 allocate(new_remap_plan_6D_real64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%send_displs(:) = 0
 allocate(new_remap_plan_6D_real64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%send_counts(:) = 0
 allocate(new_remap_plan_6D_real64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%recv_displs(:) = 0
 allocate(new_remap_plan_6D_real64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%recv_counts(:) = 0
 allocate(new_remap_plan_6D_real64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 allocate(new_remap_plan_6D_real64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_6D_real64%initial_layout => initial
 new_remap_plan_6D_real64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_6D_real64%send_counts(f) = send_counter
 new_remap_plan_6D_real64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_6D_real64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_6D_real64%send_counts(f) = 0
 new_remap_plan_6D_real64%send_displs(f) = disp_counter
 new_remap_plan_6D_real64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_6D_real64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_6D_real64%recv_counts(i) = recv_counter
 new_remap_plan_6D_real64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_6D_real64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_6D_real64%recv_counts(i) = 0
 new_remap_plan_6D_real64%recv_displs(i) = disp_counter
 new_remap_plan_6D_real64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_6D_real64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2000)

 new_remap_plan_6D_real64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_6D_real64)
 end function new_remap_plan_6D_real64
  function new_remap_plan_6D_comp64( initial, final, array )
 intrinsic :: associated
 type(remap_plan_6D_comp64), pointer :: new_remap_plan_6D_comp64
 type(sll_t_layout_6d), pointer :: initial
 type(sll_t_layout_6d), pointer :: final
  complex(kind=f64),  dimension(:,:,:,:,:,:)  :: array
 type(sll_t_collective_t), pointer :: coli
 type(sll_t_collective_t), pointer :: colf
 type(box_6D) :: ibox, fbox, inters
 integer(kind=i32) :: i, f
 integer(kind=i32) :: my_rank
 integer(kind=i32) :: col_size
 integer(kind=i32) :: ierr
 integer(kind=i32) :: disp_counter
 integer(kind=i32) :: send_counter
 integer(kind=i32) :: recv_counter
 integer(kind=i64) :: acc
 if( (.not. associated(initial)) .or. (.not. associated(final)) ) then
 print *, 'ERROR: un-initialized arguments given to sll_new_remap_plan'
 print *, size(array)
 stop
 end if
 coli => sll_o_get_layout_collective(initial)
 colf => sll_o_get_layout_collective(final)
 if( .not. sll_f_collectives_are_same( coli, colf ) ) then
 print *, 'ERROR: init and final configurations given to sll_o_new_remap_plan do not refer to the same collective.'
 stop
 end if
 acc = 0
 coli => sll_o_get_layout_collective(initial)
 my_rank = sll_f_get_collective_rank( coli )
 col_size = sll_f_get_collective_size( coli )
 allocate(new_remap_plan_6D_comp64, stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 allocate(new_remap_plan_6D_comp64%send_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%send_displs(:) = 0
 allocate(new_remap_plan_6D_comp64%send_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%send_counts(:) = 0
 allocate(new_remap_plan_6D_comp64%recv_displs(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%recv_displs(:) = 0
 allocate(new_remap_plan_6D_comp64%recv_counts(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%recv_counts(:) = 0
 allocate(new_remap_plan_6D_comp64%send_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 allocate(new_remap_plan_6D_comp64%recv_boxes(0:col_size-1), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%collective => sll_o_get_layout_collective(initial)
 send_counter = 0
 disp_counter = 0
 ibox = get_layout_box(initial, my_rank)
 new_remap_plan_6D_comp64%initial_layout => initial
 new_remap_plan_6D_comp64%final_layout => final
 do f = 0, col_size-1
 fbox = get_layout_box(final, f)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 send_counter = count_elements_in_box(inters)
 new_remap_plan_6D_comp64%send_counts(f) = send_counter
 new_remap_plan_6D_comp64%send_displs(f) = disp_counter
 disp_counter = disp_counter + send_counter
 new_remap_plan_6D_comp64%send_boxes(f) = inters
 acc = acc + send_counter
 else
 new_remap_plan_6D_comp64%send_counts(f) = 0
 new_remap_plan_6D_comp64%send_displs(f) = disp_counter
 new_remap_plan_6D_comp64%send_boxes(f) = inters
 end if
 end do
 allocate(new_remap_plan_6D_comp64%send_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 acc = 0
 disp_counter = 0
 fbox = get_layout_box(final, my_rank)
 do i = 0, col_size-1
 ibox = get_layout_box(initial,i)
 if( intersect_boxes( ibox, fbox, inters ) ) then
 recv_counter = count_elements_in_box(inters)
 new_remap_plan_6D_comp64%recv_counts(i) = recv_counter
 new_remap_plan_6D_comp64%recv_displs(i) = disp_counter
 disp_counter = disp_counter + recv_counter
 new_remap_plan_6D_comp64%recv_boxes(i) = inters
 acc = acc + recv_counter
 else
 new_remap_plan_6D_comp64%recv_counts(i) = 0
 new_remap_plan_6D_comp64%recv_displs(i) = disp_counter
 new_remap_plan_6D_comp64%recv_boxes(i) = inters
 end if
 end do
 allocate(new_remap_plan_6D_comp64%recv_buffer(0:(acc-1)), stat=ierr)
 call sll_s_test_error_code(ierr, 'Memory allocation Failure.', "<stdin>", 2001)

 new_remap_plan_6D_comp64%is_uniform = .false.
 call optimize_remap_plan(new_remap_plan_6D_comp64)
 end function new_remap_plan_6D_comp64


 ! Try to fix the name of the subroutine in the print statement by stringifying
 ! the name.


 subroutine  delete_remap_2D_int32( plan )
 type( remap_plan_2D_int32 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2025)
 nullify(plan)

 end subroutine  delete_remap_2D_int32
 subroutine  delete_remap_2D_real64( plan )
 type( sll_t_remap_plan_2d_real64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2026)
 nullify(plan)

 end subroutine  delete_remap_2D_real64
 subroutine  delete_remap_2D_comp64( plan )
 type( sll_t_remap_plan_2d_comp64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2027)
 nullify(plan)

 end subroutine  delete_remap_2D_comp64
 subroutine  delete_remap_3D_int32( plan )
 type( remap_plan_3D_int32 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2028)
 nullify(plan)

 end subroutine  delete_remap_3D_int32
 subroutine  delete_remap_3D_real64( plan )
 type( sll_t_remap_plan_3d_real64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2029)
 nullify(plan)

 end subroutine  delete_remap_3D_real64
 subroutine  delete_remap_3D_comp64( plan )
 type( sll_t_remap_plan_3d_comp64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2030)
 nullify(plan)

 end subroutine  delete_remap_3D_comp64
 subroutine  delete_remap_4D_int32( plan )
 type( remap_plan_4D_int32 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2031)
 nullify(plan)

 end subroutine  delete_remap_4D_int32
 subroutine  delete_remap_4D_real64( plan )
 type( sll_t_remap_plan_4d_real64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2032)
 nullify(plan)

 end subroutine  delete_remap_4D_real64
 subroutine  delete_remap_4D_comp64( plan )
 type( remap_plan_4D_comp64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2033)
 nullify(plan)

 end subroutine  delete_remap_4D_comp64
 subroutine  delete_remap_5D_int32( plan )
 type( remap_plan_5D_int32 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2034)
 nullify(plan)

 end subroutine  delete_remap_5D_int32
 subroutine  delete_remap_5D_real64( plan )
 type( sll_t_remap_plan_5d_real64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2035)
 nullify(plan)

 end subroutine  delete_remap_5D_real64
 subroutine  delete_remap_5D_comp64( plan )
 type( remap_plan_5D_comp64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2036)
 nullify(plan)

 end subroutine  delete_remap_5D_comp64
 subroutine  delete_remap_6D_int32( plan )
 type( remap_plan_6D_int32 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2037)
 nullify(plan)

 end subroutine  delete_remap_6D_int32
 subroutine  delete_remap_6D_real64( plan )
 type( sll_t_remap_plan_6d_real64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2038)
 nullify(plan)

 end subroutine  delete_remap_6D_real64
 subroutine  delete_remap_6D_comp64( plan )
 type( remap_plan_6D_comp64 ), pointer :: plan
 integer(kind=i32) :: ierr
 if( .not. associated(plan) ) then
 print *, 'ERROR, delete_remap_plan(): passed plan was not associated.'
 stop
 end if
 deallocate(plan%send_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%send_displs)

 deallocate(plan%send_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%send_counts)

 deallocate(plan%recv_displs, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%recv_displs)

 deallocate(plan%recv_counts, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%recv_counts)

 deallocate(plan%send_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%send_boxes)

 deallocate(plan%recv_boxes, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%recv_boxes)

 deallocate(plan%send_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%send_buffer)

 deallocate(plan%recv_buffer, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan%recv_buffer)

 deallocate(plan, stat=ierr)
 call sll_s_test_error_code(ierr, 'Error in memory deallocation.', "<stdin>", 2039)
 nullify(plan)

 end subroutine  delete_remap_6D_comp64



  ! The optimizer function is stand-alone. It may be used just
  ! before exiting the new_remap_plan_3D function.
  ! 
  ! The main idea behind the optimizations is the following: 
  ! An unoptimized remap plan is just a call to alltoallV() on a (possibly
  ! very large) communicator. This is concise, but inefficient. For a 
  ! given remapping operation, the re-arrangement of data will 
  ! normally only require communications between subsets of processes 
  ! within this communicator. The optimizer function thus has several 
  ! optimization opportunities:
  !
  ! 1. The first level of optimizations is to identify the subsets of 
  !    processes that communicate with one another, and then launch the
  !    alltoallV() call on this new (hopefully much smaller) communicator.
  ! 2. The second level of optimizations involves identifying those calls to
  !    alltoallV() which exhibit a regular pattern and than can be replaced
  !    by a call to alltoall(), which gives the implementors of the 
  !    communications libraries better optimization opportunities.
  ! 3. The last level of optimization is to simplify the loading of the
  !    send buffers whenever possible.
  !
  ! First optimization level:
  !
  ! We use an algorithm that works as follows:
  ! Every process is aware of the ranks of the processes with which it is
  ! supposed to directly exchange data. This permits the following steps:
  ! a. every process allocates an array of length 'collective_size'
  ! b. each process will figure out the ranks of the processes with which it
  !    communicates (send or receive), and will find the one with the lowest 
  !    rank ( hereafter denominated 'lowest_rank' ) and will set:
  !            array(my_rank) = lowest_rank 
  ! c. the array is shared between all processes with an allgather() operation.
  ! d. we save a copy of this array.
  ! e. then, each process will inspect the fields 'array(i)' of this array that 
  !    correspond to the ranks with which this process is supposed to exchange
  !    (send or receive) any data. The process will find the lowest value and
  !    will set     array(my_rank) = lowest_value.
  ! f. compare with the stored version of this array. If there was no change,
  !    we are done.
  ! g. else, repeat the process starting from d.
  ! h. Split new collectives using array(my_rank) as the color. These are
  !    the sub-collectives that we were looking for.
  !
  ! This algorithm will be able to sort out through complicated communication
  ! patterns where the exchanges are asymmetric.
  !
  ! The optimized plan also compresses the 'box' arrays that store the 
  ! information on the data that is to be sent/received, as well as the 
  ! send_counts and displacements...  This introduces a
  ! problem: The optimized plan has a notion of a reduced collective, as well
  ! as compressed box arrays, but will still need the 'global' information
  ! about the layouts, since the sll_o_global_to_local function only has meaning 
  ! in the context of the global layout. I find this 'mixing' very unpleasant, 
  ! and it might invite confusing those two collectives (the parent and the
  ! reduced), for now see no clean & easy way to fix this. Fortunately, at 
  ! least, the reference to the larger collective is hidden inside the 'layout' 
  ! information and used only by 'sll_o_global_to_local()'.





!-------------------------------------------------------------------------------

subroutine  optimize_remap_plan_2D_int32( plan )
 type( remap_plan_2D_int32), pointer :: plan
 type( box_2D ), dimension(:), pointer :: new_send_boxes
 type( box_2D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_2D_real64( plan )
 type( sll_t_remap_plan_2d_real64), pointer :: plan
 type(box_2D ), dimension(:), pointer :: new_send_boxes
 type(box_2D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_2D_comp64( plan )
 type( sll_t_remap_plan_2d_comp64), pointer :: plan
 type(box_2D ), dimension(:), pointer :: new_send_boxes
 type(box_2D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_3D_int32( plan )
 type( remap_plan_3D_int32), pointer :: plan
 type(box_3D ), dimension(:), pointer :: new_send_boxes
 type(box_3D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_3D_real64( plan )
 type( sll_t_remap_plan_3d_real64), pointer :: plan
 type( box_3D ), dimension(:), pointer :: new_send_boxes
 type( box_3D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_3D_comp64( plan )
 type( sll_t_remap_plan_3d_comp64), pointer :: plan
 type( box_3D ), dimension(:), pointer :: new_send_boxes
 type( box_3D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_4D_int32( plan )
 type( remap_plan_4D_int32), pointer :: plan
 type( box_4D ), dimension(:), pointer :: new_send_boxes
 type( box_4D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_4D_real64( plan )
 type( sll_t_remap_plan_4d_real64), pointer :: plan
 type( box_4D ), dimension(:), pointer :: new_send_boxes
 type( box_4D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_4D_comp64( plan )
 type( remap_plan_4D_comp64), pointer :: plan
 type( box_4D ), dimension(:), pointer :: new_send_boxes
 type( box_4D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_5D_int32( plan )
 type( remap_plan_5D_int32), pointer :: plan
 type( box_5D ), dimension(:), pointer :: new_send_boxes
 type( box_5D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine

  
subroutine  optimize_remap_plan_5D_real64( plan )
 type( sll_t_remap_plan_5d_real64), pointer :: plan
 type( box_5D ), dimension(:), pointer :: new_send_boxes
 type( box_5D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_5D_comp64( plan )
 type( remap_plan_5D_comp64), pointer :: plan
 type( box_5D ), dimension(:), pointer :: new_send_boxes
 type( box_5D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_6D_int32( plan )
 type( remap_plan_6D_int32), pointer :: plan
 type( box_6D ), dimension(:), pointer :: new_send_boxes
 type( box_6D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_6D_real64( plan )
 type( sll_t_remap_plan_6d_real64), pointer :: plan
 type( box_6D ), dimension(:), pointer :: new_send_boxes
 type( box_6D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine


subroutine  optimize_remap_plan_6D_comp64( plan )
 type( remap_plan_6D_comp64), pointer :: plan
 type( box_6D ), dimension(:), pointer :: new_send_boxes
 type( box_6D ), dimension(:), pointer :: new_recv_boxes


 integer(kind=i32), dimension(:), pointer     :: send_counts
 integer(kind=i32), dimension(:), pointer     :: send_displs
 integer(kind=i32), dimension(:), pointer     :: recv_counts
 integer(kind=i32), dimension(:), pointer     :: recv_displs
 type(sll_t_collective_t), pointer    :: col
 integer(kind=i32)                            :: col_sz
 integer(kind=i32), dimension(:), allocatable :: lowest_color
 integer(kind=i32), dimension(:), allocatable :: colors
 integer(kind=i32), dimension(:), allocatable :: colors_copy
 integer(kind=i32)                            :: ierr
 integer(kind=i32)                            :: my_rank
 integer(kind=i32)                            :: i
 type(sll_t_collective_t), pointer    :: new_collective
 integer(kind=i32)                            :: new_col_sz
 integer(kind=i32), dimension(:), pointer     :: new_send_counts
 integer(kind=i32), dimension(:), pointer     :: new_send_displs
 integer(kind=i32), dimension(:), pointer     :: new_recv_counts
 integer(kind=i32), dimension(:), pointer     :: new_recv_displs
 integer(kind=i32)                            :: new_i
 integer(kind=i32)                            :: my_color
 integer(kind=i32)                            :: exchange_size_s
 integer(kind=i32)                            :: exchange_size_r
 logical, dimension(1:1)              :: is_uniform_local
 logical, dimension(1:1)              :: is_uniform_collective
 integer(kind=i32)                            :: new_sdisp
 integer(kind=i32)                            :: new_rdisp
 
 col         => plan%collective
 col_sz      = sll_f_get_collective_size( col )
 my_rank     = sll_f_get_collective_rank( col )
 send_counts => plan%send_counts
 send_displs => plan%send_displs
 recv_counts => plan%recv_counts
 recv_displs => plan%recv_displs
 allocate( lowest_color(1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 35)

 lowest_color(1) = 0
 allocate( colors(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 37)

 colors(:) = 0
 allocate( colors_copy(0:col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 39)

 colors_copy(:) = 0
 
 ! FIRST LEVEL OF OPTIMIZATION: 
 ! Identify the sub-collectives in which the communication should 
 ! be divided. The purpose is to subdivide the original communicator
 ! into multiple communicators, each one minimally sized, but meeting
 ! the condition that each process belongs to a single communicator.
 ! In some situations, this could lead to cases in which two processes
 ! can belong to a communicator even though they do not exchange data
 ! amongst themselves directly, but need to exchange data with a
 ! third process. Even this situation might still not be necessarily
 ! slower, than having the split communicators, and here we have much
 ! simpler code.
 
 ! we want a starting point. This should not change for the lowest ranks 
 ! in the sub-collectives.
 lowest_color(1) = my_rank
 call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
 do
    ! Load the copy
    colors_copy(0:col_sz-1) = colors(0:col_sz-1)
    ! Find the lowest rank with which this process communicates
    do i=0,col_sz-1
       if( (send_counts(i) .ne. 0) .or. (recv_counts(i) .ne. 0) ) then
          if( colors(i) .lt. lowest_color(1) ) then
             lowest_color(1) = colors(i)
          end if ! else, nothing, as lowest_color is already my_rank
       end if
    end do
    ! Gather the information from all processes
    call sll_o_collective_allgather(col,lowest_color,1,colors(0:col_sz-1),1)
    if(arrays_are_equal(colors, colors_copy, col_sz)) then
       exit
    end if
 end do
 ! The results can now be used as the color for a collective-splitting 
 ! operation.
 new_collective => sll_f_new_collective( col, colors(my_rank), my_rank )
 new_col_sz     = sll_f_get_collective_size( new_collective )
 ! Allocate the new counters and displacements with the reduced 
 ! collective size.
 allocate( new_send_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 81)

 allocate( new_send_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 82)

 allocate( new_recv_counts(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 83)

 allocate( new_recv_displs(0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 84)

 allocate( new_send_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 85)

 allocate( new_recv_boxes( 0:new_col_sz-1), stat= ierr )
 call sll_s_test_error_code( ierr , 'Memory allocation Failure.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 86)

 ! Compress the 'send' and 'receive' information
 new_i = 0
 my_color = colors(my_rank)
 new_sdisp = 0
 new_rdisp = 0
 do i=0,col_sz-1
    if( colors(i) .eq. my_color ) then
       new_send_counts(new_i) = send_counts(i)
       new_send_displs(new_i) = new_sdisp
       new_send_boxes(new_i)  = plan%send_boxes(i)
       new_sdisp              = new_sdisp + send_counts(i)
       new_recv_counts(new_i) = recv_counts(i)
       new_recv_displs(new_i) = new_rdisp
       new_recv_boxes(new_i)  = plan%recv_boxes(i)
       new_rdisp              = new_rdisp + recv_counts(i)
       new_i                  = new_i + 1
    end if
 end do
 ! Change the fields of the plan to reflect the new:
 ! - collective,
 ! - send_counts,
 ! - send_displs,
 ! - recv_counts,
 ! - recv_displs,
 ! - send_boxes, and
 ! - recv_boxes.
 ! The send/receive buffers remain unchanged. Watch out for possible
 ! memory leaks...
 plan%collective => new_collective
 deallocate( plan%send_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 116)
 nullify( plan%send_counts)

 plan%send_counts => new_send_counts
 deallocate( plan%send_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 118)
 nullify( plan%send_displs)

 plan%send_displs => new_send_displs
 deallocate( plan%recv_counts, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 120)
 nullify( plan%recv_counts)

 plan%recv_counts => new_recv_counts
 deallocate( plan%recv_displs, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 122)
 nullify( plan%recv_displs)

 plan%recv_displs => new_recv_displs
 deallocate( plan%send_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 124)
 nullify( plan%send_boxes)

 plan%send_boxes => new_send_boxes
 deallocate( plan%recv_boxes, stat= ierr )
 call sll_s_test_error_code( ierr , 'Error in memory deallocation.', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 126)
 nullify( plan%recv_boxes)

 plan%recv_boxes => new_recv_boxes
 deallocate( lowest_color, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 128 )

 deallocate( colors, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 129 )

 deallocate( colors_copy, stat= ierr )
 call sll_s_test_error_code( ierr , 'Failed array deallocation: ', "/Users/navaro/Codes/selalib/src/parallelization/remap/sll_k_make_remap_optimizer.F90", 130 )

 

 ! SECOND LEVEL OF OPTIMIZATION:
 ! Identify whether the communication in the local collective is regular,
 ! thus permitting a call to alltoall(). Note that it is not sufficient
 ! to detect whether the exchange looks regular locally, all processes
 ! in the communicator must agree in this view.

 ! First we initialize "is_uniform_local" to .true. It will become false if
 ! one count does not agree
 is_uniform_local = .true.
 exchange_size_s = plan%send_counts(0)
 do i=0,new_col_sz-1
    if(plan%send_counts(i) .eq. exchange_size_s) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else ! plan%send_counts(i) is different than the first value
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 exchange_size_r = plan%recv_counts(0)
 do i=0,new_col_sz-1
    if(plan%recv_counts(i) .eq. exchange_size_r) then
       is_uniform_local(1) = is_uniform_local(1) .and. .true.
    else
       is_uniform_local(1) = is_uniform_local(1) .and. .false.
       exit
    end if
 end do
 ! Use a reduction operation to find out if this result is shared with 
 ! the other processes in the collective. Hmmm... look at this slightly
 ! disastrous occurrence: the MPI reduction operation MPI_LAND got out of
 ! the cage... this needs to be addressed.
 call sll_o_collective_allreduce(plan%collective,is_uniform_local(:),1,MPI_LAND, is_uniform_collective(:) )
 
 ! This flag will be used for an optimized call in apply_remap_plan()
 plan%is_uniform = is_uniform_collective(1)

end subroutine



  function arrays_are_equal( a1, a2, n )
    logical :: arrays_are_equal
    integer(kind=i32), dimension(:), intent(in) :: a1
    integer(kind=i32), dimension(:), intent(in) :: a2
    integer(kind=i32), intent(in)               :: n
    integer(kind=i32)                           :: i
    arrays_are_equal = .true.
    do i=1,n
       if( a1(i).ne.a2(i) ) then
          arrays_are_equal = .false. 
       end if
    end do
  end function arrays_are_equal



  function get_remap_2D_initial_layout_int32( plan )
 type( sll_t_layout_2d), pointer :: get_remap_2D_initial_layout_int32
 type( remap_plan_2D_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_2D_initial_layout_int32 => plan%initial_layout
 end function get_remap_2D_initial_layout_int32
  function get_remap_2D_initial_layout_real64( plan )
 type( sll_t_layout_2d), pointer :: get_remap_2D_initial_layout_real64
 type( sll_t_remap_plan_2d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_2D_initial_layout_real64 => plan%initial_layout
 end function get_remap_2D_initial_layout_real64
  function get_remap_2D_initial_layout_comp64( plan )
 type( sll_t_layout_2d), pointer :: get_remap_2D_initial_layout_comp64
 type( sll_t_remap_plan_2d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_2D_initial_layout_comp64 => plan%initial_layout
 end function get_remap_2D_initial_layout_comp64
  function get_remap_3D_initial_layout_int32( plan )
 type( sll_t_layout_3d), pointer :: get_remap_3D_initial_layout_int32
 type( remap_plan_3D_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_3D_initial_layout_int32 => plan%initial_layout
 end function get_remap_3D_initial_layout_int32
  function get_remap_3D_initial_layout_real64( plan )
 type( sll_t_layout_3d), pointer :: get_remap_3D_initial_layout_real64
 type( sll_t_remap_plan_3d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_3D_initial_layout_real64 => plan%initial_layout
 end function get_remap_3D_initial_layout_real64
  function get_remap_3D_initial_layout_comp64( plan )
 type( sll_t_layout_3d), pointer :: get_remap_3D_initial_layout_comp64
 type( sll_t_remap_plan_3d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_3D_initial_layout_comp64 => plan%initial_layout
 end function get_remap_3D_initial_layout_comp64
  function get_remap_4D_initial_layout_int32( plan )
 type( sll_t_layout_4d), pointer :: get_remap_4D_initial_layout_int32
 type( remap_plan_4D_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_4D_initial_layout_int32 => plan%initial_layout
 end function get_remap_4D_initial_layout_int32
  function get_remap_4D_initial_layout_real64( plan )
 type( sll_t_layout_4d), pointer :: get_remap_4D_initial_layout_real64
 type( sll_t_remap_plan_4d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_4D_initial_layout_real64 => plan%initial_layout
 end function get_remap_4D_initial_layout_real64
  function get_remap_4D_initial_layout_comp64( plan )
 type( sll_t_layout_4d), pointer :: get_remap_4D_initial_layout_comp64
 type( remap_plan_4D_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_4D_initial_layout_comp64 => plan%initial_layout
 end function get_remap_4D_initial_layout_comp64
  function get_remap_5D_initial_layout_int32( plan )
 type( sll_t_layout_5d), pointer :: get_remap_5D_initial_layout_int32
 type( remap_plan_5D_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_5D_initial_layout_int32 => plan%initial_layout
 end function get_remap_5D_initial_layout_int32
  function get_remap_5D_initial_layout_real64( plan )
 type( sll_t_layout_5d), pointer :: get_remap_5D_initial_layout_real64
 type( sll_t_remap_plan_5d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_5D_initial_layout_real64 => plan%initial_layout
 end function get_remap_5D_initial_layout_real64
  function get_remap_5D_initial_layout_comp64( plan )
 type( sll_t_layout_5d), pointer :: get_remap_5D_initial_layout_comp64
 type( remap_plan_5D_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_5D_initial_layout_comp64 => plan%initial_layout
 end function get_remap_5D_initial_layout_comp64
  function get_remap_6D_initial_layout_int32( plan )
 type( sll_t_layout_6d), pointer :: get_remap_6D_initial_layout_int32
 type( remap_plan_6D_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_6D_initial_layout_int32 => plan%initial_layout
 end function get_remap_6D_initial_layout_int32
  function get_remap_6D_initial_layout_real64( plan )
 type( sll_t_layout_6d), pointer :: get_remap_6D_initial_layout_real64
 type( sll_t_remap_plan_6d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_6D_initial_layout_real64 => plan%initial_layout
 end function get_remap_6D_initial_layout_real64
  function get_remap_6D_initial_layout_comp64( plan )
 type( sll_t_layout_6d), pointer :: get_remap_6D_initial_layout_comp64
 type( remap_plan_6D_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_initial_layout'
 end if
 get_remap_6D_initial_layout_comp64 => plan%initial_layout
 end function get_remap_6D_initial_layout_comp64



  function get_remap_2D_final_layout_int32( plan )
 type(sll_t_layout_2d), pointer :: get_remap_2D_final_layout_int32
 type(remap_plan_2d_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_2D_final_layout_int32 => plan%final_layout
 end function get_remap_2D_final_layout_int32
  function get_remap_2D_final_layout_real64( plan )
 type(sll_t_layout_2d), pointer :: get_remap_2D_final_layout_real64
 type(sll_t_remap_plan_2d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_2D_final_layout_real64 => plan%final_layout
 end function get_remap_2D_final_layout_real64
  function get_remap_2D_final_layout_comp64( plan )
 type(sll_t_layout_2d), pointer :: get_remap_2D_final_layout_comp64
 type(sll_t_remap_plan_2d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_2D_final_layout_comp64 => plan%final_layout
 end function get_remap_2D_final_layout_comp64
  function get_remap_3D_final_layout_int32( plan )
 type(sll_t_layout_3d), pointer :: get_remap_3D_final_layout_int32
 type(remap_plan_3d_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_3D_final_layout_int32 => plan%final_layout
 end function get_remap_3D_final_layout_int32
  function get_remap_3D_final_layout_real64( plan )
 type(sll_t_layout_3d), pointer :: get_remap_3D_final_layout_real64
 type(sll_t_remap_plan_3d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_3D_final_layout_real64 => plan%final_layout
 end function get_remap_3D_final_layout_real64
  function get_remap_3D_final_layout_comp64( plan )
 type(sll_t_layout_3d), pointer :: get_remap_3D_final_layout_comp64
 type(sll_t_remap_plan_3d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_3D_final_layout_comp64 => plan%final_layout
 end function get_remap_3D_final_layout_comp64
  function get_remap_4D_final_layout_int32( plan )
 type(sll_t_layout_4d), pointer :: get_remap_4D_final_layout_int32
 type(remap_plan_4d_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_4D_final_layout_int32 => plan%final_layout
 end function get_remap_4D_final_layout_int32
  function get_remap_4D_final_layout_real64( plan )
 type(sll_t_layout_4d), pointer :: get_remap_4D_final_layout_real64
 type(sll_t_remap_plan_4d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_4D_final_layout_real64 => plan%final_layout
 end function get_remap_4D_final_layout_real64
  function get_remap_4D_final_layout_comp64( plan )
 type(sll_t_layout_4d), pointer :: get_remap_4D_final_layout_comp64
 type(remap_plan_4d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_4D_final_layout_comp64 => plan%final_layout
 end function get_remap_4D_final_layout_comp64
  function get_remap_5D_final_layout_int32( plan )
 type(sll_t_layout_5d), pointer :: get_remap_5D_final_layout_int32
 type(remap_plan_5d_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_5D_final_layout_int32 => plan%final_layout
 end function get_remap_5D_final_layout_int32
  function get_remap_5D_final_layout_real64( plan )
 type(sll_t_layout_5d), pointer :: get_remap_5D_final_layout_real64
 type(sll_t_remap_plan_5d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_5D_final_layout_real64 => plan%final_layout
 end function get_remap_5D_final_layout_real64
  function get_remap_5D_final_layout_comp64( plan )
 type(sll_t_layout_5d), pointer :: get_remap_5D_final_layout_comp64
 type(remap_plan_5d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_5D_final_layout_comp64 => plan%final_layout
 end function get_remap_5D_final_layout_comp64
  function get_remap_6D_final_layout_int32( plan )
 type(sll_t_layout_6d), pointer :: get_remap_6D_final_layout_int32
 type(remap_plan_6d_int32), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_6D_final_layout_int32 => plan%final_layout
 end function get_remap_6D_final_layout_int32
  function get_remap_6D_final_layout_real64( plan )
 type(sll_t_layout_6d), pointer :: get_remap_6D_final_layout_real64
 type(sll_t_remap_plan_6d_real64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_6D_final_layout_real64 => plan%final_layout
 end function get_remap_6D_final_layout_real64
  function get_remap_6D_final_layout_comp64( plan )
 type(sll_t_layout_6d), pointer :: get_remap_6D_final_layout_comp64
 type(remap_plan_6d_comp64), pointer :: plan
 if( .not. associated( plan ) ) then
 write (*,'(a)') 'not associated pointer argument'
 stop 'get_remap_final_layout'
 end if
 get_remap_6D_final_layout_comp64 => plan%final_layout
 end function get_remap_6D_final_layout_comp64

  ! In this implementation, the user provides the memory location where the
  ! result of the remap operation will end up. The remap functions are
  ! type dependent. The objective will be to keep the type dependence here
  ! only. This objective is straightforward when we want to send types that
  ! happen to be basic MPI types. A problem arises when we want to communicate
  ! something like a derived type.
  !
  ! For derived types, one would normally be required to use the MPI 
  ! derived type functions like MPI_Type_struct and all that (or whatever
  ! their Fortran equivalent is) and all of a sudden we have lost containment
  ! (read: lost modularity) of the MPI LIBRARY.
  !
  ! Here we try an approach, standard in C but apparently unusual in Fortran.
  ! The idea is to always communicate the MPI_INTEGER datatype. The only extra
  ! step is to translate the arrays for counts and displacements in terms
  ! of their integer-sizes. While we would still need a different 
  ! apply_remap_XD() function for every new type, at least this will not 
  ! affect the sll_o_new_remap_plan() function.
  !
  ! For apply_remap_XD_int(), we use this approach as a test case, even though
  ! it is not necessary since 'integer' is also a native MPI type.

  !subroutine convert_into_integer_sizes( sz, ai, n, bi )
  !  integer(kind=i32), intent(in)                :: sz   ! in integer-size
  !  integer(kind=i32), intent(in), dimension(:)  :: ai   ! array to convert
  !  integer(kind=i32), intent(in)                :: n    ! size of array
  !  integer(kind=i32), intent(out), dimension(:) :: bi   ! output
  !  integer(kind=i32)                            :: i
  !  
  !  
  !  do i=1,n
  !     bi(i) = ai(i)*sz
  !  end do
  !end subroutine convert_into_integer_sizes

  ! **********************************************************************
  !
  !    Continue here with 3D, 4D and 5D functions...
  !
  ! **********************************************************************
  subroutine apply_remap_3D_int( plan, data_in, data_out )
    type(remap_plan_3D_int32), pointer             :: plan
    integer(kind=i32), dimension(:,:,:), intent(in)  :: data_in
    integer(kind=i32), dimension(:,:,:), intent(out) :: data_out
    integer(kind=i32), dimension(:), pointer         :: sb       ! send buffer
    integer(kind=i32), dimension(:), pointer         :: rb       ! receive buffer
    integer(kind=i32), dimension(:), pointer         :: sdisp    ! send displacements
    integer(kind=i32), dimension(:), pointer         :: rdisp    ! receive displacements
    integer(kind=i32), dimension(:), pointer         :: scnts    ! send counts
    integer(kind=i32), dimension(:), pointer         :: rcnts    ! receive counts
    type(sll_t_collective_t), pointer          :: col      ! collective
    type(sll_t_layout_3d), pointer                 :: init_layout  => NULL()
    type(sll_t_layout_3d), pointer                 :: final_layout => NULL()
    integer(kind=i32)                                :: id, jd, kd
    integer(kind=i32)                                :: i
    integer(kind=i32)                                :: col_sz
    integer(kind=i32)                                :: loi, loj, lok
    integer(kind=i32)                                :: hii, hij, hik
    type(box_3D)                             :: sbox
    integer(kind=i32)                                :: my_rank
    integer(kind=i32)                                :: loc
    integer(kind=i32), dimension(1:3)                :: local_lo, local_hi
    integer(kind=i32), dimension(1:3)                :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_3D_initial_layout_int32(plan)
    final_layout => get_remap_3D_final_layout_int32(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer
    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             write (*,'(a,i4,a,i16)') 'apply_remap_3D_int() ERROR: discrepancy between displs(i) and the loading index for i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox     = plan%send_boxes(i)
          loi      = get_box_3D_i_min(sbox)
          loj      = get_box_3D_j_min(sbox)
          lok      = get_box_3D_k_min(sbox)
          hii      = get_box_3D_i_max(sbox)
          hij      = get_box_3D_j_max(sbox)
          hik      = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( init_layout, tmpa)
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( init_layout, tmpa )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   sb(loc) = data_in(id,jd,kd)
                   loc     = loc + 1
                end do
             end do
          end do
       end if
    end do
    
!    write (*,'(a,i4)') 'the send buffer in rank:', my_rank
!    print *, sb(0:(size(sb)-1))
!    flush( output_unit )
 
   if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if
!    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
!    print *, rb(0:size(rb)-1)
!    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdisp(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_3D_i_min(sbox)
          loj = get_box_3D_j_min(sbox)
          lok = get_box_3D_k_min(sbox)
          hii = get_box_3D_i_max(sbox)
          hij = get_box_3D_j_max(sbox)
          hik = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( final_layout, tmpa )
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   data_out(id,jd,kd) = rb(loc)
                   loc                = loc + 1
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_3D_int

  subroutine apply_remap_2D_double( plan, data_in, data_out )
    type(sll_t_remap_plan_2d_real64), pointer       :: plan
    real(kind=f64), dimension(:,:), intent(in)    :: data_in
    real(kind=f64), dimension(:,:), intent(out)   :: data_out
    real(kind=f64), dimension(:), pointer         :: sb     ! send buffer
    real(kind=f64), dimension(:), pointer         :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_2d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_2d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj
    integer(kind=i32)                                 :: hii, hij
    type(box_2D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:2)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:2)                 :: tmpa

!!$    ! to load the MPI function and send integers, we have a separate set of
!!$    ! arrays to store this information for now.
!!$    integer(kind=i32), dimension(:), allocatable     :: sdispi  ! send displacements
!!$    integer(kind=i32), dimension(:), allocatable     :: rdispi  ! receive displacements
!!$    integer(kind=i32), dimension(:), allocatable     :: scntsi  ! send counts
!!$    integer(kind=i32), dimension(:), allocatable     :: rcntsi  ! receive counts

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_2D_initial_layout_real64(plan)
    final_layout => get_remap_2D_final_layout_real64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

!!$ 
!!$ 
!!$ 
!!$ 

    ! Translate the amounts into integers
!!$!if 1
!!$    call convert_into_integer_sizes(size(transfer(data_in(1,1), (/1_i32/))), sdisp, &
!!$         col_sz, sdispi)
!!$    call convert_into_integer_sizes(size(transfer(data_in(1,1), (/1_i32/))), rdisp, &
!!$         col_sz, rdispi)
!!$    call convert_into_integer_sizes(size(transfer(data_in(1,1), (/1_i32/))), scnts, &
!!$         col_sz, scntsi)
!!$    call convert_into_integer_sizes(size(transfer(data_in(1,1), (/1_i32/))), rcnts, &
!!$         col_sz, rcntsi)
!!$!endif
    
!!$!if 0
!!$    write (*,'(a,i4)') 'parameters from rank ', my_rank
!!$    print *, 'scntsi', scntsi(:)
!!$    print *, 'sdispi', sdispi(:)
!!$    print *, 'rcntsi', rcntsi(:)
!!$    print *, 'rdispi', rdispi(:)
!!$    flush( output_unit )
!!$!endif

    ! load the send buffer
    loc = 0             ! first loading is at position zero
!!$    ! This step is obviously not needed for integers themselves. We put this
!!$    ! here for generality.
!!$    int32_data_size = size(transfer( data_in(1,1) , (/1_i32/)))
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
!!$          if( loc .ne. sdispi(i) ) then
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_2D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
!!$                  'i = ', i, ' displs(i) = ', sdispi(i)
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_2D_i_min(sbox)
          loj = get_box_2D_j_min(sbox)
          hii = get_box_2D_i_max(sbox)
          hij = get_box_2D_j_max(sbox)
          tmpa(:)  = (/loi,loj/)
          local_lo = global_to_local_2D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij/)
          local_hi = global_to_local_2D( init_layout, tmpa )

!!$          local_lo = global_to_local_2D( init_layout, (/loi,loj/) )
!!$          local_hi = global_to_local_2D( init_layout, (/hii,hij/)  )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do jd = local_lo(2), local_hi(2)
             do id = local_lo(1), local_hi(1)
!!$                sb(loc:) = transfer(data_in(id,jd),(/1_i32/))
                sb(loc) = data_in(id,jd)
!!$                loc      = loc + int32_data_size
                loc      = loc + 1
             end do
          end do
       end if
    end do

    ! Comment the following when not debugging    
    !   write (*,'(a,i4)') 'the send buffer in rank:', my_rank
    !  print *, sb(0:(size(sb)-1))
    ! flush( output_unit )
    !    print *, 'from inside remap: rank ', my_rank, 'calling communications'
    !    flush( output_unit )
   if( plan%is_uniform .eqv. .false. ) then 
      ! the following call can be changed from a generic to a type-specific
      ! call when right away, but especially if the apply_remap function gets
      ! specialized (i.e. gets rid of transfer() calls).
       call sll_o_collective_alltoallv( sb(:),       &
!!$                                      scntsi(0:col_sz-1), &
!!$                                      sdispi(0:col_sz-1), &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
!!$                                      rcntsi(0:col_sz-1), &
!!$                                      rdispi(0:col_sz-1), &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), &
                                      col )
    else
       call sll_o_collective_alltoall ( sb(:), &
!!$                                      scntsi(0), &
!!$                                      rcntsi(0), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if
!    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
!    print *, rb(0:size(rb)-1)
!    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
!!$          if( loc .ne. rdispi(i) ) then
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdisp(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_2D_i_min(sbox)
          loj = get_box_2D_j_min(sbox)
          hii = get_box_2D_i_max(sbox)
          hij = get_box_2D_j_max(sbox)
          tmpa(:)  = (/loi,loj/)
          local_lo = global_to_local_2D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij/)
          local_hi = global_to_local_2D( final_layout, tmpa )
          do jd = local_lo(2), local_hi(2)
             do id = local_lo(1), local_hi(1)
!!$                data_out(id,jd) = transfer(rb(loc:),data_out(1,1))
                data_out(id,jd) = rb(loc)
!!$                loc                = loc + int32_data_size
                loc                = loc + 1
             end do
          end do
       end if
    end do
!!$    ! And why weren't these arrays part of the plan anyway??
!!$    
!!$    
!!$    
!!$    
  end subroutine apply_remap_2D_double

  subroutine apply_remap_2D_complex( plan, data_in, data_out )
    type(sll_t_remap_plan_2d_comp64), pointer       :: plan
    complex(kind=f64), dimension(:,:), intent(in)    :: data_in
    complex(kind=f64), dimension(:,:), intent(out)   :: data_out
    complex(kind=f64), dimension(:), pointer         :: sb     ! send buffer
    complex(kind=f64), dimension(:), pointer         :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_2d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_2d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj
    integer(kind=i32)                                 :: hii, hij
    type(box_2D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:2)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:2)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_2D_initial_layout_comp64(plan)
    final_layout => get_remap_2D_final_layout_comp64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer








    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_2D_complex() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_2D_i_min(sbox)
          loj = get_box_2D_j_min(sbox)
          hii = get_box_2D_i_max(sbox)
          hij = get_box_2D_j_max(sbox)
          tmpa(:)  = (/loi,loj/)
          local_lo = global_to_local_2D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij/)
          local_hi = global_to_local_2D( init_layout, tmpa )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do jd = local_lo(2), local_hi(2)
             do id = local_lo(1), local_hi(1)
                sb(loc) = data_in(id,jd)
                loc     = loc + 1
             end do
          end do
       end if
    end do
    ! Comment the following when not debugging    
!!$    write (*,'(a,i4)') 'the send buffer in rank:', my_rank
!!$    print *, sb(0:(size(sb)-1))
!!$    flush( output_unit )
!!$    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!!$    flush( output_unit )

   if( plan%is_uniform .eqv. .false. ) then 
      ! the following call can be changed from a generic to a type-specific
      ! call when right away, but especially if the apply_remap function gets
      ! specialized (i.e. gets rid of transfer() calls).
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if

    ! Comment when not debugging:
!!$    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
!!$    print *, rb(0:size(rb)-1)
!!$    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_2D_i_min(sbox)
          loj = get_box_2D_j_min(sbox)
          hii = get_box_2D_i_max(sbox)
          hij = get_box_2D_j_max(sbox)
          tmpa(:)  = (/loi,loj/)
          local_lo = global_to_local_2D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij/)
          local_hi = global_to_local_2D( final_layout, tmpa )
          do jd = local_lo(2), local_hi(2)
             do id = local_lo(1), local_hi(1)
                data_out(id,jd) = rb(loc)
                loc             = loc + 1
             end do
          end do
       end if
    end do
  end subroutine apply_remap_2D_complex



  subroutine apply_remap_3D_double( plan, data_in, data_out )
    type(sll_t_remap_plan_3d_real64), pointer              :: plan
    real(kind=f64), dimension(:,:,:), intent(in)  :: data_in
    real(kind=f64), dimension(:,:,:), intent(out) :: data_out
    real(kind=f64), dimension(:), pointer         :: sb     ! send buffer
    real(kind=f64), dimension(:), pointer         :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_3d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_3d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok
    integer(kind=i32)                                 :: hii, hij, hik
    type(box_3D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:3)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:3)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_3D_initial_layout_real64(plan)
    final_layout => get_remap_3D_final_layout_real64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! print *, 'from rank ', my_rank, 'loading parameters: ', sdisp, rdisp, &
    ! scnts, rcnts

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_3D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_3D_i_min(sbox)
          loj = get_box_3D_j_min(sbox)
          lok = get_box_3D_k_min(sbox)
          hii = get_box_3D_i_max(sbox)
          hij = get_box_3D_j_max(sbox)
          hik = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( init_layout, tmpa )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   sb(loc) = data_in(id,jd,kd)
                   loc     = loc + 1
                end do
             end do
          end do
       end if
    end do
    ! Comment the following when not debugging    
 !   write (*,'(a,i4)') 'the send buffer in rank:', my_rank
  !  print *, sb(0:(size(sb)-1))
   ! flush( output_unit )
!    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!    flush( output_unit )
   if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if
!    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
!    print *, rb(0:size(rb)-1)
!    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_3D_i_min(sbox)
          loj = get_box_3D_j_min(sbox)
          lok = get_box_3D_k_min(sbox)
          hii = get_box_3D_i_max(sbox)
          hij = get_box_3D_j_max(sbox)
          hik = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( final_layout, tmpa )
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   data_out(id,jd,kd) = rb(loc)
                   loc                = loc + 1
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_3D_double

  subroutine apply_remap_4D_double( plan, data_in, data_out )
    type(sll_t_remap_plan_4d_real64), pointer                :: plan
    real(kind=f64), dimension(:,:,:,:), intent(in)  :: data_in
    real(kind=f64), dimension(:,:,:,:), intent(out) :: data_out
    real(kind=f64), dimension(:), pointer         :: sb     ! send buffer
    real(kind=f64), dimension(:), pointer         :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_4d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_4d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd, ld
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok, lol
    integer(kind=i32)                                 :: hii, hij, hik, hil
    type(box_4D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:4)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:4)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_4D_initial_layout_real64(plan)
    final_layout => get_remap_4D_final_layout_real64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! print *, 'from rank ', my_rank, 'loading parameters: ', sdisp, rdisp, &
    ! scnts, rcnts

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_4D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_4D_i_min(sbox)
          loj = get_box_4D_j_min(sbox)
          lok = get_box_4D_k_min(sbox)
          lol = get_box_4D_l_min(sbox)
          hii = get_box_4D_i_max(sbox)
          hij = get_box_4D_j_max(sbox)
          hik = get_box_4D_k_max(sbox)
          hil = get_box_4D_l_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol/)
          local_lo = global_to_local_4D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil/)
          local_hi = global_to_local_4D( init_layout, tmpa )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do ld = local_lo(4), local_hi(4)
             do kd = local_lo(3), local_hi(3)
                do jd = local_lo(2), local_hi(2)
                   do id = local_lo(1), local_hi(1)
                      sb(loc) = data_in(id,jd,kd,ld)
                      loc     = loc + 1
                   end do
                end do
             end do
          end do
       end if
    end do
    ! Comment the following when not debugging    
    !   write (*,'(a,i4)') 'the send buffer in rank:', my_rank
    !  print *, sb(0:(size(sb)-1))
    ! flush( output_unit )
    !    print *, 'from inside remap: rank ', my_rank, 'calling communications'
    !    flush( output_unit )
    if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if
    !    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
    !    print *, rb(0:size(rb)-1)
    !    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_4D_i_min(sbox)
          loj = get_box_4D_j_min(sbox)
          lok = get_box_4D_k_min(sbox)
          lol = get_box_4D_l_min(sbox)
          hii = get_box_4D_i_max(sbox)
          hij = get_box_4D_j_max(sbox)
          hik = get_box_4D_k_max(sbox)
          hil = get_box_4D_l_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol/)
          local_lo = global_to_local_4D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil/)
          local_hi = global_to_local_4D( final_layout, tmpa )
          do ld = local_lo(4), local_hi(4)
             do kd = local_lo(3), local_hi(3)
                do jd = local_lo(2), local_hi(2)
                   do id = local_lo(1), local_hi(1)
                      data_out(id,jd,kd,ld) = rb(loc)
                      loc                   = loc + 1
                   end do
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_4D_double

  subroutine apply_remap_3D_complex( plan, data_in, data_out )
    type(sll_t_remap_plan_3d_comp64), pointer              :: plan
    complex(kind=f64), dimension(:,:,:), intent(in)  :: data_in
    complex(kind=f64), dimension(:,:,:), intent(out) :: data_out
    complex(kind=f64), dimension(:), pointer          :: sb     ! send buffer
    complex(kind=f64), dimension(:), pointer          :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_3d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_3d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok
    integer(kind=i32)                                 :: hii, hij, hik
    type(box_3D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:3)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:3)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_3D_initial_layout_comp64(plan)
    final_layout => get_remap_3D_final_layout_comp64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             write (*,'(a,i4,a,i16)') 'apply_remap_3D_int() ERROR: discrepancy between displs(i) and the loading index for i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             stop 'apply_remap(): loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_3D_i_min(sbox)
          loj = get_box_3D_j_min(sbox)
          lok = get_box_3D_k_min(sbox)
          hii = get_box_3D_i_max(sbox)
          hij = get_box_3D_j_max(sbox)
          hik = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( init_layout, tmpa )

          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   sb(loc) = data_in(id,jd,kd)
                   loc     = loc + 1
                end do
             end do
          end do
       end if
    end do
    
!    write (*,'(a,i4)') 'the send buffer in rank:', my_rank
!    print *, sb(0:(size(sb)-1))
!    flush( output_unit )
 
   if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if
!    write (*,'(a, i4)') 'the receive buffer in rank: ', my_rank
!    print *, rb(0:size(rb)-1)
!    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_3D_i_min(sbox)
          loj = get_box_3D_j_min(sbox)
          lok = get_box_3D_k_min(sbox)
          hii = get_box_3D_i_max(sbox)
          hij = get_box_3D_j_max(sbox)
          hik = get_box_3D_k_max(sbox)
          tmpa(:)  = (/loi,loj,lok/)
          local_lo = global_to_local_3D( final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik/)
          local_hi = global_to_local_3D( final_layout, tmpa )
          do kd = local_lo(3), local_hi(3)
             do jd = local_lo(2), local_hi(2)
                do id = local_lo(1), local_hi(1)
                   data_out(id,jd,kd) = rb(loc)
                   loc                = loc + 1
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_3D_complex



  subroutine apply_remap_5D_double( plan, data_in, data_out )
    type(sll_t_remap_plan_5d_real64), pointer              :: plan
    real(kind=f64), dimension(:,:,:,:,:), intent(in)  :: data_in
    real(kind=f64), dimension(:,:,:,:,:), intent(out) :: data_out
    real(kind=f64), dimension(:), pointer          :: sb     ! send buffer
    real(kind=f64), dimension(:), pointer          :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_5d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_5d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd, ld, md
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok, lol, lom
    integer(kind=i32)                                 :: hii, hij, hik, hil, him
    type(box_5D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:5)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:5)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_5D_initial_layout_real64(plan)
    final_layout => get_remap_5D_final_layout_real64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! print *, 'from rank ', my_rank, 'loading parameters: ', sdisp, rdisp, &
    ! scnts, rcnts

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_5D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): exchange buffer loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_5D_i_min(sbox)
          loj = get_box_5D_j_min(sbox)
          lok = get_box_5D_k_min(sbox)
          lol = get_box_5D_l_min(sbox)
          lom = get_box_5D_m_min(sbox)
          hii = get_box_5D_i_max(sbox)
          hij = get_box_5D_j_max(sbox)
          hik = get_box_5D_k_max(sbox)
          hil = get_box_5D_l_max(sbox)
          him = get_box_5D_m_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol,lom/)
          local_lo = global_to_local_5D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil,him/)
          local_hi = global_to_local_5D( init_layout, tmpa)

          ! The plan to load the send buffer is to traverse the send buffer
          ! array with a single index (loc). We manually increment the loading
          ! index. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            sb(loc) = data_in(id,jd,kd,ld,md)
                            loc     = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
       end if
    end do
    ! Comment the following when not debugging    
!!$    write (*,'(a,i4)') 'the send buffer in rank:', my_rank
!!$    print *, sb(0:(size(sb)-1))
!!$    flush( output_unit )
!!$    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!!$    flush( output_unit )

    if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if

!!$    write (*,'(a, i4)') 'receive buffer in rank: ', my_rank
!!$    print *, rb(0:size(rb)-1)
!!$    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'exchange buffer unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_5D_i_min(sbox)
          loj = get_box_5D_j_min(sbox)
          lok = get_box_5D_k_min(sbox)
          lol = get_box_5D_l_min(sbox)
          lom = get_box_5D_m_min(sbox)
          hii = get_box_5D_i_max(sbox)
          hij = get_box_5D_j_max(sbox)
          hik = get_box_5D_k_max(sbox)
          hil = get_box_5D_l_max(sbox)
          him = get_box_5D_m_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol,lom/)
          local_lo = global_to_local_5D(final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil,him/)
          local_hi = global_to_local_5D(final_layout, tmpa)
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            data_out(id,jd,kd,ld,md) = rb(loc)
                            loc                         = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
       end if
    end do
  end subroutine apply_remap_5D_double



  subroutine apply_remap_5D_int( plan, data_in, data_out )
    type(remap_plan_5D_int32), pointer              :: plan
    integer(kind=i32), dimension(:,:,:,:,:), intent(in)  :: data_in
    integer(kind=i32), dimension(:,:,:,:,:), intent(out) :: data_out
    integer(kind=i32), dimension(:), pointer          :: sb     ! send buffer
    integer(kind=i32), dimension(:), pointer          :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_5d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_5d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd, ld, md
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok, lol, lom
    integer(kind=i32)                                 :: hii, hij, hik, hil, him
    type(box_5D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:5)                 :: local_lo, local_hi

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_5D_initial_layout_int32(plan)
    final_layout => get_remap_5D_final_layout_int32(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_5D_int() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): exchange buffer loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_5D_i_min(sbox)
          loj = get_box_5D_j_min(sbox)
          lok = get_box_5D_k_min(sbox)
          lol = get_box_5D_l_min(sbox)
          lom = get_box_5D_m_min(sbox)
          hii = get_box_5D_i_max(sbox)
          hij = get_box_5D_j_max(sbox)
          hik = get_box_5D_k_max(sbox)
          hil = get_box_5D_l_max(sbox)
          him = get_box_5D_m_max(sbox)
          local_lo = &
               global_to_local_5D( init_layout,(/loi,loj,lok,lol,lom/))
          local_hi = &
               global_to_local_5D( init_layout,(/hii,hij,hik,hil,him/))
          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            sb(loc) = data_in(id,jd,kd,ld,md)
                            loc      = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
       end if
    end do

    ! Comment the following when not debugging    
!!$    if(my_rank == 0) then
!!$       write (*,'(a,i4)') 'send buffer, rank:', my_rank, 'buffer size = ', &
!!$            size(sb)
!!$       print *, 'sb: ', sb(0:(size(sb)-1))
!!$       print *, 'scntsi: ', scntsi(:)
!!$       print *, 'sdispi: ', sdispi(:)
!!$       print *, 'rb: ', rb(:)
!!$       print *, 'rcntsi: ', rcntsi(:)
!!$       print *, 'rdispi: ', rdispi(:)
!!$       print *, 'uniformity: ', plan%is_uniform
!!$       flush( output_unit )
!!$    end if
!!$    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!!$    flush( output_unit )

    if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if

!!$    write (*,'(a, i4)') 'receive buffer in rank: ', my_rank
!!$    print *, rb(0:size(rb)-1)
!!$    flush( output_unit )

    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'exchange buffer unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_5D_i_min(sbox)
          loj = get_box_5D_j_min(sbox)
          lok = get_box_5D_k_min(sbox)
          lol = get_box_5D_l_min(sbox)
          lom = get_box_5D_m_min(sbox)
          hii = get_box_5D_i_max(sbox)
          hij = get_box_5D_j_max(sbox)
          hik = get_box_5D_k_max(sbox)
          hil = get_box_5D_l_max(sbox)
          him = get_box_5D_m_max(sbox)
          local_lo = &
               global_to_local_5D(final_layout, (/loi,loj,lok,lol,lom/))
          local_hi = &
               global_to_local_5D(final_layout, (/hii,hij,hik,hil,him/))
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            data_out(id,jd,kd,ld,md) = rb(loc)
                            loc                         = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
       end if
    end do
  end subroutine apply_remap_5D_int






  subroutine apply_remap_6D_double( plan, data_in, data_out )
    type(sll_t_remap_plan_6d_real64), pointer              :: plan
    real(kind=f64), dimension(:,:,:,:,:,:), intent(in)  :: data_in
    real(kind=f64), dimension(:,:,:,:,:,:), intent(out) :: data_out
    real(kind=f64), dimension(:), pointer          :: sb     ! send buffer
    real(kind=f64), dimension(:), pointer          :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_6d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_6d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd, ld, md, nd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok, lol, lom, lon
    integer(kind=i32)                                 :: hii, hij, hik, hil, him, hin
    type(box_6D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:6)                 :: local_lo, local_hi
    integer(kind=i32), dimension(1:6)                 :: tmpa

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_6D_initial_layout_real64(plan)
    final_layout => get_remap_6D_final_layout_real64(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! print *, 'from rank ', my_rank, 'loading parameters: ', sdisp, rdisp, &
    ! scnts, rcnts

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_6D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): exchange buffer loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_6D_i_min(sbox)
          loj = get_box_6D_j_min(sbox)
          lok = get_box_6D_k_min(sbox)
          lol = get_box_6D_l_min(sbox)
          lom = get_box_6D_m_min(sbox)
          lon = get_box_6D_n_min(sbox)
          hii = get_box_6D_i_max(sbox)
          hij = get_box_6D_j_max(sbox)
          hik = get_box_6D_k_max(sbox)
          hil = get_box_6D_l_max(sbox)
          him = get_box_6D_m_max(sbox)
          hin = get_box_6D_n_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol,lom,lon/)
          local_lo = global_to_local_6D( init_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil,him,hin/)
          local_hi = global_to_local_6D( init_layout, tmpa)

          ! The plan to load the send buffer is to traverse the send buffer
          ! array with a single index (loc). We manually increment the loading
          ! index. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do nd = local_lo(6), local_hi(6)
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            sb(loc) = data_in(id,jd,kd,ld,md,nd)
                            loc     = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
          end do
       end if
    end do
    ! Comment the following when not debugging    
!!$    write (*,'(a,i4)') 'the send buffer in rank:', my_rank
!!$    print *, sb(0:(size(sb)-1))
!!$    flush( output_unit )
!!$    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!!$    flush( output_unit )

    if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if

!!$    write (*,'(a, i4)') 'receive buffer in rank: ', my_rank
!!$    print *, rb(0:size(rb)-1)
!!$    flush( output_unit )
    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'exchange buffer unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_6D_i_min(sbox)
          loj = get_box_6D_j_min(sbox)
          lok = get_box_6D_k_min(sbox)
          lol = get_box_6D_l_min(sbox)
          lom = get_box_6D_m_min(sbox)
          lon = get_box_6D_n_min(sbox)
          hii = get_box_6D_i_max(sbox)
          hij = get_box_6D_j_max(sbox)
          hik = get_box_6D_k_max(sbox)
          hil = get_box_6D_l_max(sbox)
          him = get_box_6D_m_max(sbox)
          hin = get_box_6D_n_max(sbox)
          tmpa(:)  = (/loi,loj,lok,lol,lom,lon/)
          local_lo = global_to_local_6D(final_layout, tmpa )
          tmpa(:)  = (/hii,hij,hik,hil,him,hin/)
          local_hi = global_to_local_6D(final_layout, tmpa)
          do nd = local_lo(6), local_hi(6)
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            data_out(id,jd,kd,ld,md,nd) = rb(loc)
                            loc                         = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_6D_double

  subroutine apply_remap_6D_int( plan, data_in, data_out )
    type(remap_plan_6D_int32), pointer              :: plan
    integer(kind=i32), dimension(:,:,:,:,:,:), intent(in)  :: data_in
    integer(kind=i32), dimension(:,:,:,:,:,:), intent(out) :: data_out
    integer(kind=i32), dimension(:), pointer          :: sb     ! send buffer
    integer(kind=i32), dimension(:), pointer          :: rb     ! receive buffer
    integer(kind=i32), dimension(:), pointer          :: sdisp  ! send displacements
    integer(kind=i32), dimension(:), pointer          :: rdisp  ! receive displacements 
    integer(kind=i32), dimension(:), pointer          :: scnts  ! send counts
    integer(kind=i32), dimension(:), pointer          :: rcnts  ! receive counts
    type(sll_t_collective_t), pointer           :: col    ! collective
    type(sll_t_layout_6d), pointer                  :: init_layout  => NULL()
    type(sll_t_layout_6d), pointer                  :: final_layout => NULL()
    integer(kind=i32)                                 :: id, jd, kd, ld, md, nd
    integer(kind=i32)                                 :: i
    integer(kind=i32)                                 :: col_sz
    integer(kind=i32)                                 :: loi, loj, lok, lol, lom, lon
    integer(kind=i32)                                 :: hii, hij, hik, hil, him, hin
    type(box_6D)                              :: sbox
    integer(kind=i32)                                 :: my_rank
    integer(kind=i32)                                 :: loc
    integer(kind=i32), dimension(1:6)                 :: local_lo, local_hi

    ! unpack the plan: There are inconsistencies here, one one hand we access
    ! directly and on the other with access functions... standardize...
    sdisp        => plan%send_displs
    rdisp        => plan%recv_displs
    scnts        => plan%send_counts
    rcnts        => plan%recv_counts
    col          => plan%collective
    col_sz       =  sll_f_get_collective_size(col)
    init_layout  => get_remap_6D_initial_layout_int32(plan)
    final_layout => get_remap_6D_final_layout_int32(plan)
    my_rank      =  sll_f_get_collective_rank(col)
    sb           => plan%send_buffer
    rb           => plan%recv_buffer

    ! load the send buffer
    loc = 0             ! first loading is at position zero
    do i = 0, col_sz-1
       if( scnts(i) .ne. 0 ) then ! send something to rank 'i'
          if( loc .ne. sdisp(i) ) then
             print *, 'ERROR DETECTED in process: ', my_rank
             print *, 'apply_remap_6D_double() ERROR: ', &
                  'discrepancy between displs(i) and the loading index for ',&
                  'i = ', i, ' displs(i) = ', sdisp(i)
             write(*,'(a,i8)') 'col_sz = ', col_sz
             flush( output_unit )
             stop 'apply_remap(): exchange buffer loading error'
          end if
          ! get the information on the box to send, get the limits,
          ! convert to the local indices and find out where in the 
          ! buffer to start writing.
          sbox = plan%send_boxes(i)
          loi = get_box_6D_i_min(sbox)
          loj = get_box_6D_j_min(sbox)
          lok = get_box_6D_k_min(sbox)
          lol = get_box_6D_l_min(sbox)
          lom = get_box_6D_m_min(sbox)
          lon = get_box_6D_n_min(sbox)
          hii = get_box_6D_i_max(sbox)
          hij = get_box_6D_j_max(sbox)
          hik = get_box_6D_k_max(sbox)
          hil = get_box_6D_l_max(sbox)
          him = get_box_6D_m_max(sbox)
          hin = get_box_6D_n_max(sbox)
          local_lo = &
               global_to_local_6D( init_layout,(/loi,loj,lok,lol,lom,lon/))
          local_hi = &
               global_to_local_6D( init_layout,(/hii,hij,hik,hil,him,hin/))
          ! The plan to load the send buffer is to traverse the integer
          ! array with a single index (loc). When we load the buffer, each
          ! data element may occupy multiple integer 'slots', hence the
          ! loading index needs to be manually increased. As an advantage,
          ! we can do some error checking every time we send data to a 
          ! different process, as we know what is the expected value of 
          ! the index at that point.
          do nd = local_lo(6), local_hi(6)
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            sb(loc) = data_in(id,jd,kd,ld,md,nd)
                            loc      = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
          end do
       end if
    end do

    ! Comment the following when not debugging    
!!$    if(my_rank == 0) then
!!$       write (*,'(a,i4)') 'send buffer, rank:', my_rank, 'buffer size = ', &
!!$            size(sb)
!!$       print *, 'sb: ', sb(0:(size(sb)-1))
!!$       print *, 'scntsi: ', scntsi(:)
!!$       print *, 'sdispi: ', sdispi(:)
!!$       print *, 'rb: ', rb(:)
!!$       print *, 'rcntsi: ', rcntsi(:)
!!$       print *, 'rdispi: ', rdispi(:)
!!$       print *, 'uniformity: ', plan%is_uniform
!!$       flush( output_unit )
!!$    end if
!!$    print *, 'from inside remap: rank ', my_rank, 'calling communications'
!!$    flush( output_unit )

    if( plan%is_uniform .eqv. .false. ) then 
       call sll_o_collective_alltoallv( sb(:),       &
                                      scnts(0:col_sz-1), &
                                      sdisp(0:col_sz-1), &
                                      rb(:),       &
                                      rcnts(0:col_sz-1), &
                                      rdisp(0:col_sz-1), col )
    else
       call sll_o_collective_alltoall ( sb(:), &
                                      scnts(0), &
                                      rcnts(0), &
                                      rb(:), col )
    end if

!!$    write (*,'(a, i4)') 'receive buffer in rank: ', my_rank
!!$    print *, rb(0:size(rb)-1)
!!$    flush( output_unit )

    ! Unpack the plan into the outgoing buffer.
    loc = 0  ! We load first from position 0 in the receive buffer.
    do i = 0, col_sz-1
       if( rcnts(i) .ne. 0 ) then ! we expect something from rank 'i'
          if( loc .ne. rdisp(i) ) then
             write (*,'(a,i4)') &
                  'ERROR: discrepancy between rdispi(i) and index for i = ', i
             stop 'exchange buffer unpacking error'
          end if
          ! get the information on the box to receive, get the limits, and 
          ! convert to the local indices.
          sbox = plan%recv_boxes(i)
          loi = get_box_6D_i_min(sbox)
          loj = get_box_6D_j_min(sbox)
          lok = get_box_6D_k_min(sbox)
          lol = get_box_6D_l_min(sbox)
          lom = get_box_6D_m_min(sbox)
          lon = get_box_6D_n_min(sbox)
          hii = get_box_6D_i_max(sbox)
          hij = get_box_6D_j_max(sbox)
          hik = get_box_6D_k_max(sbox)
          hil = get_box_6D_l_max(sbox)
          him = get_box_6D_m_max(sbox)
          hin = get_box_6D_n_max(sbox)
          local_lo = &
               global_to_local_6D(final_layout, (/loi,loj,lok,lol,lom,lon/))
          local_hi = &
               global_to_local_6D(final_layout, (/hii,hij,hik,hil,him,hin/))
          do nd = local_lo(6), local_hi(6)
             do md = local_lo(5), local_hi(5)
                do ld = local_lo(4), local_hi(4)
                   do kd = local_lo(3), local_hi(3)
                      do jd = local_lo(2), local_hi(2)
                         do id = local_lo(1), local_hi(1)
                            data_out(id,jd,kd,ld,md,nd) = rb(loc)
                            loc                         = loc + 1
                         end do
                      end do
                   end do
                end do
             end do
          end do
       end if
    end do
  end subroutine apply_remap_6D_int

  ! Placeholder: the load/unload subroutines for the send and receive buffers
  ! should ideally be abstracted out. This means that we need to probably
  ! define some generic interface and hide behind the types that we want to
  ! exchange. We can think of direct loading and exchanging the basic types:
  ! - single/double precision floats
  ! - integers
  ! - stay with the transfer function for other types.














  function  get_box_2D_i_min( b )
 integer(kind=i32) ::  get_box_2D_i_min
 type( box_2D), intent(in) :: b
  get_box_2D_i_min = b% i_min 
 end function  get_box_2D_i_min
  function  get_box_2D_i_max( b )
 integer(kind=i32) ::  get_box_2D_i_max
 type( box_2D), intent(in) :: b
  get_box_2D_i_max = b% i_max 
 end function  get_box_2D_i_max
  function  get_box_2D_j_min( b )
 integer(kind=i32) ::  get_box_2D_j_min
 type( box_2D), intent(in) :: b
  get_box_2D_j_min = b% j_min 
 end function  get_box_2D_j_min
  function  get_box_2D_j_max( b )
 integer(kind=i32) ::  get_box_2D_j_max
 type( box_2D), intent(in) :: b
  get_box_2D_j_max = b% j_max 
 end function  get_box_2D_j_max

  function  get_box_3D_i_min( b )
 integer(kind=i32) ::  get_box_3D_i_min
 type( box_3D), intent(in) :: b
  get_box_3D_i_min = b% i_min 
 end function  get_box_3D_i_min
  function  get_box_3D_i_max( b )
 integer(kind=i32) ::  get_box_3D_i_max
 type( box_3D), intent(in) :: b
  get_box_3D_i_max = b% i_max 
 end function  get_box_3D_i_max
  function  get_box_3D_j_min( b )
 integer(kind=i32) ::  get_box_3D_j_min
 type( box_3D), intent(in) :: b
  get_box_3D_j_min = b% j_min 
 end function  get_box_3D_j_min
  function  get_box_3D_j_max( b )
 integer(kind=i32) ::  get_box_3D_j_max
 type( box_3D), intent(in) :: b
  get_box_3D_j_max = b% j_max 
 end function  get_box_3D_j_max
  function  get_box_3D_k_min( b )
 integer(kind=i32) ::  get_box_3D_k_min
 type( box_3D), intent(in) :: b
  get_box_3D_k_min = b% k_min 
 end function  get_box_3D_k_min
  function  get_box_3D_k_max( b )
 integer(kind=i32) ::  get_box_3D_k_max
 type( box_3D), intent(in) :: b
  get_box_3D_k_max = b% k_max 
 end function  get_box_3D_k_max

  function  get_box_4D_i_min( b )
 integer(kind=i32) ::  get_box_4D_i_min
 type( box_4D), intent(in) :: b
  get_box_4D_i_min = b% i_min 
 end function  get_box_4D_i_min
  function  get_box_4D_i_max( b )
 integer(kind=i32) ::  get_box_4D_i_max
 type( box_4D), intent(in) :: b
  get_box_4D_i_max = b% i_max 
 end function  get_box_4D_i_max
  function  get_box_4D_j_min( b )
 integer(kind=i32) ::  get_box_4D_j_min
 type( box_4D), intent(in) :: b
  get_box_4D_j_min = b% j_min 
 end function  get_box_4D_j_min
  function  get_box_4D_j_max( b )
 integer(kind=i32) ::  get_box_4D_j_max
 type( box_4D), intent(in) :: b
  get_box_4D_j_max = b% j_max 
 end function  get_box_4D_j_max
  function  get_box_4D_k_min( b )
 integer(kind=i32) ::  get_box_4D_k_min
 type( box_4D), intent(in) :: b
  get_box_4D_k_min = b% k_min 
 end function  get_box_4D_k_min
  function  get_box_4D_k_max( b )
 integer(kind=i32) ::  get_box_4D_k_max
 type( box_4D), intent(in) :: b
  get_box_4D_k_max = b% k_max 
 end function  get_box_4D_k_max
  function  get_box_4D_l_min( b )
 integer(kind=i32) ::  get_box_4D_l_min
 type( box_4D), intent(in) :: b
  get_box_4D_l_min = b% l_min 
 end function  get_box_4D_l_min
  function  get_box_4D_l_max( b )
 integer(kind=i32) ::  get_box_4D_l_max
 type( box_4D), intent(in) :: b
  get_box_4D_l_max = b% l_max 
 end function  get_box_4D_l_max

  function  get_box_5D_i_min( b )
 integer(kind=i32) ::  get_box_5D_i_min
 type( box_5D), intent(in) :: b
  get_box_5D_i_min = b% i_min 
 end function  get_box_5D_i_min
  function  get_box_5D_i_max( b )
 integer(kind=i32) ::  get_box_5D_i_max
 type( box_5D), intent(in) :: b
  get_box_5D_i_max = b% i_max 
 end function  get_box_5D_i_max
  function  get_box_5D_j_min( b )
 integer(kind=i32) ::  get_box_5D_j_min
 type( box_5D), intent(in) :: b
  get_box_5D_j_min = b% j_min 
 end function  get_box_5D_j_min
  function  get_box_5D_j_max( b )
 integer(kind=i32) ::  get_box_5D_j_max
 type( box_5D), intent(in) :: b
  get_box_5D_j_max = b% j_max 
 end function  get_box_5D_j_max
  function  get_box_5D_k_min( b )
 integer(kind=i32) ::  get_box_5D_k_min
 type( box_5D), intent(in) :: b
  get_box_5D_k_min = b% k_min 
 end function  get_box_5D_k_min
  function  get_box_5D_k_max( b )
 integer(kind=i32) ::  get_box_5D_k_max
 type( box_5D), intent(in) :: b
  get_box_5D_k_max = b% k_max 
 end function  get_box_5D_k_max
  function  get_box_5D_l_min( b )
 integer(kind=i32) ::  get_box_5D_l_min
 type( box_5D), intent(in) :: b
  get_box_5D_l_min = b% l_min 
 end function  get_box_5D_l_min
  function  get_box_5D_l_max( b )
 integer(kind=i32) ::  get_box_5D_l_max
 type( box_5D), intent(in) :: b
  get_box_5D_l_max = b% l_max 
 end function  get_box_5D_l_max
  function  get_box_5D_m_min( b )
 integer(kind=i32) ::  get_box_5D_m_min
 type( box_5D), intent(in) :: b
  get_box_5D_m_min = b% m_min 
 end function  get_box_5D_m_min
  function  get_box_5D_m_max( b )
 integer(kind=i32) ::  get_box_5D_m_max
 type( box_5D), intent(in) :: b
  get_box_5D_m_max = b% m_max 
 end function  get_box_5D_m_max

  function  get_box_6D_i_min( b )
 integer(kind=i32) ::  get_box_6D_i_min
 type( box_6D), intent(in) :: b
  get_box_6D_i_min = b% i_min 
 end function  get_box_6D_i_min
  function  get_box_6D_i_max( b )
 integer(kind=i32) ::  get_box_6D_i_max
 type( box_6D), intent(in) :: b
  get_box_6D_i_max = b% i_max 
 end function  get_box_6D_i_max
  function  get_box_6D_j_min( b )
 integer(kind=i32) ::  get_box_6D_j_min
 type( box_6D), intent(in) :: b
  get_box_6D_j_min = b% j_min 
 end function  get_box_6D_j_min
  function  get_box_6D_j_max( b )
 integer(kind=i32) ::  get_box_6D_j_max
 type( box_6D), intent(in) :: b
  get_box_6D_j_max = b% j_max 
 end function  get_box_6D_j_max
  function  get_box_6D_k_min( b )
 integer(kind=i32) ::  get_box_6D_k_min
 type( box_6D), intent(in) :: b
  get_box_6D_k_min = b% k_min 
 end function  get_box_6D_k_min
  function  get_box_6D_k_max( b )
 integer(kind=i32) ::  get_box_6D_k_max
 type( box_6D), intent(in) :: b
  get_box_6D_k_max = b% k_max 
 end function  get_box_6D_k_max
  function  get_box_6D_l_min( b )
 integer(kind=i32) ::  get_box_6D_l_min
 type( box_6D), intent(in) :: b
  get_box_6D_l_min = b% l_min 
 end function  get_box_6D_l_min
  function  get_box_6D_l_max( b )
 integer(kind=i32) ::  get_box_6D_l_max
 type( box_6D), intent(in) :: b
  get_box_6D_l_max = b% l_max 
 end function  get_box_6D_l_max
  function  get_box_6D_m_min( b )
 integer(kind=i32) ::  get_box_6D_m_min
 type( box_6D), intent(in) :: b
  get_box_6D_m_min = b% m_min 
 end function  get_box_6D_m_min
  function  get_box_6D_m_max( b )
 integer(kind=i32) ::  get_box_6D_m_max
 type( box_6D), intent(in) :: b
  get_box_6D_m_max = b% m_max 
 end function  get_box_6D_m_max
  function  get_box_6D_n_min( b )
 integer(kind=i32) ::  get_box_6D_n_min
 type( box_6D), intent(in) :: b
  get_box_6D_n_min = b% n_min 
 end function  get_box_6D_n_min
  function  get_box_6D_n_max( b )
 integer(kind=i32) ::  get_box_6D_n_max
 type( box_6D), intent(in) :: b
  get_box_6D_n_max = b% n_max 
 end function  get_box_6D_n_max


  function sll_get_num_nodes_2D( lims )
    integer(kind=i32)                  :: sll_get_num_nodes_2D
    type(sll_t_layout_2d), pointer :: lims
    sll_get_num_nodes_2D = sll_f_get_collective_size( lims%collective )
  end function sll_get_num_nodes_2D

  function sll_get_num_nodes_3D( lims )
    integer(kind=i32)                  :: sll_get_num_nodes_3D
    type(sll_t_layout_3d), pointer :: lims
    sll_get_num_nodes_3D = sll_f_get_collective_size( lims%collective )
  end function sll_get_num_nodes_3D

  function sll_get_num_nodes_4D( lims )
    integer(kind=i32)                  :: sll_get_num_nodes_4D
    type(sll_t_layout_4d), pointer :: lims
    sll_get_num_nodes_4D = sll_f_get_collective_size( lims%collective )
  end function sll_get_num_nodes_4D

  function sll_get_num_nodes_5D( lims )
    integer(kind=i32)                  :: sll_get_num_nodes_5D
    type(sll_t_layout_5d), pointer :: lims
    sll_get_num_nodes_5D = sll_f_get_collective_size( lims%collective )
  end function sll_get_num_nodes_5D

  function sll_get_num_nodes_6D( lims )
    integer(kind=i32)                  :: sll_get_num_nodes_6D
    type(sll_t_layout_6d), pointer :: lims
    sll_get_num_nodes_6D = sll_f_get_collective_size( lims%collective )
  end function sll_get_num_nodes_6D


  ! It seems that it is essential to have functions that would convert
  ! indices from a local to a global indexing and back. For instance, if we
  ! consider a 1D array as a single global unit, it has an unique indexing.
  ! If we domain-decompose the array, even if there are overlapping domains,
  ! the result of a local2global() indexing function would be unambiguous.
  !
  ! However, the global2local() indexing operation can be ambiguous if the
  ! domains are overlapping. There are thus some design choices that emerge:
  !
  ! On the one hand, we could choose a scheme in which the global2local()
  ! function only responds in the context of the calling process, thus, if
  ! a call to this function returns, say, '0' (and the array is indexed 1:N), 
  ! then we know that the global index has no presence in the layout in the 
  ! local process.
  ! 
  ! On the other hand, the global2local() function could also be made to
  ! indicate the local index and rank of the other processes that also happen
  ! to have that global index in their domain. This second part, while it
  ! seems more useful, may be way too complicated (and would return multiple
  ! things). Thus here we go for the first option.
  function local_to_global_2D( layout, doublet )
    integer(kind=i32), dimension(1:2)             :: local_to_global_2D
    type(sll_t_layout_2d), pointer              :: layout
    integer(kind=i32), intent(in), dimension(1:2) :: doublet
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_2D)                          :: box
    ! fixme: arg checking
    col                => get_layout_2D_collective( layout )
    my_rank            =  sll_f_get_collective_rank( col )
    box                =  get_layout_2D_box( layout, my_rank )
    local_to_global_2D(1) = get_box_2D_i_min(box) + doublet(1) - 1
    local_to_global_2D(2) = get_box_2D_j_min(box) + doublet(2) - 1
  end function local_to_global_2D

  function local_to_global_3D( layout, triplet )
    integer(kind=i32), dimension(1:3)             :: local_to_global_3D
    type(sll_t_layout_3d), pointer            :: layout
    integer(kind=i32), intent(in), dimension(1:3) :: triplet
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_3D)                          :: box
    ! fixme: arg checking
    col                => get_layout_3D_collective( layout )
    my_rank            =  sll_f_get_collective_rank( col )
    box                =  get_layout_3D_box( layout, my_rank )
    local_to_global_3D(1) = get_box_3D_i_min(box) + triplet(1) - 1
    local_to_global_3D(2) = get_box_3D_j_min(box) + triplet(2) - 1
    local_to_global_3D(3) = get_box_3D_k_min(box) + triplet(3) - 1
  end function local_to_global_3D

  function local_to_global_4D( layout, quad )
    integer(kind=i32), dimension(1:4)             :: local_to_global_4D
    type(sll_t_layout_4d), pointer              :: layout
    integer(kind=i32), intent(in), dimension(1:4) :: quad
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_4D)                          :: box
    ! fixme: arg checking
    col                => get_layout_4D_collective( layout )
    my_rank            =  sll_f_get_collective_rank( col )
    box                =  get_layout_4D_box( layout, my_rank )
    local_to_global_4D(1) = get_box_4D_i_min(box) + quad(1) - 1
    local_to_global_4D(2) = get_box_4D_j_min(box) + quad(2) - 1
    local_to_global_4D(3) = get_box_4D_k_min(box) + quad(3) - 1
    local_to_global_4D(4) = get_box_4D_l_min(box) + quad(4) - 1
  end function local_to_global_4D

  function local_to_global_5D( layout, quintet )
    integer(kind=i32), dimension(1:5)             :: local_to_global_5D
    type(sll_t_layout_5d), pointer              :: layout
    integer(kind=i32), intent(in), dimension(1:5) :: quintet
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_5D)                          :: box
    ! fixme: arg checking
    col                => get_layout_5D_collective( layout )
    my_rank            =  sll_f_get_collective_rank( col )
    box                =  get_layout_5D_box( layout, my_rank )
    local_to_global_5D(1) = get_box_5D_i_min(box) + quintet(1) - 1
    local_to_global_5D(2) = get_box_5D_j_min(box) + quintet(2) - 1
    local_to_global_5D(3) = get_box_5D_k_min(box) + quintet(3) - 1
    local_to_global_5D(4) = get_box_5D_l_min(box) + quintet(4) - 1
    local_to_global_5D(5) = get_box_5D_m_min(box) + quintet(5) - 1
  end function local_to_global_5D



  function local_to_global_6D( layout, hextet )
    integer(kind=i32), dimension(1:6)             :: local_to_global_6D
    type(sll_t_layout_6d), pointer              :: layout
    integer(kind=i32), intent(in), dimension(1:6) :: hextet
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_6D)                          :: box
    ! fixme: arg checking
    col                => get_layout_6D_collective( layout )
    my_rank            =  sll_f_get_collective_rank( col )
    box                =  get_layout_6D_box( layout, my_rank )
    local_to_global_6D(1) = get_box_6D_i_min(box) + hextet(1) - 1
    local_to_global_6D(2) = get_box_6D_j_min(box) + hextet(2) - 1
    local_to_global_6D(3) = get_box_6D_k_min(box) + hextet(3) - 1
    local_to_global_6D(4) = get_box_6D_l_min(box) + hextet(4) - 1
    local_to_global_6D(5) = get_box_6D_m_min(box) + hextet(5) - 1
    local_to_global_6D(6) = get_box_6D_n_min(box) + hextet(6) - 1
  end function local_to_global_6D


  ! We need to make sure that the decision of choosing '-1' as the return
  ! value when the global index is not available locally does not backfire.
  ! If one decides to use an array with an indexing that contains -1, this 
  ! would be problematic.

  function global_to_local_2D( layout, gtuple )
    intrinsic                             :: associated
    integer(kind=i32), dimension(1:2)             :: global_to_local_2D
    type(sll_t_layout_2d), pointer            :: layout
    integer(kind=i32), dimension(1:2), intent(in) :: gtuple ! global indices, as array
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_2D)                          :: box
    if( .not. associated(get_layout_2D_collective(layout)) ) then
       write (*,'(a)') 'ERROR in global_to_local_2D(), not-associated col'
       stop 'global_to_local_2D'
    end if
    col     => get_layout_2D_collective( layout )
    my_rank =  sll_f_get_collective_rank( col )
    box     =  get_layout_2D_box( layout, my_rank )
    if( (gtuple(1) .ge. get_box_2D_i_min(box)) .and. &
        (gtuple(1) .le. get_box_2D_i_max(box)) .and. &
        (gtuple(2) .ge. get_box_2D_j_min(box)) .and. &
        (gtuple(2) .le. get_box_2D_j_max(box)) ) then  ! the index is present
       global_to_local_2D(1) = gtuple(1) - get_box_2D_i_min(box) + 1
       global_to_local_2D(2) = gtuple(2) - get_box_2D_j_min(box) + 1
    else  ! the index is not present
       global_to_local_2D(1) = -1
       global_to_local_2D(2) = -1
    end if
  end function global_to_local_2D

  function global_to_local_3D( layout, gtuple )
    intrinsic                             :: associated
    integer(kind=i32), dimension(1:3)             :: global_to_local_3D
    type(sll_t_layout_3d), pointer            :: layout
    integer(kind=i32), dimension(1:3), intent(in) :: gtuple ! global indices, as array
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_3D)                          :: box
    if( .not. associated(get_layout_3D_collective(layout)) ) then
       write (*,'(a)') 'ERROR in global_to_local_3D(), not-associated col'
       stop 'global_to_local_3D'
    end if
    col     => get_layout_3D_collective( layout )
    my_rank =  sll_f_get_collective_rank( col )
    box     =  get_layout_3D_box( layout, my_rank )
    if( (gtuple(1) .ge. get_box_3D_i_min(box)) .and. &
         (gtuple(1) .le. get_box_3D_i_max(box)) .and. &
         (gtuple(2) .ge. get_box_3D_j_min(box)) .and. &
         (gtuple(2) .le. get_box_3D_j_max(box)) .and. &
         (gtuple(3) .ge. get_box_3D_k_min(box)) .and. &
         (gtuple(3) .le. get_box_3D_k_max(box)) ) then  ! the index is present
       global_to_local_3D(1) = gtuple(1) - get_box_3D_i_min(box) + 1
       global_to_local_3D(2) = gtuple(2) - get_box_3D_j_min(box) + 1
       global_to_local_3D(3) = gtuple(3) - get_box_3D_k_min(box) + 1
    else  ! the index is not present
       global_to_local_3D(1) = -1
       global_to_local_3D(2) = -1
       global_to_local_3D(3) = -1
    end if
  end function global_to_local_3D

  function global_to_local_4D( layout, gtuple )
    intrinsic                             :: associated
    integer(kind=i32), dimension(1:4)             :: global_to_local_4D
    type(sll_t_layout_4d), pointer            :: layout
    integer(kind=i32), dimension(1:4), intent(in) :: gtuple ! global indices, as array
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_4D)                          :: box
    if( .not. associated(get_layout_4D_collective(layout)) ) then
       write (*,'(a)') 'ERROR in global_to_local_4D(), not-associated col'
       stop 'global_to_local_4D'
    end if
    col     => get_layout_4D_collective( layout )
    my_rank =  sll_f_get_collective_rank( col )
    box     =  get_layout_4D_box( layout, my_rank )
    if( (gtuple(1) .ge. get_box_4D_i_min(box)) .and. &
        (gtuple(1) .le. get_box_4D_i_max(box)) .and. &
        (gtuple(2) .ge. get_box_4D_j_min(box)) .and. &
        (gtuple(2) .le. get_box_4D_j_max(box)) .and. &
        (gtuple(3) .ge. get_box_4D_k_min(box)) .and. &
        (gtuple(3) .le. get_box_4D_k_max(box)) .and. &
        (gtuple(4) .ge. get_box_4D_l_min(box)) .and. &
        (gtuple(4) .le. get_box_4D_l_max(box)) ) then  ! the index is present
       global_to_local_4D(1) = gtuple(1) - get_box_4D_i_min(box) + 1
       global_to_local_4D(2) = gtuple(2) - get_box_4D_j_min(box) + 1
       global_to_local_4D(3) = gtuple(3) - get_box_4D_k_min(box) + 1
       global_to_local_4D(4) = gtuple(4) - get_box_4D_l_min(box) + 1
    else  ! the index is not present
       global_to_local_4D(1) = -1
       global_to_local_4D(2) = -1
       global_to_local_4D(3) = -1
       global_to_local_4D(4) = -1
    end if
  end function global_to_local_4D

  function global_to_local_5D( layout, gtuple )
    intrinsic                             :: associated
    integer(kind=i32), dimension(1:5)             :: global_to_local_5D
    type(sll_t_layout_5d), pointer              :: layout
    integer(kind=i32), dimension(1:5), intent(in) :: gtuple ! global indices, as array
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_5D)                          :: box
    if( .not. associated(get_layout_5D_collective(layout)) ) then
       write (*,'(a)') 'ERROR in global_to_local_5D(), not-associated col'
       stop 'global_to_local_5D'
    end if
    col     => get_layout_5D_collective( layout )
    my_rank =  sll_f_get_collective_rank( col )
    box     =  get_layout_5D_box( layout, my_rank )
    if( (gtuple(1) .ge. get_box_5D_i_min(box)) .and. &
        (gtuple(1) .le. get_box_5D_i_max(box)) .and. &
        (gtuple(2) .ge. get_box_5D_j_min(box)) .and. &
        (gtuple(2) .le. get_box_5D_j_max(box)) .and. &
        (gtuple(3) .ge. get_box_5D_k_min(box)) .and. &
        (gtuple(3) .le. get_box_5D_k_max(box)) .and. &
        (gtuple(4) .ge. get_box_5D_l_min(box)) .and. &
        (gtuple(4) .le. get_box_5D_l_max(box)) .and. &
        (gtuple(5) .ge. get_box_5D_m_min(box)) .and. &
        (gtuple(5) .le. get_box_5D_m_max(box)) ) then  ! the index is present
       global_to_local_5D(1) = gtuple(1) - get_box_5D_i_min(box) + 1
       global_to_local_5D(2) = gtuple(2) - get_box_5D_j_min(box) + 1
       global_to_local_5D(3) = gtuple(3) - get_box_5D_k_min(box) + 1
       global_to_local_5D(4) = gtuple(4) - get_box_5D_l_min(box) + 1
       global_to_local_5D(5) = gtuple(5) - get_box_5D_m_min(box) + 1
    else  ! the index is not present
       print *, 'WARNING: from rank ', my_rank, 'index is not present.'
       call view_box_5D( box )
       print *, 'passed global indices: ', gtuple(:)
       global_to_local_5D(1) = -1
       global_to_local_5D(2) = -1
       global_to_local_5D(3) = -1
       global_to_local_5D(4) = -1
       global_to_local_5D(5) = -1
    end if
  end function global_to_local_5D

  function global_to_local_6D( layout, gtuple )
    intrinsic                             :: associated
    integer(kind=i32), dimension(1:6)             :: global_to_local_6D
    type(sll_t_layout_6d), pointer              :: layout
    integer(kind=i32), dimension(1:6), intent(in) :: gtuple ! global indices, as array
    type(sll_t_collective_t), pointer       :: col
    integer(kind=i32)                             :: my_rank
    type(box_6D)                          :: box
    if( .not. associated(get_layout_6D_collective(layout)) ) then
       write (*,'(a)') 'ERROR in global_to_local_6D(), not-associated col'
       stop 'global_to_local_6D'
    end if
    col     => get_layout_6D_collective( layout )
    my_rank =  sll_f_get_collective_rank( col )
    box     =  get_layout_6D_box( layout, my_rank )
    if( (gtuple(1) .ge. get_box_6D_i_min(box)) .and. &
        (gtuple(1) .le. get_box_6D_i_max(box)) .and. &
        (gtuple(2) .ge. get_box_6D_j_min(box)) .and. &
        (gtuple(2) .le. get_box_6D_j_max(box)) .and. &
        (gtuple(3) .ge. get_box_6D_k_min(box)) .and. &
        (gtuple(3) .le. get_box_6D_k_max(box)) .and. &
        (gtuple(4) .ge. get_box_6D_l_min(box)) .and. &
        (gtuple(4) .le. get_box_6D_l_max(box)) .and. &
        (gtuple(5) .ge. get_box_6D_m_min(box)) .and. &
        (gtuple(5) .le. get_box_6D_m_max(box)) .and. &
        (gtuple(6) .ge. get_box_6D_n_min(box)) .and. &
        (gtuple(6) .le. get_box_6D_n_max(box)) ) then  ! the index is present
       global_to_local_6D(1) = gtuple(1) - get_box_6D_i_min(box) + 1
       global_to_local_6D(2) = gtuple(2) - get_box_6D_j_min(box) + 1
       global_to_local_6D(3) = gtuple(3) - get_box_6D_k_min(box) + 1
       global_to_local_6D(4) = gtuple(4) - get_box_6D_l_min(box) + 1
       global_to_local_6D(5) = gtuple(5) - get_box_6D_m_min(box) + 1
       global_to_local_6D(6) = gtuple(6) - get_box_6D_n_min(box) + 1
    else  ! the index is not present
       print *, 'WARNING: from rank ', my_rank, 'index is not present.'
       call view_box_6D( box )
       print *, 'passed global indices: ', gtuple(:)
       global_to_local_6D(1) = -1
       global_to_local_6D(2) = -1
       global_to_local_6D(3) = -1
       global_to_local_6D(4) = -1
       global_to_local_6D(5) = -1
       global_to_local_6D(6) = -1
    end if
  end function global_to_local_6D


  subroutine view_box_2D( b )
    type(box_2D), intent(in) :: b
    write(*,'(a,i4,a,i4,a,i4,a,i4,a)') &
         '[  [', b%i_min,',', b%i_max,'], [', &
                 b%j_min,',', b%j_max,']  ]'
  end subroutine view_box_2D

  subroutine view_box_3D( b )
    type(box_3D), intent(in) :: b
    write(*,'(a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a)') &
         '[  [', b%i_min,',', b%i_max,'], [', &
                 b%j_min,',', b%j_max,'], [', &
                 b%k_min,',', b%k_max,']  ]'
  end subroutine view_box_3D

  subroutine view_box_4D( b )
    type(box_4D), intent(in) :: b
    write(*,'(a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a)') &
         '[  [', b%i_min,',', b%i_max,'], [', &
                 b%j_min,',', b%j_max,'], [', &
                 b%k_min,',', b%k_max,'], [', &
                 b%l_min,',', b%l_max,'] ]'
  end subroutine view_box_4D

  subroutine view_box_5D( b )
    type(box_5D), intent(in) :: b
    write(*,'(a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a)') &
         '[  [', b%i_min,',', b%i_max,'], [', &
                 b%j_min,',', b%j_max,'], [', &
                 b%k_min,',', b%k_max,'], [', &
                 b%l_min,',', b%l_max,'], [', &
                 b%m_min,',', b%m_max,'] ]'
  end subroutine view_box_5D

  subroutine view_box_6D( b )
    type(box_6D), intent(in) :: b
    write(*,'(a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a,i4,a)') &
         '[  [', b%i_min,',', b%i_max,'], [', &
                 b%j_min,',', b%j_max,'], [', &
                 b%k_min,',', b%k_max,'], [', &
                 b%l_min,',', b%l_max,'], [', &
                 b%m_min,',', b%m_max,'], [', &
                 b%n_min,',', b%n_max,'] ]'
  end subroutine view_box_6D


  subroutine sll_view_lims_2D( layout )
    type(sll_t_layout_2d), pointer :: layout
    integer(kind=i32)                  :: i
    integer(kind=i32)                  :: sz
    sz = sll_o_get_num_nodes( layout )
    print *, 'limits: '
    do i=0,sz-1
       call view_box_2D(get_layout_2D_box( layout, i ))
    end do
    flush( output_unit )
  end subroutine sll_view_lims_2D


  subroutine sll_view_lims_3D( layout )
    type(sll_t_layout_3d), pointer :: layout
    integer(kind=i32)                  :: i
    integer(kind=i32)                  :: sz
    sz = sll_o_get_num_nodes( layout )
    print *, 'limits: '
    do i=0,sz-1
       call view_box_3D(get_layout_3D_box( layout, i ))
    end do
    flush( output_unit )
  end subroutine sll_view_lims_3D

  subroutine sll_view_lims_4D( layout )
    type(sll_t_layout_4d), pointer :: layout
    integer(kind=i32)                  :: i
    integer(kind=i32)                  :: sz
    sz = sll_o_get_num_nodes( layout )
    print *, 'limits: '
    do i=0,sz-1
       call view_box_4D(get_layout_4D_box( layout, i ))
    end do
    flush( output_unit )
  end subroutine sll_view_lims_4D

  subroutine sll_view_lims_5D( layout )
    type(sll_t_layout_5d), pointer :: layout
    integer(kind=i32)                  :: i
    integer(kind=i32)                  :: sz
    sz = sll_o_get_num_nodes( layout )
    print *, 'limits: '
    do i=0,sz-1
       call view_box_5D(get_layout_5D_box( layout, i ))
    end do
    flush( output_unit )
  end subroutine sll_view_lims_5D


  subroutine sll_view_lims_6D( layout )
    type(sll_t_layout_6d), pointer :: layout
    integer(kind=i32)                  :: i
    integer(kind=i32)                  :: sz
    sz = sll_o_get_num_nodes( layout )
    print *, 'limits: '
    do i=0,sz-1
       call view_box_6D(get_layout_6D_box( layout, i ))
    end do
    flush( output_unit )
  end subroutine sll_view_lims_6D


  ! the return value of intersect_boxes() is 'logical', and answers
  ! the question whether the boxes intersect or not. 'ans' is a box with
  ! the actual intersection between the argument boxes. In case that there
  ! is no intersection between the boxes the value [0,0] is returned. 

  function intersect_boxes_2D( b1, b2, ans )
    intrinsic                 :: min, max
    logical                   :: intersect_boxes_2D
    type(box_2D), intent(in)  :: b1, b2
    type(box_2D), intent(out) :: ans
    integer(kind=i32)                 :: loi, hii
    integer(kind=i32)                 :: loj, hij
    integer(kind=i32)                 :: loib1, hiib1
    integer(kind=i32)                 :: lojb1, hijb1
    integer(kind=i32)                 :: loib2, hiib2
    integer(kind=i32)                 :: lojb2, hijb2
    ! FIXME: add error checking, if boxes are null, for instance.
    loib1 = get_box_2D_i_min(b1)
    hiib1 = get_box_2D_i_max(b1)
    lojb1 = get_box_2D_j_min(b1)
    hijb1 = get_box_2D_j_max(b1)

    loib2 = get_box_2D_i_min(b2)
    hiib2 = get_box_2D_i_max(b2)
    lojb2 = get_box_2D_j_min(b2)
    hijb2 = get_box_2D_j_max(b2)

    
    

    loi = max(loib1, loib2)
    hii = min(hiib1, hiib2)
    loj = max(lojb1, lojb2)
    hij = min(hijb1, hijb2)

    if( (loi .gt. hii) .or. (loj .gt. hij) ) then 
       ans%i_min = 0
       ans%i_max = 0
       ans%j_min = 0
       ans%j_max = 0
       intersect_boxes_2D = .false.
    else
       ans%i_min = loi
       ans%i_max = hii
       ans%j_min = loj
       ans%j_max = hij
       intersect_boxes_2D = .true.
    end if
  end function intersect_boxes_2D

  function intersect_boxes_3D( b1, b2, ans )
    intrinsic                 :: min, max
    logical                   :: intersect_boxes_3D
    type(box_3D), intent(in)  :: b1, b2
    type(box_3D), intent(out) :: ans
    integer(kind=i32)                 :: loi, hii
    integer(kind=i32)                 :: loj, hij
    integer(kind=i32)                 :: lok, hik
    integer(kind=i32)                 :: loib1, hiib1
    integer(kind=i32)                 :: lojb1, hijb1
    integer(kind=i32)                 :: lokb1, hikb1
    integer(kind=i32)                 :: loib2, hiib2
    integer(kind=i32)                 :: lojb2, hijb2
    integer(kind=i32)                 :: lokb2, hikb2
    ! FIXME: add error checking, if boxes are null, for instance.
    loib1 = get_box_3D_i_min(b1)
    hiib1 = get_box_3D_i_max(b1)
    lojb1 = get_box_3D_j_min(b1)
    hijb1 = get_box_3D_j_max(b1)
    lokb1 = get_box_3D_k_min(b1)
    hikb1 = get_box_3D_k_max(b1)

    loib2 = get_box_3D_i_min(b2)
    hiib2 = get_box_3D_i_max(b2)
    lojb2 = get_box_3D_j_min(b2)
    hijb2 = get_box_3D_j_max(b2)
    lokb2 = get_box_3D_k_min(b2)
    hikb2 = get_box_3D_k_max(b2)

    
    
    

    loi = max(loib1, loib2)
    hii = min(hiib1, hiib2)
    loj = max(lojb1, lojb2)
    hij = min(hijb1, hijb2)
    lok = max(lokb1, lokb2)
    hik = min(hikb1, hikb2)

    if( (loi .gt. hii) .or. (loj .gt. hij) .or. (lok .gt. hik) ) then 
       ans%i_min = 0
       ans%i_max = 0
       ans%j_min = 0
       ans%j_max = 0
       ans%k_min = 0
       ans%k_max = 0
       intersect_boxes_3D = .false.
    else
       ans%i_min = loi
       ans%i_max = hii
       ans%j_min = loj
       ans%j_max = hij
       ans%k_min = lok
       ans%k_max = hik
       intersect_boxes_3D = .true.
    end if
  end function intersect_boxes_3D

  function intersect_boxes_4D( b1, b2, ans )
    intrinsic                 :: min, max
    logical                   :: intersect_boxes_4D
    type(box_4D), intent(in)  :: b1, b2
    type(box_4D), intent(out) :: ans
    integer(kind=i32)                 :: loi, hii
    integer(kind=i32)                 :: loj, hij
    integer(kind=i32)                 :: lok, hik
    integer(kind=i32)                 :: lol, hil
    integer(kind=i32)                 :: loib1, hiib1
    integer(kind=i32)                 :: lojb1, hijb1
    integer(kind=i32)                 :: lokb1, hikb1
    integer(kind=i32)                 :: lolb1, hilb1
    integer(kind=i32)                 :: loib2, hiib2
    integer(kind=i32)                 :: lojb2, hijb2
    integer(kind=i32)                 :: lokb2, hikb2
    integer(kind=i32)                 :: lolb2, hilb2

    ! FIXME: add error checking, if boxes are null, for instance.
    loib1 = get_box_4D_i_min(b1)
    hiib1 = get_box_4D_i_max(b1)
    lojb1 = get_box_4D_j_min(b1)
    hijb1 = get_box_4D_j_max(b1)
    lokb1 = get_box_4D_k_min(b1)
    hikb1 = get_box_4D_k_max(b1)
    lolb1 = get_box_4D_l_min(b1)
    hilb1 = get_box_4D_l_max(b1)

    loib2 = get_box_4D_i_min(b2)
    hiib2 = get_box_4D_i_max(b2)
    lojb2 = get_box_4D_j_min(b2)
    hijb2 = get_box_4D_j_max(b2)
    lokb2 = get_box_4D_k_min(b2)
    hikb2 = get_box_4D_k_max(b2)
    lolb2 = get_box_4D_l_min(b2)
    hilb2 = get_box_4D_l_max(b2)

    
    
    
    

    loi = max(loib1, loib2)
    hii = min(hiib1, hiib2)
    loj = max(lojb1, lojb2)
    hij = min(hijb1, hijb2)
    lok = max(lokb1, lokb2)
    hik = min(hikb1, hikb2)
    lol = max(lolb1, lolb2)
    hil = min(hilb1, hilb2)

    if( (loi .gt. hii) .or. (loj .gt. hij) .or. (lok .gt. hik) .or. &
        (lol .gt. hil) ) then 
       ans%i_min = 0
       ans%i_max = 0
       ans%j_min = 0
       ans%j_max = 0
       ans%k_min = 0
       ans%k_max = 0
       ans%l_min = 0
       ans%l_max = 0
       intersect_boxes_4D = .false.
    else
       ans%i_min = loi
       ans%i_max = hii
       ans%j_min = loj
       ans%j_max = hij
       ans%k_min = lok
       ans%k_max = hik
       ans%l_min = lol
       ans%l_max = hil
       intersect_boxes_4D = .true.
    end if
  end function intersect_boxes_4D



  function intersect_boxes_5D( b1, b2, ans )
    intrinsic                 :: min, max
    logical                   :: intersect_boxes_5D
    type(box_5D), intent(in)  :: b1, b2
    type(box_5D), intent(out) :: ans
    integer(kind=i32)                 :: loi, hii
    integer(kind=i32)                 :: loj, hij
    integer(kind=i32)                 :: lok, hik
    integer(kind=i32)                 :: lol, hil
    integer(kind=i32)                 :: lom, him
    integer(kind=i32)                 :: loib1, hiib1
    integer(kind=i32)                 :: lojb1, hijb1
    integer(kind=i32)                 :: lokb1, hikb1
    integer(kind=i32)                 :: lolb1, hilb1
    integer(kind=i32)                 :: lomb1, himb1

    integer(kind=i32)                 :: loib2, hiib2
    integer(kind=i32)                 :: lojb2, hijb2
    integer(kind=i32)                 :: lokb2, hikb2
    integer(kind=i32)                 :: lolb2, hilb2
    integer(kind=i32)                 :: lomb2, himb2

    ! FIXME: add error checking, if boxes are null, for instance.
    loib1 = get_box_5D_i_min(b1)
    hiib1 = get_box_5D_i_max(b1)
    lojb1 = get_box_5D_j_min(b1)
    hijb1 = get_box_5D_j_max(b1)
    lokb1 = get_box_5D_k_min(b1)
    hikb1 = get_box_5D_k_max(b1)
    lolb1 = get_box_5D_l_min(b1)
    hilb1 = get_box_5D_l_max(b1)
    lomb1 = get_box_5D_m_min(b1)
    himb1 = get_box_5D_m_max(b1)

    loib2 = get_box_5D_i_min(b2)
    hiib2 = get_box_5D_i_max(b2)
    lojb2 = get_box_5D_j_min(b2)
    hijb2 = get_box_5D_j_max(b2)
    lokb2 = get_box_5D_k_min(b2)
    hikb2 = get_box_5D_k_max(b2)
    lolb2 = get_box_5D_l_min(b2)
    hilb2 = get_box_5D_l_max(b2)
    lomb2 = get_box_5D_m_min(b2)
    himb2 = get_box_5D_m_max(b2)

    
    
    
    
    

    loi = max(loib1, loib2)
    hii = min(hiib1, hiib2)
    loj = max(lojb1, lojb2)
    hij = min(hijb1, hijb2)
    lok = max(lokb1, lokb2)
    hik = min(hikb1, hikb2)
    lol = max(lolb1, lolb2)
    hil = min(hilb1, hilb2)
    lom = max(lomb1, lomb2)
    him = min(himb1, himb2)

    if( (loi .gt. hii) .or. (loj .gt. hij) .or. (lok .gt. hik) .or. &
        (lol .gt. hil) .or. (lom .gt. him) ) then 
       ans%i_min = 0
       ans%i_max = 0
       ans%j_min = 0
       ans%j_max = 0
       ans%k_min = 0
       ans%k_max = 0
       ans%l_min = 0
       ans%l_max = 0
       ans%m_min = 0
       ans%m_max = 0
       intersect_boxes_5D = .false.
    else
       ans%i_min = loi
       ans%i_max = hii
       ans%j_min = loj
       ans%j_max = hij
       ans%k_min = lok
       ans%k_max = hik
       ans%l_min = lol
       ans%l_max = hil
       ans%m_min = lom
       ans%m_max = him
       intersect_boxes_5D = .true.
    end if
  end function intersect_boxes_5D






  function intersect_boxes_6D( b1, b2, ans )
    intrinsic                 :: min, max
    logical                   :: intersect_boxes_6D
    type(box_6D), intent(in)  :: b1, b2
    type(box_6D), intent(out) :: ans
    integer(kind=i32)                 :: loi, hii
    integer(kind=i32)                 :: loj, hij
    integer(kind=i32)                 :: lok, hik
    integer(kind=i32)                 :: lol, hil
    integer(kind=i32)                 :: lom, him
    integer(kind=i32)                 :: lon, hin
    integer(kind=i32)                 :: loib1, hiib1
    integer(kind=i32)                 :: lojb1, hijb1
    integer(kind=i32)                 :: lokb1, hikb1
    integer(kind=i32)                 :: lolb1, hilb1
    integer(kind=i32)                 :: lomb1, himb1
    integer(kind=i32)                 :: lonb1, hinb1

    integer(kind=i32)                 :: loib2, hiib2
    integer(kind=i32)                 :: lojb2, hijb2
    integer(kind=i32)                 :: lokb2, hikb2
    integer(kind=i32)                 :: lolb2, hilb2
    integer(kind=i32)                 :: lomb2, himb2
    integer(kind=i32)                 :: lonb2, hinb2

    ! FIXME: add error checking, if boxes are null, for instance.
    loib1 = get_box_6D_i_min(b1)
    hiib1 = get_box_6D_i_max(b1)
    lojb1 = get_box_6D_j_min(b1)
    hijb1 = get_box_6D_j_max(b1)
    lokb1 = get_box_6D_k_min(b1)
    hikb1 = get_box_6D_k_max(b1)
    lolb1 = get_box_6D_l_min(b1)
    hilb1 = get_box_6D_l_max(b1)
    lomb1 = get_box_6D_m_min(b1)
    himb1 = get_box_6D_m_max(b1)
    lonb1 = get_box_6D_n_min(b1)
    hinb1 = get_box_6D_n_max(b1)

    loib2 = get_box_6D_i_min(b2)
    hiib2 = get_box_6D_i_max(b2)
    lojb2 = get_box_6D_j_min(b2)
    hijb2 = get_box_6D_j_max(b2)
    lokb2 = get_box_6D_k_min(b2)
    hikb2 = get_box_6D_k_max(b2)
    lolb2 = get_box_6D_l_min(b2)
    hilb2 = get_box_6D_l_max(b2)
    lomb2 = get_box_6D_m_min(b2)
    himb2 = get_box_6D_m_max(b2)
    lonb2 = get_box_6D_n_min(b2)
    hinb2 = get_box_6D_n_max(b2)

    
    
    
    
    
    

    loi = max(loib1, loib2)
    hii = min(hiib1, hiib2)
    loj = max(lojb1, lojb2)
    hij = min(hijb1, hijb2)
    lok = max(lokb1, lokb2)
    hik = min(hikb1, hikb2)
    lol = max(lolb1, lolb2)
    hil = min(hilb1, hilb2)
    lom = max(lomb1, lomb2)
    him = min(himb1, himb2)
    lon = max(lonb1, lonb2)
    hin = min(hinb1, hinb2)

    if( (loi .gt. hii) .or. (loj .gt. hij) .or. (lok .gt. hik) .or. &
        (lol .gt. hil) .or. (lom .gt. him) .or. (lon .gt. hin) ) then 
       ans%i_min = 0
       ans%i_max = 0
       ans%j_min = 0
       ans%j_max = 0
       ans%k_min = 0
       ans%k_max = 0
       ans%l_min = 0
       ans%l_max = 0
       ans%m_min = 0
       ans%m_max = 0
       ans%n_min = 0
       ans%n_max = 0
       intersect_boxes_6D = .false.
    else
       ans%i_min = loi
       ans%i_max = hii
       ans%j_min = loj
       ans%j_max = hij
       ans%k_min = lok
       ans%k_max = hik
       ans%l_min = lol
       ans%l_max = hil
       ans%m_min = lom
       ans%m_max = him
       ans%n_min = lon
       ans%n_max = hin
       intersect_boxes_6D = .true.
    end if
  end function intersect_boxes_6D


  function count_elements_in_box_2D( box )
    integer(kind=i32)                 :: count_elements_in_box_2D
    type(box_2D), intent (in) :: box
    integer(kind=i32)                 :: irange
    integer(kind=i32)                 :: jrange
    irange = get_box_2D_i_max(box) - get_box_2D_i_min(box) + 1
    jrange = get_box_2D_j_max(box) - get_box_2D_j_min(box) + 1
    count_elements_in_box_2D = irange*jrange
  end function count_elements_in_box_2D

  function count_elements_in_box_3D( box )
    integer(kind=i32)                 :: count_elements_in_box_3D
    type(box_3D), intent (in) :: box
    integer(kind=i32)                 :: irange
    integer(kind=i32)                 :: jrange
    integer(kind=i32)                 :: krange
    irange = get_box_3D_i_max(box) - get_box_3D_i_min(box) + 1
    jrange = get_box_3D_j_max(box) - get_box_3D_j_min(box) + 1
    krange = get_box_3D_k_max(box) - get_box_3D_k_min(box) + 1
    count_elements_in_box_3D = irange*jrange*krange
  end function count_elements_in_box_3D

  function count_elements_in_box_4D( box )
    integer(kind=i32)                 :: count_elements_in_box_4D
    type(box_4D), intent (in) :: box
    integer(kind=i32)                 :: irange
    integer(kind=i32)                 :: jrange
    integer(kind=i32)                 :: krange
    integer(kind=i32)                 :: lrange
    irange = get_box_4D_i_max(box) - get_box_4D_i_min(box) + 1
    jrange = get_box_4D_j_max(box) - get_box_4D_j_min(box) + 1
    krange = get_box_4D_k_max(box) - get_box_4D_k_min(box) + 1
    lrange = get_box_4D_l_max(box) - get_box_4D_l_min(box) + 1
    count_elements_in_box_4D = irange*jrange*krange*lrange
  end function count_elements_in_box_4D


  function count_elements_in_box_5D( box )
    integer(kind=i32)                 :: count_elements_in_box_5D
    type(box_5D), intent (in) :: box
    integer(kind=i32)                 :: irange
    integer(kind=i32)                 :: jrange
    integer(kind=i32)                 :: krange
    integer(kind=i32)                 :: lrange
    integer(kind=i32)                 :: mrange
    irange = get_box_5D_i_max(box) - get_box_5D_i_min(box) + 1
    jrange = get_box_5D_j_max(box) - get_box_5D_j_min(box) + 1
    krange = get_box_5D_k_max(box) - get_box_5D_k_min(box) + 1
    lrange = get_box_5D_l_max(box) - get_box_5D_l_min(box) + 1
    mrange = get_box_5D_m_max(box) - get_box_5D_m_min(box) + 1
    count_elements_in_box_5D = irange*jrange*krange*lrange*mrange
  end function count_elements_in_box_5D



  function count_elements_in_box_6D( box )
    integer(kind=i32)                 :: count_elements_in_box_6D
    type(box_6D), intent (in) :: box
    integer(kind=i32)                 :: irange
    integer(kind=i32)                 :: jrange
    integer(kind=i32)                 :: krange
    integer(kind=i32)                 :: lrange
    integer(kind=i32)                 :: mrange
    integer(kind=i32)                 :: nrange
    irange = get_box_6D_i_max(box) - get_box_6D_i_min(box) + 1
    jrange = get_box_6D_j_max(box) - get_box_6D_j_min(box) + 1
    krange = get_box_6D_k_max(box) - get_box_6D_k_min(box) + 1
    lrange = get_box_6D_l_max(box) - get_box_6D_l_min(box) + 1
    mrange = get_box_6D_m_max(box) - get_box_6D_m_min(box) + 1
    nrange = get_box_6D_n_max(box) - get_box_6D_n_min(box) + 1
    count_elements_in_box_6D = irange*jrange*krange*lrange*mrange*nrange
  end function count_elements_in_box_6D


  subroutine compute_local_sizes_6d( &
    layout, &
    loc_sz_i, &
    loc_sz_j, &
    loc_sz_k, &
    loc_sz_l, &
    loc_sz_m, &
    loc_sz_n )

    type(sll_t_layout_6d), pointer :: layout
    integer(kind=i32), intent(out) :: loc_sz_i
    integer(kind=i32), intent(out) :: loc_sz_j
    integer(kind=i32), intent(out) :: loc_sz_k
    integer(kind=i32), intent(out) :: loc_sz_l
    integer(kind=i32), intent(out) :: loc_sz_m
    integer(kind=i32), intent(out) :: loc_sz_n
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max
    integer(kind=i32) :: m_min
    integer(kind=i32) :: m_max
    integer(kind=i32) :: n_min
    integer(kind=i32) :: n_max
    integer(kind=i32) :: my_rank
    if( .not. associated(layout) ) then
       print *, 'not-associated layout passed to compute_local_sizes_6d'
       print *, 'Exiting...'
       STOP
    end if
    my_rank = sll_f_get_collective_rank(get_layout_6D_collective(layout))
    i_min = get_layout_6D_i_min( layout, my_rank )
    i_max = get_layout_6D_i_max( layout, my_rank )
    j_min = get_layout_6D_j_min( layout, my_rank )
    j_max = get_layout_6D_j_max( layout, my_rank )
    k_min = get_layout_6D_k_min( layout, my_rank )
    k_max = get_layout_6D_k_max( layout, my_rank )
    l_min = get_layout_6D_l_min( layout, my_rank )
    l_max = get_layout_6D_l_max( layout, my_rank )
    m_min = get_layout_6D_m_min( layout, my_rank )
    m_max = get_layout_6D_m_max( layout, my_rank )
    n_min = get_layout_6D_n_min( layout, my_rank )
    n_max = get_layout_6D_n_max( layout, my_rank )
    loc_sz_i = i_max - i_min + 1
    loc_sz_j = j_max - j_min + 1
    loc_sz_k = k_max - k_min + 1
    loc_sz_l = l_max - l_min + 1
    loc_sz_m = m_max - m_min + 1
    loc_sz_n = n_max - n_min + 1
  end subroutine compute_local_sizes_6d


  subroutine compute_local_sizes_5d( &
    layout, &
    loc_sz_i, &
    loc_sz_j, &
    loc_sz_k, &
    loc_sz_l, &
    loc_sz_m )

    type(sll_t_layout_5d), pointer :: layout
    integer(kind=i32), intent(out) :: loc_sz_i
    integer(kind=i32), intent(out) :: loc_sz_j
    integer(kind=i32), intent(out) :: loc_sz_k
    integer(kind=i32), intent(out) :: loc_sz_l
    integer(kind=i32), intent(out) :: loc_sz_m
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max
    integer(kind=i32) :: m_min
    integer(kind=i32) :: m_max
    integer(kind=i32) :: my_rank
    if( .not. associated(layout) ) then
       print *, 'not-associated layout passed to compute_local_sizes_5d'
       print *, 'Exiting...'
       STOP
    end if
    my_rank = sll_f_get_collective_rank(get_layout_5D_collective(layout))
    i_min = get_layout_5D_i_min( layout, my_rank )
    i_max = get_layout_5D_i_max( layout, my_rank )
    j_min = get_layout_5D_j_min( layout, my_rank )
    j_max = get_layout_5D_j_max( layout, my_rank )
    k_min = get_layout_5D_k_min( layout, my_rank )
    k_max = get_layout_5D_k_max( layout, my_rank )
    l_min = get_layout_5D_l_min( layout, my_rank )
    l_max = get_layout_5D_l_max( layout, my_rank )
    m_min = get_layout_5D_m_min( layout, my_rank )
    m_max = get_layout_5D_m_max( layout, my_rank )
    loc_sz_i = i_max - i_min + 1
    loc_sz_j = j_max - j_min + 1
    loc_sz_k = k_max - k_min + 1
    loc_sz_l = l_max - l_min + 1
    loc_sz_m = m_max - m_min + 1
  end subroutine compute_local_sizes_5d




  subroutine compute_local_sizes_4d( &
    layout, &
    loc_sz_i, &
    loc_sz_j, &
    loc_sz_k, &
    loc_sz_l )

    type(sll_t_layout_4d), pointer :: layout
    integer(kind=i32), intent(out) :: loc_sz_i
    integer(kind=i32), intent(out) :: loc_sz_j
    integer(kind=i32), intent(out) :: loc_sz_k
    integer(kind=i32), intent(out) :: loc_sz_l
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: l_min
    integer(kind=i32) :: l_max
    integer(kind=i32) :: my_rank
    if( .not. associated(layout) ) then
       print *, 'not-associated layout passed to compute_local_sizes_4d'
       print *, 'Exiting...'
       STOP
    end if
    my_rank = sll_f_get_collective_rank(get_layout_4D_collective(layout))
    i_min = get_layout_4D_i_min( layout, my_rank )
    i_max = get_layout_4D_i_max( layout, my_rank )
    j_min = get_layout_4D_j_min( layout, my_rank )
    j_max = get_layout_4D_j_max( layout, my_rank )
    k_min = get_layout_4D_k_min( layout, my_rank )
    k_max = get_layout_4D_k_max( layout, my_rank )
    l_min = get_layout_4D_l_min( layout, my_rank )
    l_max = get_layout_4D_l_max( layout, my_rank )
    loc_sz_i = i_max - i_min + 1
    loc_sz_j = j_max - j_min + 1
    loc_sz_k = k_max - k_min + 1
    loc_sz_l = l_max - l_min + 1
  end subroutine compute_local_sizes_4d

  subroutine compute_local_sizes_3d( &
    layout, &
    loc_sz_i, &
    loc_sz_j, &
    loc_sz_k )

    type(sll_t_layout_3d), pointer :: layout
    integer(kind=i32), intent(out) :: loc_sz_i
    integer(kind=i32), intent(out) :: loc_sz_j
    integer(kind=i32), intent(out) :: loc_sz_k
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: k_min
    integer(kind=i32) :: k_max
    integer(kind=i32) :: my_rank
    if( .not. associated(layout) ) then
       print *, 'not-associated layout passed to compute_local_sizes_3d'
       print *, 'Exiting...'
       STOP
    end if
    my_rank = sll_f_get_collective_rank(get_layout_3D_collective(layout))
    i_min = get_layout_3D_i_min( layout, my_rank )
    i_max = get_layout_3D_i_max( layout, my_rank )
    j_min = get_layout_3D_j_min( layout, my_rank )
    j_max = get_layout_3D_j_max( layout, my_rank )
    k_min = get_layout_3D_k_min( layout, my_rank )
    k_max = get_layout_3D_k_max( layout, my_rank )
    loc_sz_i = i_max - i_min + 1
    loc_sz_j = j_max - j_min + 1
    loc_sz_k = k_max - k_min + 1
  end subroutine compute_local_sizes_3d

  subroutine compute_local_sizes_2d( &
    layout, &
    loc_sz_i, &
    loc_sz_j )

    type(sll_t_layout_2d), pointer :: layout
    integer(kind=i32), intent(out) :: loc_sz_i
    integer(kind=i32), intent(out) :: loc_sz_j
    integer(kind=i32) :: i_min
    integer(kind=i32) :: i_max
    integer(kind=i32) :: j_min
    integer(kind=i32) :: j_max
    integer(kind=i32) :: my_rank
    if( .not. associated(layout) ) then
       print *, 'not-associated layout passed to compute_local_sizes_2d'
       print *, 'Exiting...'
       STOP
    end if
    my_rank = sll_f_get_collective_rank(get_layout_2D_collective(layout))
    i_min = get_layout_2D_i_min( layout, my_rank )
    i_max = get_layout_2D_i_max( layout, my_rank )
    j_min = get_layout_2D_j_min( layout, my_rank )
    j_max = get_layout_2D_j_max( layout, my_rank )
    loc_sz_i = i_max - i_min + 1
    loc_sz_j = j_max - j_min + 1
  end subroutine compute_local_sizes_2d

  !***************************************************************************
  !
  ! Functions that operate with more than one dimension.
  !
  ! We've found that sometimes it may be necessary to interpret a layout of
  ! a given dimension, say 4D, as a layout of a different dimension, like 2D.
  ! For this operation to be valid some conditions need to be met. For
  ! example, in the 4D to 2D case, some array dimensions should be equal to 1
  ! in order to reinterpret the layout properly. Here we just proceed to add
  ! these routines as we need them.
  !
  !***************************************************************************

  !> @brief
  !> Create new layout from other layout properties.
  !> @details
  !> layout_2D_from_layout_4D() takes a 4D layout that describes the distribution
  !> of a 4D array of dimensions npx1 X npx2 X 1 X 1 and returns a 2D layout,
  !> defined over the same collective, which describes the distribution of a 2D
  !> array of dimensions npx1 X npx2. Note that it assumes that it is the last
  !> two dimensions which are of size 1.
  !> 
  !> This function is special in that it allocates the new layout to be returned.
  !> So the usual interface of declaring the layout, calling new_layout() and
  !> then initializing is not followed. This irregularity is itself a bit of
  !> a problem, but may be a sign that the usual way to allocate and initialize
  !> layouts might need to be merged.
  !> @returns a new layout allocated.
  function sll_f_new_layout_2d_from_layout_4d( layout4d )
    type(sll_t_layout_2d), pointer :: sll_f_new_layout_2d_from_layout_4d
    type(sll_t_layout_4d), pointer :: layout4d
    type(sll_t_collective_t), pointer :: coll
    integer(kind=i32)                :: coll_size
    integer(kind=i32)                :: process
    integer(kind=i32)                :: i_min
    integer(kind=i32)                :: i_max
    integer(kind=i32)                :: j_min
    integer(kind=i32)                :: j_max
    integer(kind=i32)                :: k_min
    integer(kind=i32)                :: k_max
    integer(kind=i32)                :: l_min
    integer(kind=i32)                :: l_max

    
    coll                     => sll_o_get_layout_collective( layout4d )
    coll_size                = sll_f_get_collective_size( coll )
    sll_f_new_layout_2d_from_layout_4d => sll_f_new_layout_2d( coll )
    ! Just copy the contents of the layout
    do process=0, coll_size-1
       i_min = sll_o_get_layout_i_min( layout4d, process )
       i_max = sll_o_get_layout_i_max( layout4d, process )
       j_min = sll_o_get_layout_j_min( layout4d, process )
       j_max = sll_o_get_layout_j_max( layout4d, process )
       call sll_o_set_layout_i_min( sll_f_new_layout_2d_from_layout_4d, process, i_min )
       call sll_o_set_layout_i_max( sll_f_new_layout_2d_from_layout_4d, process, i_max )
       call sll_o_set_layout_j_min( sll_f_new_layout_2d_from_layout_4d, process, j_min )
       call sll_o_set_layout_j_max( sll_f_new_layout_2d_from_layout_4d, process, j_max )
       ! For safety, check if there is any loss of information
       k_min = sll_o_get_layout_k_min( layout4d, process )
       k_max = sll_o_get_layout_k_max( layout4d, process )
       l_min = sll_o_get_layout_l_min( layout4d, process )
       l_max = sll_o_get_layout_l_max( layout4d, process )
!!$       if( (k_min .ne. 1) .or. (k_max .ne. 1) .or. &
!!$           (l_min .ne. 1) .or. (l_max .ne. 1) ) then
!!$           print *, 'WARNING, sll_f_new_layout_2d_from_layout_4d(): there is loss ',&
!!$                'of information in the convertion. This may be the intention',&
!!$                ' if you are essentially projecting one layout onto another.',&
!!$                ' Printing values:'
!!$           print *, 'k_min = ', k_min
!!$           print *, 'k_max = ', k_max
!!$           print *, 'l_min = ', l_min
!!$           print *, 'l_max = ', l_max
!!$        end if
    end do
  end function sll_f_new_layout_2d_from_layout_4d

  !> @returns a new layout allocated.
  function sll_f_new_layout_3d_from_layout_4d( layout4d )
    type(sll_t_layout_3d), pointer :: sll_f_new_layout_3d_from_layout_4d
    type(sll_t_layout_4d), pointer :: layout4d
    type(sll_t_collective_t), pointer :: coll
    integer(kind=i32)                :: coll_size
    integer(kind=i32)                :: process
    integer(kind=i32)                :: i_min
    integer(kind=i32)                :: i_max
    integer(kind=i32)                :: j_min
    integer(kind=i32)                :: j_max
    integer(kind=i32)                :: k_min
    integer(kind=i32)                :: k_max
    integer(kind=i32)                :: l_min
    integer(kind=i32)                :: l_max

    
    coll                         => sll_o_get_layout_collective( layout4d )
    coll_size                    = sll_f_get_collective_size( coll )
    sll_f_new_layout_3d_from_layout_4d => sll_f_new_layout_3d( coll )
    ! Just copy the contents of the layout
    do process=0, coll_size-1
       i_min = sll_o_get_layout_i_min( layout4d, process )
       i_max = sll_o_get_layout_i_max( layout4d, process )
       j_min = sll_o_get_layout_j_min( layout4d, process )
       j_max = sll_o_get_layout_j_max( layout4d, process )
       k_min = sll_o_get_layout_k_min( layout4d, process )
       k_max = sll_o_get_layout_k_max( layout4d, process )
       call sll_o_set_layout_i_min( sll_f_new_layout_3d_from_layout_4d, process, i_min )
       call sll_o_set_layout_i_max( sll_f_new_layout_3d_from_layout_4d, process, i_max )
       call sll_o_set_layout_j_min( sll_f_new_layout_3d_from_layout_4d, process, j_min )
       call sll_o_set_layout_j_max( sll_f_new_layout_3d_from_layout_4d, process, j_max )
       call sll_o_set_layout_k_min( sll_f_new_layout_3d_from_layout_4d, process, k_min )
       call sll_o_set_layout_k_max( sll_f_new_layout_3d_from_layout_4d, process, k_max )
       ! For safety, check if there is any loss of information
       l_min = sll_o_get_layout_l_min( layout4d, process )
       l_max = sll_o_get_layout_l_max( layout4d, process )
       if(  &
           (l_min .ne. 1) .or. (l_max .ne. 1) ) then
           !print *, 'WARNING, layout_3D_from_layout_4D(): there is loss of ',&
           !     'information in the convertion. Printing values:'
           !print *, 'l_min = ', l_min
           !print *, 'l_max = ', l_max
        end if
    end do
  end function sll_f_new_layout_3d_from_layout_4d





  !> Create file for plotmtv to display the MPI topology
  subroutine write_to_file( layout, fname )

     type(sll_t_layout_2d), pointer  :: layout
     character(len=*)          :: fname
     character(len=4)          :: cproc

     integer(kind=i32)  :: i, sz, loc_sz_i, loc_sz_j

     call compute_local_sizes_2d( layout, loc_sz_i, loc_sz_j)

     open(44,file=fname//".mtv")
     write(44,*)"$DATA=CURVE2D"
     write(44,*)"%toplabel = 'MPI topology'" 
     write(44,*)"%subtitle = '"//fname//"'"
     write(44,*)"%equalscale=T"
     write(44,*)"%linetype = 0"
     write(44,*)"%filltype = 4" 
     write(44,*)"%xmin=",1, " xmax=",layout%global_sz1
     write(44,*)"%ymin=",1, " ymax=",layout%global_sz2
     write(44,*)"0.0 0.0"
     write(44,*)"0.0 1.0"
     write(44,*)"1.0 1.0"
     write(44,*)"1.0 0.0"
     sz = sll_o_get_num_nodes( layout )
     do i=0,sz-1
        call sll_s_int2string(i, cproc)
        write(44,*)"@ rectangle x1=", sll_o_get_layout_i_min(layout,i), &
        &          " y1=",  sll_o_get_layout_j_min(layout,i), " z1=0.0 "
        write(44,*)" x2=", sll_o_get_layout_i_max(layout,i), &
        &          " y2=", sll_o_get_layout_j_max(layout,i), " z2=0.0 "
        write(44,*) "fillcolor="//cproc//" filltype=1 linelabel='"//cproc//"'"
     end do

     write(44,"('$END')")
     close(44)

  end subroutine write_to_file

!------------------------------------------------------------------------------!
  ! Procedures to find decomposition of 

  !> Helper function checking if number is divisible by two
  function divisible_by_two( num )
    logical :: divisible_by_two
    integer(kind=i32), intent(in) :: num
    if(modulo(num,2) == 0) then
       divisible_by_two = .true.
    else
       divisible_by_two = .false.
    end if
  end function divisible_by_two
  
  !> Helper function checking if number is divisible by three
  function divisible_by_three( num )
    logical :: divisible_by_three
    integer(kind=i32), intent(in) :: num
    if(modulo(num,3) == 0) then
       divisible_by_three = .true.
    else
       divisible_by_three = .false.
    end if
  end function divisible_by_three

  !> @brief helper function to find proper partitioning of processors for 3D array
  !> @details given a number that is a power of two, we decompose it in 3 factors 
  !> intended to be as close to each other as possible, while still keeping
  !> them factors of two as well.
  !> @param [in] num_procs Number of processors to be distributed
  !> @param [out] decomp_procs Number of processors along dimension one, two, three
  subroutine sll_s_factorize_in_three_powers_of_two( &
       num_procs, &
       decomp_procs_1, &
       decomp_procs_2, &
       decomp_procs_3 )
    integer(kind=i32), intent(in)  :: num_procs
    integer(kind=i32), intent(out) :: decomp_procs_1
    integer(kind=i32), intent(out) :: decomp_procs_2
    integer(kind=i32), intent(out) :: decomp_procs_3

    integer(kind=i32)  :: exponent
    integer(kind=i32)  :: tmpi

    
    exponent = int(log(real(num_procs))/log(2.0))
    if( (exponent > 0) .and. divisible_by_three(exponent) ) then
       tmpi = exponent/3
       decomp_procs_1 = 2**tmpi
       decomp_procs_2 = 2**tmpi
       decomp_procs_3 = 2**tmpi
    else
       if( exponent == 0 ) then
          decomp_procs_1   = 1
          decomp_procs_2   = 1
          decomp_procs_3   = 1
       else if( exponent == 1 ) then
          decomp_procs_1   = 2
          decomp_procs_2   = 1
          decomp_procs_3   = 1
       else if( divisible_by_three(exponent-1) ) then
          tmpi = (exponent-1)/3
          decomp_procs_1   = 2**tmpi
          decomp_procs_2   = 2**tmpi
          decomp_procs_3   = 2**(tmpi+1)
       else if( divisible_by_three(exponent+1) ) then
          tmpi = (exponent+1)/3
          decomp_procs_1   = 2**tmpi
          decomp_procs_2   = 2**tmpi
          decomp_procs_3   = 2**(tmpi-1)
       end if
    end if
  end subroutine sll_s_factorize_in_three_powers_of_two


  !> @brief helper function to find proper partitioning of processors for 2D array
  !> @details given a number that is a power of two, we decompose it in 2 factors 
  !> intended to be as close to each other as possible, while still keeping
  !> them factors of two as well.
  !> @param [in] num_procs Number of processors to be distributed
  !> @param [out] f1 Number of processors along dimension one
  !> @param [out] f2 Number of processors along dimension two
  subroutine sll_s_factorize_in_two_powers_of_two( num_procs, f1, f2 )
    integer(kind=i32), intent(in)  :: num_procs
    integer(kind=i32), intent(out) :: f1
    integer(kind=i32), intent(out) :: f2
    integer(kind=i32)  :: exponent
    integer(kind=i32)  :: tmpi

    
    exponent = int(log(real(num_procs))/log(2.0))
    if( (exponent > 0) .and. divisible_by_two(exponent) ) then
       tmpi = exponent/2
       f1 = 2**tmpi
       f2 = 2**tmpi
    else
       if( exponent == 0 ) then
          f1   = 1
          f2   = 1
       else 
          tmpi = (exponent-1)/2
          f1   = 2**((exponent-1)/2)
          f2   = 2**((exponent+1)/2)
       end if
    end if
  end subroutine sll_s_factorize_in_two_powers_of_two


  ! Array getter functions to simplify 6d computations
  !< Getter function for first index on current processor for each dimension
  subroutine get_layout_min_indices_6d(layout, mpi_rank, indices)
    type(sll_t_layout_6D), intent(in) :: layout !< layout object
    integer(kind=i32),       intent(in) :: mpi_rank !< mpi rank of processor
    integer(kind=i32),       intent(out):: indices(6) !< first index local to processor

    indices(1) = layout%boxes(mpi_rank)%i_min
    indices(2) = layout%boxes(mpi_rank)%j_min
    indices(3) = layout%boxes(mpi_rank)%k_min
    indices(4) = layout%boxes(mpi_rank)%l_min
    indices(5) = layout%boxes(mpi_rank)%m_min
    indices(6) = layout%boxes(mpi_rank)%n_min

  end subroutine get_layout_min_indices_6d

  !< Getter function for last index on current processor for each dimension
  subroutine get_layout_max_indices_6d(layout, mpi_rank, indices)
    type(sll_t_layout_6d), intent(in) :: layout !< layout object
    integer(kind=i32),       intent(in) :: mpi_rank !< mpi rank of processor
    integer(kind=i32),       intent(out):: indices(6) !< first index local to processor

    indices(1) = layout%boxes(mpi_rank)%i_max
    indices(2) = layout%boxes(mpi_rank)%j_max
    indices(3) = layout%boxes(mpi_rank)%k_max
    indices(4) = layout%boxes(mpi_rank)%l_max
    indices(5) = layout%boxes(mpi_rank)%m_max
    indices(6) = layout%boxes(mpi_rank)%n_max

  end subroutine get_layout_max_indices_6d

  !< Getter function for local sizes on processor
  subroutine get_layout_local_sizes_6d(layout, mpi_rank, local_sizes)
    type(sll_t_layout_6d), intent(in) :: layout !< layout object
    integer(kind=i32),       intent(in) :: mpi_rank !< mpi rank of processor
    integer(kind=i32),       intent(out):: local_sizes(6) !< first index local to processor

    integer(kind=i32) :: indices_min(6)

    call get_layout_min_indices_6d(layout, mpi_rank, indices_min)
    call get_layout_max_indices_6d(layout, mpi_rank, local_sizes)
    local_sizes = local_sizes - indices_min + 1


  end subroutine get_layout_local_sizes_6d



end module sll_m_remapper

