\documentclass[]{report}   % list options between brackets
\usepackage{amsmath, verbatim}    
\usepackage{color}

% user-defined commands here

\begin{document}

\title{Selalib Notes - DRAFT -}   
\author{Edwin Chacon-Golcher}        
\date{\today}    
\maketitle

\begin{abstract}
 This is a draft for a guide to the facilities offered by Selalib, the Semi-Lagrangian Library. It serves as a record for module descriptions, design decision, pending issues, etc., which are relevant for the development and improvement of the library. The main focus is the exposed API, thus the document also serves as a working document for the architectural specifications. More specific implementation details should be found in the comments within the source code. 
\end{abstract}

\tableofcontents

\chapter{Introduction}             % chapter 1
Selalib is the \emph{Se}mi\emph{La}grangian \emph{Lib}rary, a collection of types and its associated methods that are useful for creating parallel plasma physics simulations that use this specific methodology for the solution of the \emph{Vlasov} equation. In its design, we have attempted to expose to the users an interface that expresses as naturally as possible the problems that arise when using the semilagrangian approach. However, most of the modules contained in the library are not intrinsically related with the semilagrangian method, but are more general utilities which could be used in different contexts. A principle in the development of the library has been to continually identify specific functionalities and to attempt to promote them into their own standalone module, with a sufficiently general interface which may still be reasonably efficient.

Selalib is structured in layers. One can think about these layers as libraries in their own right. A given layer can use the capabilities offered by a lower layer through the exposed interface, but never from a higher level. The layer with the lowest level of abstraction presently contains basic utilities like memory allocators, assertions and basic numeric types. The second layer is composed of numerical and parallel utilities. The third and highest level of the library contains the semi-lagrangian methodology tools, types and methods. This manual will ultimately describe each of these layers.

Most of the native types and operations provided by Selalib are prefixed by \verb+sll_+. In this way you can at least have an expectation of finding documentation (if a user) and a starting point of where to start looking if you wish to dive into some particular aspect of an implementation (if a developer). 

Selalib is written in Fortran 2003. We have deviated from the original intent to make Selalib fully f95-compatible for multiple reasons: the newer standard permits a separation of interface and implementation which is desirable in a development like this, the reduction in coding that is obtained with the use of abstract classes is appealing for a project with quite limited manpower as this one, and finally, the desire to make this product as forward-looking as possible.

There are some aspects of the library's implementation that may warrant some commentary as these have an impact on how the library is used. For instance, the full library can be imported by the declaration \textcolor{red}{(Pierre, is this true presently?)}:
\begin{verbatim}
#include "selalib.h"
\end{verbatim}
instead of the more Fortran-natural form:
\begin{verbatim}
use selalib
\end{verbatim}
The reason for this is that some features of the library are implemented as \emph{macros}. To the user of the library, it makes no difference whether some functionality is implemented in the form of a procedure or a macro, with the exception that presently, macro names are written in \verb+ALL-CAPS+. The use of the macro is required to offer certain capabilities, like informative error messages. For a developer, the use of the macros is needed in many cases to reduce code redundancy. The need for the use of macros will hopefully be more understandable when the reader sees the behavior of calls to simple macros like \verb+SLL_ALLOCATE()+ or \verb+SLL_ASSERT()+.

A macro is a pre-processor directive. Selalib uses only very simple macros that are handled by \emph{fpp}, the Fortran Pre-Processor. \emph{fpp}'s capabilities are very limited and one peculiarity of its output is that macros are expanded into a single long line, which can easily surpass the 132 character limit that Fortran systems have. For this reason alone, the compilation of Selalib requires the use of a compilation flag: \verb+-ffree-line-length-none+ (in \textbf{gfortran}) or its equivalent in another compiler. On a similar vein, some compilers require the extension \verb+.F90+ (as opposed to \verb+.f90+) in order to apply a preprocessing step. Thus, all files in Selalib use the \verb+.F90+ extension. Clients of the library which want to use the macro facilities should thus also use this extension as well.


%\section{Introduction}     % section 1.1
%\subsection{History}       % subsection 1.1.1

\chapter{Low-Level Layer: Basic Utilities}           % chapter 2


\section{Numeric Types}     % section 2.1
\subsection{Description}
As a \emph{convenience}, Selalib offers aliases to some of Fortran's basic numeric types. This is intended to:
\begin{enumerate}
\item concisely and uniformly make clear the intended precision of a given variable, 
\item permit mixed precision representations when needed (for example, a developer could wish to represent a particular real number with a combination of a 32-bit integer and a 32-bit real instead of a single 64-bit real as is sometimes done in ultra-high performance software), and
\item provide a centralized location to change the precision of a numerical representation program-wide.
\end{enumerate}

\subsection{Exposed Interface}         % subsection 2.1.1
Selalib's numeric precision features are accessed through the following aliases:

\vspace{+0.5cm}
\begin{tabular}{l l}
alias & shorthand for... \\
\hline
\verb+sll_int32+ & \verb+integer(kind=i32)+ \\
\verb+sll_int64+ & \verb+integer(kind=i64)+ \\
\verb+sll_real32+ & \verb+real(kind=f32)+ \\
\verb+sll_real64+ & \verb+real(kind=f64)+ \\
\verb+sll_int+  & \verb+integer(kind=user)+ \\
\verb+sll_real+ & \verb+real(kind=user)+ \\
\verb+sll_comp32+ & \verb+complex(kind=f32)+\\
\verb+sll_comp64+ & \verb+complex(kind=f64)+\\
\hline
\end{tabular}
\vspace{+0.5cm}


Where the kind type parameters \verb+i32+, \verb+i64+, \verb+f32+ and \verb+f64+ have been defined to give a representation that is at least the denoted size for a given number. \verb+user+ is available for a flexible kind type parameter. These kind type parameters can also be used to specify the precision of numerical constants in the usual Fortran way, i.e. \verb+3.14159265_f32+. The use of these constants is encouraged for development within the library as then we can in principle change the numeric precision library-wide if needed with only a parameter change.

\subsection{Usage}
To use the module in a stand-alone way, use the line:
\begin{verbatim}
#include "sll_working_precision.h"
\end{verbatim}

These types are to be used like the native Fortran types that they are aliasing:

\begin{verbatim}
     sll_real64 :: my_pi
     sll_real64 :: theta
     sll_int32  :: i
     sll_int32  :: N
     sll_real64, dimension(:), allocatable :: w
     ! allocate w ...
     my_pi = 3.1415926535897932384626433_f64
     theta = 2.0*my_pi/real(N,f64)
     do i=1,N/2
          w(i) = exp((0.0,1.0_f64)*theta*real(i,f64))
     end do
\end{verbatim}

\subsection{Status}
Unit-tested.

\section{Memory Allocator}
\subsection{Description}
Selalib's memory allocators are simple wrappers around Fortran's native allocators. We ask very little from these allocators:
\begin{enumerate}
\item to allocate memory, 
\item to initialize it if requested (only for Fortran-native types), 
\item to deallocate memory, and 
\item to fail with as descriptive a message as possible.
\end{enumerate}

\subsection{Exposed Interface}
The interface to these allocators follows very closely the interface of Fortran's \verb+allocate()+ and \verb+deallocate()+ functions, except for a mandatory integer variable argument which does not need to be initialized. The user may decide to allocate arrays or pointers of any type, and up to the same number of dimensions as permitted by a given Fortran implementation. The exposed macros are:

\begin{verbatim}
     SLL_ALLOCATE( array_and_lims, ierr )
\end{verbatim}
This is the basic memory allocator with the same syntax as Fortran's native \verb+allocate()+ but with a required integer error parameter. Any type and dimension that the native fortran allocator would accept can be given as the argument \verb+array_and_lims+.

\begin{verbatim}
     SLL_CLEAR_ALLOCATE( array_and_lims, ierr )
\end{verbatim}
Same behavior as \verb+SLL_ALLOCATE()+ but also initializes the allocated memory to zero. This works for Fortran native types only or for derived types for which an assignment operator ($= 0$) has been defined.
\begin{verbatim}
     SLL_DEALLOCATE( array_and_lims, ierr )
\end{verbatim}
Basic deallocator. It is a wrapper around Fortran's native \verb+deallocate()+ function but also nullifies the pointer given as an argument after deallocation. This is a difference between the native Fortran routine and this wrapper, as we have thus needed to distinguish between the call that deallocates a pointer and a simple array:
\begin{verbatim}
     SLL_DEALLOCATE_ARRAY( array, ierr )
\end{verbatim}
The array deallocator differs from the previous in that it does not attempt to nullify the array name after the deallocation is complete. This and the previous macro could in principle be merged into one for simplification.
\begin{verbatim}
     SLL_INIT_ARRAY( array, val )
\end{verbatim}
While not really an allocator/deallocator, we expose this macro for convenience in initializing an array with a given constant value. For consistency, it may be decided to eliminate this from the interface.

\subsection{Usage}

To use the memory module in stand-alone fashion, use the line:
\begin{verbatim}
#include "sll_memory.h"
\end{verbatim}
An example of the use of the module is:
\begin{verbatim}
     integer :: err
     real, dimension(:), allocatable :: a
     real, dimension(:,:,:), pointer :: b=>null()

     SLL_ALLOCATE( a(5000), err )
     SLL_CLEAR_ALLOCATE( b(1:4,1:3,1:2), err)
     SLL_INIT_ARRAY(b,0)
\end{verbatim}

When finding an error condition, the user is informed about the location of the failing call:

\begin{verbatim}
Memory allocation Failure. Triggered in FILE tester.F90, 
in LINE:   35
STOP ERROR: test_error_code(): exiting program
\end{verbatim}

\subsection{Status}
Unit-tested.

\section{Assertions}
\subsection{Description}
This is a very small but very useful capability that permits the developer to devise many sorts of defensive programming techniques. The simple idea is that of declaring a condition that is expected to be true, thus triggering a descriptive error if the condition is violated. The assertions are only present while compiling the library in \verb+DEBUG+ mode, thus any overhead associated with the test can be eliminated by changing the type of compilation. For this reason, the types of tests that should be permanent should not be implemented with the assert facility.

\subsection{Exposed Interface}
Wherever a specific condition needs to be asserted, simply write:
\begin{verbatim}
     SLL_ASSERT( logical_condition )
\end{verbatim}
Thus the condition to be checked must be cast in the form of a logical statement. Falseness of such statement would trigger an assertion error.

The assertions can be used liberally since they are controlled by a \verb+-DEBUG+ flag at compilation time (\verb+DEBUG+ compilation mode). Absence of this flag (i.e. in \verb+RELEASE+ compilation mode) will delete all calls to \verb+SLL_ASSERT()+ from the code. Hence, assertion conditions can be used during a debugging or testing phase without increasing the overhead in production code.

\subsection{Usage}
To use the \emph{assertions} module in a stand-alone way, use the line:
\begin{verbatim}
#include "sll_assert.h"
\end{verbatim}
However, all the following steps are necessary:

An example may be the checking of in-range indices on a protected array:

\begin{verbatim}
     function get_val( a, i )
          sll_int32 :: get_val
          sll_int32, intent(in) :: i
          sll_int32, dimension(:), intent(in) :: a
          SLL_ASSERT( (i .ge. 1) .and. (i .le. size(a)) )
          get_val = a(i)
     end function get_val
\end{verbatim}
Which could produce a behavior such as:
\begin{verbatim}
$./unit_test
     The size of a is: 1000
     a(1) =    0
     a(117) =    0
     Here we ask for the value of a(1001):

     (i .ge. 1) .and. (i .le. size(a)) : Assertion 
     error triggered in file unit_test.F90 in line       25
     STOP :  ASSERTION FAILURE
\end{verbatim}
Such way of stopping a program is much less uncomfortable than the sinking feeling one has when the program stops as in:
\begin{verbatim}
$ ./unit_test
     Array values: 
     The size of a is: 1000
     a(1) =    0
     a(117) =    0
     Incident de segmentation (core dumped)
\end{verbatim}
which of course doesn't even need to happen at the moment of the first error.

\subsection{Status}
Unit tested.

\subsection{Developer notes}
\begin{enumerate}
\item the \verb+SLL_ASSERT()	+ macro needs some other macros to convert parameters into strings, but the way to accomplish this may vary depending on the compiler used. If problems are found, make sure that the appropriate macro is used in the \verb+sll_assert.h+ to activate the proper behavior of such macros. As an example, when using \textbf{gfortran} compiler, notice the role played by the \verb+-DGFORTRAN+ flag.
\item when using \textbf{gfortran}, use pass along the flag \verb+-ffree-line-length-none+ to prevent compilation error as some of the included macros may go beyond Fortrans 132 character limit. Use the equivalent flag when changing compilers. All of this should be set within CMake.
\end{enumerate}



\section{Timing Utility}
\subsection{Description}
When a high-resolution timer is available the measurable time interval can be a bit smaller than 2 $\mu s$.

\subsection{Exposed Interface}

The module is imported by
\begin{verbatim}
use sll_timer
\end{verbatim}
or
\begin{verbatim}
include sll_timer
\end{verbatim}
which defines the type \verb+sll_time_mark+ which is meant to be treated as an opaque object i.e. only interact with it through the methods defined for it. An instance of this type can be used to measure time intervals with the following routines:

\begin{verbatim}
     set_time_mark( mark)
     time_elapsed_since( mark )
     time_elapsed_between( mark_0, mark_1 )
\end{verbatim}

\verb+set_time_mark( mark )+ is a routine that takes an \verb+sll_time_mark+ object and sets is internals to mark the time at the moment of the routine call.

\verb+time_elapsed_since( mark )+ is a function that takes a time mark as an argument and returns the time, \emph{in seconds} between the clock reading contained in the passed argument and the moment at which the function was called.

\verb+time_elapsed_between( mark_0, mark_1 )+ is a function which takes two time marks that must have been set before obviously and will return the time elapsed between them.



\subsection{Usage}
Here is an example of the use of this module:

\begin{verbatim}
1     program timer_test
2     use sll_timer
3     implicit none
4     integer(8) :: i, j, k
5     real(c_double), dimension(:), allocatable :: dt
6     type(sll_time_mark) :: tmark
7
8     #define ITERATIONS 1000
9 
10    allocate(dt(ITERATIONS))
11
12    do i=1,ITERATIONS
13       call sll_set_time_mark(tmark)
14       do k=1,100000    ! Just a delay
15          j = i * i - i
16       end do
17       dt(i) = sll_time_elapsed_since(tmark) 
18    end do
19    ! print diagnostics here, averages, min, max, etc.
\end{verbatim}

In brief:
\begin{description}
\item[Line 2:]
Imports the timer module. 

\item[Line 5:]
Here we define an array to store the results of the timing test. This array stores the return values of the function \verb+time_elapsed_since()+, which returns a double precision value (\verb+sll_real64+).

\item[Line 6: ]
Declaration of the time marker.

\item[Lines 13:]
Sets the time marker with a current clock reading.

\item[Line 17:]
We store the result of the timing operation.
\end{description}

Any number of time markers can be declared and set at different points. 

\subsection{Status}
Unit-tested.


\section{Constants}

  \subsection{Description}
  Selalib provides a single file that specifies commonly used constants as read-only parameters that can be used library-wide or by users.

  \subsection{Exposed Interface}
  Selalib simply defines a list of symbols, all in units of the International System when applicable. To use, just write either
  
  \begin{verbatim}
use sll_constants
\end{verbatim}
or
\begin{verbatim}
include sll_constants.
\end{verbatim}
The symbols defined are:
  
  \begin{description}
    \item[sll\_pi]: mathematical constant $\pi$
    \item[sll\_c]: speed of light [$m/s$].
    \item[sll\_epsilon\_0]: permittivity of free space ($\epsilon_0$) [$F/m$].
    \item[sll\_mu\_0]: permeability of free space ($\mu_0$) [$N/A^2$].
    \item[sll\_e\_charge]: fundamental charge [$C$].
    \item[sll\_e\_mass]: mass of the electron [$kg$].
    \item[sll\_proton\_mass]: mass of the proton [$kg$].
    \item[sll\_g]: gravitational acceleration at sea level [$m/s^2$]
  \end{description}
  



\section{Logical Meshes}

    \subsection{Description}
    
    Selalib solves its PDEs on structured grids\footnote{We use the terms \emph{mesh} and \emph{grid} interchangeably.}. Furthermore, the actual solutions of the equations are carried out on rectangular, uniform grids (i.e. cartesian) which within Selalib are referred to as \emph{logical meshes}. This means that when dealing with \emph{physical domains} (i.e. the actual geometry that is to be modeled) there is a coordinate transformation that maps the logical mesh to the physical domain\footnote{Or multiple coordinate transformations, in case that the physical domain is represented by multiple patches.}. Such coordinate transformations will be discussed on a different chapter. Here we occupy ourselves with the description of the logical mesh itself. The specification of a logical mesh is quite simple, as at a minimum it only needs the number of cells in each dimension and the values of the endpoints. As a convention, the coordinates in the logical meshes are always referred to by the symbol $\eta$. Thus the coordinate for the 1D mesh is $\eta_1$, for the 2D mesh they are $\eta_1$ and $\eta_2$ and so on.


    \subsection{Exposed Interface}
    
    
    Public types:
    
    \begin{verbatim}
    sll_logical_mesh_1d
    sll_logical_mesh_2d
    sll_logical_mesh_3d
    sll_logical_mesh_4d
     \end{verbatim}
     
    Routines:
     
     \begin{verbatim}
    new_logical_mesh_1d( num_cells,         
                         eta1_min, 
	                         eta1_max )
	                                              
    new_logical_mesh_2d( num_cells1, 
                         num_cells2, 
                         eta1_min, 
                         eta1_max, 
                         eta2_min, 
                         eta2_max )
                              
    new_logical_mesh_3d( num_cells1, 
                         num_cells2,
                         num_cells3, 
                         eta1_min, 
                         eta1_max, 
                         eta2_min, 
                         eta2_max, 
                         eta3_min, 
                         eta3_max )
                             
    new_logical_mesh_4d( num_cells1, 
                         num_cells2,
                         num_cells3,
                         num_cells4, 
                         eta1_min, 
                         eta1_max, 
                         eta2_min, 
                         eta2_max, 
                         eta3_min, 
                         eta3_max, 
                         eta4_min, 
                         eta4_max )          
                              
     sll_display( mesh )  ! generic, for any mesh dimension      
     delete( mesh )  ! generic, for any mesh dimension
     \end{verbatim}


The 'new' functions return pointers to allocated and initialized meshes. All the parameters that specify the limits of the values of \emph{eta} are optional. These limits default to 0.0 and 1.0 for their minimum and maximum values. The routine \verb+sll_display( )+ is helpful to show the contents of a given mesh.


As a rare case in Selalib, the interface of the logical meshes permits direct access to their internals. The slots available for each type are:

\begin{verbatim}
    num_cellsX
    etaX_min
    etaX_max
    delta_etaX
\end{verbatim}
where 'X' stands for the index of the direction of interest (1, 2, 3, etc.). Direct access is meant for reading, as the 'new' functions are enough to produce duly initialized logical meshes. Thus a user can directly access any of these slots as in:

\begin{verbatim}
    mesh%delta_eta1
\end{verbatim}

\subsection{Usage}

\begin{verbatim}
1 program logical_meshes
2 use sll_logical_meshes
3  implicit none
4
5  type(sll_logical_mesh_2d), pointer :: m2d
6  
7  m2d => new_logical_mesh_2d(64, 64)
8
9  call sll_display(m2d)
10
11 call delete(m2d)
12 end program logical_meshes
\end{verbatim}

\subsection{Status}
Unit-tested.


\section{File IO}

    \subsection{Description}
	Presently, Selalib offers facilities to output data in the XDMF file format, readable by the VisIt program. To use, import the module \verb+sll_file_io+. The interface allows to open a file, write multi-dimensional data in it and then close it. The main purpose of this module is to provide the low-level building blocks that can be used by higher-level functions to conveniently write data to files.

    \subsection{Exposed Interface}
    The current interface is a collection of generic functions:
    \begin{verbatim}
        sll_xdmf_open( file_name,
                       mesh_name,
                       nnodes_x1,nnodes_x2,[nnodes_x3,]
                       file_id,
                       error )
        sll_xdmf_write_array( mesh_name,
                              array,
                              array_name,
                              error,
                              xmffile_id,
                              center )
        sll_xdmf_close(file_id,error)
    \end{verbatim}
    Where the parameters in brackets are used depending of the dimensionality of the data.
    \begin{description}
       \item \verb+sll_xdmf_open( )+ opens a file with a given name and returns a file identifier on \verb+file_id+.
       \item \verb+sll_xdmf_write_array( )+ writes a given multi-dimensional array on a file identified by \verb+xmffile_id+.
       \item \verb+sll_xdmf_close( )+ closes the given file.
    \end{description}

\subsection{Critical Commentary}
ECG: This interface can be improved. To consider:
\begin{description}
\item The job of \verb+sll_xdmf_open( )+ should be to open a file, with a given filename; it should take as parameters some flags to indicate what behavior to exercise in case of error or if the file exists (overwrite? append?) and nothing else. The nnodes parameters are used to write XDMF-related preambles, but this should be sent to the other functions that actually write into the file.
\item The mesh\_name parameter is not clear. Why mesh?
{\it Answer Mesh coordinates are written in a separate file, so you can write it only one time at the beginning of the computation. When you plot a field you still need to link your data to a mesh.}
\item What is the 'center' parameter in the write\_array() function?
{\it Answer When you plot field you can specify if your values are node centered or cell centered}
\end{description}

\chapter{Mid-Level Layer: Numerical and Parallel Utilities}

\section{Tridiagonal System Solver}
\subsection{Description}
To solve systems of the form $Ax=b$, where $A$ is a tridiagonal matrix, Selalib offers a native, robust tridiagonal system solver. The present implementation contains only a serial version. The algorithm is based on an \emph{LU} factorization of a given matrix, with row pivoting. The tridiagonal matrix must be given as a single array, with a memory layout shown next.
\begin{equation*}
  \begin{bmatrix}
    a(2) & a(3) &        &        &        &        &  a(1) \\
    a(4) & a(5) & a(6)   &        &        &        &       \\
         & a(7) & a(8)   & a(9)   &        &        &       \\
         &      & \ddots & \ddots & \ddots &        &       \\
         &      &        & \ddots & \ddots & \ddots &       \\
         &      &        &        & a(3n-5)& a(3n-4)&a(3n-3)\\
    a(3n)&      &        &        &        & a(3n-2)&a(3n-1)\\
  \end{bmatrix}
\end{equation*}

\subsection{Exposed Interface}
Factorization of the matrix $A$ is obtained through a call to the subroutine
\begin{verbatim}
     sll_setup_cyclic_tridiag( a, n, lu, ipiv )
\end{verbatim}
where \verb+a+ is the matrix to be factorized, \verb+n+ is the problem size (the number of unknowns), \verb+lu+ is a real array of size $7n$ where factorization information will be returned and \verb+ipiv+ is an integer array of length \verb+n+ on which pivoting information will be returned. From the perspective of the user, \verb+lu+ and \verb+ipiv+ are only arrays that \verb+sll_setup_cyclic_tridiag+ requires and do not need any further consideration.

The solution of a tridiagonal system, once the original array $A$ has been factorized, is obtained through a call to 
\begin{verbatim}
     sll_solve_cyclic_tridiag( lu, ipiv, b, n, x )
\end{verbatim}
where \verb+lu+, \verb+ipiv+ are the arrays returned by \verb+sll_setup_cyclic_tridiag()+, \verb+b+ is the independent term in the original matrix equation, \verb+n+ is the system size and \verb+x+ is the array where the solution will be returned.
  
\subsection{Usage}
To use the module in a stand-alone way, include the line:
\begin{verbatim}
     use sll_tridiagonal
\end{verbatim}
The following code snippet is an example of the use of the tridiagonal solver.
\begin{verbatim}
     sll_int32 :: n = 1000
     sll_int32 :: ierr
     sll_real64, allocatable, dimension(:) :: lu
     sll_int32,  allocatable, dimension(:) :: ipiv
     sll_real64, allocatable, dimension(:) :: x

     SLL_ALLOCATE( lu(7*n), ierr )
     SLL_ALLOCATE( ipiv(n), ierr )
     SLL_ALLOCATE( x(n), ierr )
     
     ! initialize a(:) with the proper coefficients here... 
     and then:
     
     sll_setup_cyclic_tridiag( a, n, lu, ipiv )
     sll_solve_cyclic_tridiag( lu, ipiv, b, n, x )
     
      SLL_DEALLOCATE_ARRAY( lu, ierr )
      SLL_DEALLOCATE_ARRAY( ipiv, ierr )
      SLL_DEALLOCATE_ARRAY( x, ierr )
\end{verbatim}
Note that if the last call had been made as in
\begin{verbatim}
     sll_solve_cyclic_tridiag( lu, ipiv, b, n, b )
\end{verbatim}
the system would have been solved in-place.

\subsection{Status}
Unit-tested.






\section{Boundary Condition Descriptors}

\subsection{Description}
This tiny module defines a few symbols that are meant to be used library-wide as a means to indicate various boundary condition types or their combinations. The objective is to have pre-defined symbols that will prevent the need of using numeric values explicitly to specify this information.

\subsection{Exposed Interface}
The defined symbols are:

\begin{verbatim}
     SLL_USER_DEFINED
     SLL_PERIODIC
     SLL_DIRICHLET
     SLL_NEUMANN 
     SLL_HERMITE 
     SLL_NEUMANN_MODE_0
     SLL_SET_TO_LIMIT 
\end{verbatim}

\subsection{Usage}
Simply pass the parameter as an argument to any routine call which requires a \emph{boundary condition descriptor}.





\section{Cubic Splines}

\subsection{Description}
The cubic splines module provides capabilities for 1D and 2D data interpolation with cubic B-splines and different boundary conditions (at the time of this writing: periodic, hermite). The data to be interpolated are represented by a simple array.  The spline coefficients and other information are stored in a spline object, which is also used to interpolate the fitted data. To use this module, simply declare an instance of the type to be used, initialize the object with the desired parameters, use the initialized object to do interpolations and when no longer needed, release the resources through a call to the \verb+sll_delete( )+ routine. More details below.

\subsection{Exposed Interface}
Fundamental types:
\begin{verbatim}
     sll_cubic_spline_1d
     sll_cubic_spline_2d
\end{verbatim}
These types are declared as pointers and only manipulated through the functions and subroutines described below. For more explicit examples, see the usage section.

For the 1D case, the available routines are:
\begin{verbatim}
     new_cubic_spline_1D( num_points, 
                          xmin, 
                          xmax, 
                          bc_type, 
                          [slope_L], 
                          [slope_R] )  
     compute_cubic_spline_1D( data, spline_object )
     interpolate_value( x, spline_object )
     interpolate_derivative( x, spline_object )
     interpolate_array_values( a_in, a_out, np, spline_object )
     interpolate_pointer_values( a_in, a_out, np, spline_object )
     interpolate_array_derivatives( a_in, a_out, np, spline_object )
     interpolate_pointer_derivatives( ptr_in, ptr_out, np, spline_object )
     get_x1_min( spline_object )
     get_x1_max( spline_object )
     get_x1_delta( spline_object )
     sll_delete( spline_object )
\end{verbatim}
 
In the above list:
 
\begin{description}
	\item \verb+new_cubic_spline_1D()+ is responsible for allocating all the necessary storage for the spline object and initializating it. Arguments:

	\begin{description}
		\item[num\_points:] 
32-bit integer. Number of data points for which the spline needs to be computed, including the end-points (regardless of the boundary condition used).
		\item[xmin:]
Double precision real. Lower bound of the domain in which the data array is defined. In other words, if we think of the data array (indexed 1:NP) as the values of a discrete function \emph{f} defined over a sequence of $x_i$'s, then $x_1 = xmin$.
		\item[xmax:]
Double precision real. Similarly to \verb+xmin+, \verb+xmax+ represents the maximum extent of the domain. For data indexed 1:NP: $xmax = x_{NP}$. 
		\item[bc\_type:]
Pre-defined parameter. Descriptor of the type of boundary condition to be imposed in the spline. Use only the symbols defined in Selalib's \emph{boundary condition descriptors} module. Presently, one of \verb+PERIODIC_SPLINE+ or \verb+HERMITE_SPLINE+. These are really aliases to integer flags, but in Selalib we avoid the use of non-descriptive flags.
		\item[slope\_L:]
	Double precision real. Optional value representing the desired slope at $x = xmin$, in the hermite BC case.
		\item[slope\_R:]
	Double precision real. Optional value representing the desired slope at $x = xmax$, in the hermite BC case.
	\end{description}


	\item \verb+compute_cubic_spline_1D()+ calculates the spline coefficients needed to represent the given data and stores this information in the spline object. Arguments:
	
	\begin{description}
		\item[ data:] Double precision 1D real array containing NP values.
		\item[ spline\_object: ] Initialized object of type \verb+sll_cubic_spline_1d+.
	\end{description}


	\item \verb+interpolate_value()+ returns the value of \emph{f(x)} where \emph{x} is a floating-point value between \verb+xmin+ and \verb+xmax+, and \emph{f} is a continuous function built with cubic B-splines and the user-defined boundary conditions contained in the spline object passed. Essentially, the spline object, together with the \verb+interpolate_value()+ function create the illusion of having available a continuous function when originally using the discrete data given. Arguments:
	
	\begin{description}
		\item[ x:] Double precision value representing the ordinate whose image is sought.
		\item[ spline\_object: ] Initialized object of type \verb+sll_cubic_spline_1d+. A call to \verb+compute_cubic_spline_1D()+ should have been made previous to calling this function.
	\end{description}

	\item \verb+interpolate_array_values()+ has an analogous functionality than the previous interpolation function, but is capable of processing whole arrays. This is useful to avoid the overhead associated with a call to \verb+interpolate_value()+ inside a loop.
	
	
	\item \verb+interpolate_derivative()+ returns the value of \emph{f'(x)} where \emph{x} is a floating-point value between \verb+xmin+ and \verb+xmax+, and \emph{f} is a continuous function built with cubic B-splines and the user-defined boundary conditions contained in the spline object passed. Same types of arguments as in \verb+interpolate_value()+.
	
	\item \verb+interpolate_array_values()+ is a subroutine that interpolates the results of multiple values of \emph{x}. Arguments:
		\begin{description}
			\item[a\_in:] [in] double precision 1D array containing the values of the ordinates to be interpolated.
			\item[a\_out:] [out]double precision 1D array to store the results, i.e., the images of the values contained in \verb+a_in+.
			\item[np:] [in] 32-bit integer storing the number of points meant to be interpolated.
			\item[ spline\_object: ] [inout] Initialized object of type \verb+sll_cubic_spline_1d+.
		\end{description}

	\item \verb+interpolate_pointer_values()+ is a subroutine with analogous arguments to \verb+interpolate_array_values+ except that it receives pointers instead of arrays for its arguments.
	
	\item \verb+interpolate_array_derivatives()+ computes multiple first-derivative values. Its interface is identical to \verb+interpolate_array_values()+.
	
	\item \verb+interpolate_pointer_derivatives()+ computes multiple first-derivative values, just as \verb+interpolate_array_derivatives()+ except that its arguments are pointers.
	
	\item \verb+get_x1_min()+ returns the minimum value of the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_1D+
		\end{description}
	
	\item \verb+get_x1_max()+ returns the maximum value of the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_1D+
		\end{description}
		
		\item \verb+get_x1_delta()+ returns the value of the spacing between the points used to compute the spline values. This is determined from the extent of the domain and the number of cells used. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_1D+
		\end{description}

	\item \verb+sll_delete()+ subroutine to free the resources of a given spline object. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_1D+
		\end{description}
\end{description}



For the 2D case, the available routines are:



\begin{verbatim}     
     new_cubic_spline_2d( num_pts_x1,  
                          num_pts_x2,  
                          x1_min,      
                          x1_max,     
                          x2_min,      
                          x2_max,     
                          x1_bc_type, 
                          x2_bc_type,  
                          const_slope_x1_min,
                          const_slope_x1_max,
                          const_slope_x2_min, 
                          const_slope_x2_max,
                          x1_min_slopes,
                          x1_max_slopes,
                          x2_min_slopes, 
                          x2_max_slopes )
       compute_cubic_spline_2d( data, spline_object )
       interpolate_value_2d( x1, x2, spline_object )
       interpolate_x1_derivative_2d( x1, x2, spline_object )
       interpolate_x2_derivative_2d( x1, x2, spline_object )      
       get_x1_min( spline_object )
       get_x1_max( spline_object )
       get_x2_min( spline_object )
       get_x2_max( spline_object )
       get_x1_delta( spline_object )
       get_x2_delta( spline_object )
       sll_delete( spline_object )             
\end{verbatim}

   
In the above list:
 
\begin{description}
	\item \verb+new_cubic_spline_2D()+ is responsible for allocating all the necessary storage for the spline object and initializating it. Arguments:

	\begin{description}
		\item[num\_points\_x1:] 
[in] 32-bit integer. Number of data points in the first (memory-contiguous) direction for which the spline needs to be fitted. Endpoints at $x_{1,j} = x1_{min}$ and $x_{NPX1,j} = x1_{max}$ must be included.
		\item[num\_points\_x2:]
[in] 32-bit integer. Number of data points in the second direction for which the spline needs to be fitted. Endpoints at $x_{i,1} = x2_{min}$ and $x_{i,NPX2} = x2_{max}$ must be included.
		\item[x1\_min:]
[in] Double precision real. Lower bound of the domain in which the data array is defined in the first (memory-contiguous) direction.
		\item[x1\_max:]
[in]Double precision real. Represents the maximum extent of the domain in the first (memory-contiguous) direction.
		\item[x2\_min:]
[in] Double precision real. Lower bound of the domain in which the data array is defined in the second direction.
		\item[x2\_max:]
[in]Double precision real. Represents the maximum extent of the domain in the second direction.
		\item[x1\_bc\_type:]
[in] Pre-defined parameter. Descriptor of the type of boundary condition to be imposed in the spline in the first direction. Presently, one of \verb+PERIODIC_SPLINE+ or \verb+HERMITE_SPLINE+ as defined in Selalib's \emph{boundary condition descriptors} module.
		\item[x2\_bc\_type:]
[in] Pre-defined parameter. Descriptor of the type of boundary condition to be imposed in the spline in the second direction. Presently, one of \verb+PERIODIC_SPLINE+ or \verb+HERMITE_SPLINE+ as defined in Selalib's \emph{boundary condition descriptors} module.
		\item[const\_slope\_x1\_min:]
	[optional, in]Double precision real. Optional value representing the desired slope at $x1_{min}$, in the hermite BC case if a constant value for the whole edge is to be specified.
		\item[const\_slope\_x1\_max:]
		[optional, in]Double precision real. Optional value representing the desired slope at $x1_{max}$, in the hermite BC case if a constant value for the whole edge is to be specified.
		\item[const\_slope\_x2\_min:]
	[optional, in]Double precision real. Optional value representing the desired slope at $x2_{min}$, in the hermite BC case if a constant value for the whole edge is to be specified.
		\item[const\_slope\_x2\_max:]
		[optional, in]Double precision real. Optional value representing the desired slope at $x2_{max}$, in the hermite BC case if a constant value for the whole edge is to be specified.
		\item[x1\_min\_slopes:]
		[optional, in] Array with the values of the slopes at each of the \verb+num_points_x2+ locations in the edge at $x1_{min}$. To be used with the hermite boundary condition only.
		\item[x1\_max\_slopes:]
		[optional, in] Array with the values of the slopes at each of the \verb+num_points_x2+ locations in the edge at $x1_{max}$. To be used with the hermite boundary condition only.
		\item[x2\_min\_slopes:]
		[optional, in] Array with the values of the slopes at each of the \verb+num_points_x1+ locations in the edge at $x2_{min}$. To be used with the hermite boundary condition only.
		\item[x2\_max\_slopes:]
		[optional, in] Array with the values of the slopes at each of the \verb+num_points_x1+ locations in the edge at $x2_{max}$. To be used with the hermite boundary condition only.
	\end{description}

	\item \verb+compute_cubic_spline_2D()+ calculates the spline coefficients needed to represent the given 2D data and stores this information in the spline object. Arguments:
	
	\begin{description}
		\item[ data:] [in] Double precision 2D real array containing NPX1*NPX2 values.
		\item[ spline\_object: ] Initialized object of type \verb+sll_cubic_spline_2d+.
	\end{description}


	\item \verb+interpolate_value_2d()+ returns the value of \emph{f(x1,x2)} where the ordered pair $(x1,x2)$ is in the domain $[x1_{min},x1_{max}] X [x2_{min},x2_{max}]$. \emph{f} is a continuous function built with cubic B-splines and the user-defined boundary conditions contained in the spline object passed.  Arguments:
	
	\begin{description}
		\item[ x1:] [in] Double precision value representing the value of the first coordinate.
		\item[ x2:] [in] Double precision value representing the value of the second coordinate.
		\item[ spline\_object: ] Initialized object of type \verb+sll_cubic_spline_2d+. A call to \verb+compute_cubic_spline_2D()+ should have been made previous to calling this function.
	\end{description}

	\item \verb+interpolate_x1_derivative_2d()+ returns the value of the first derivative in the $x1$ direction. Uses same types of arguments as the $interpolate_value_2d$ function.
	
	\item \verb+interpolate_x2_derivative_2d()+ returns the value of the first derivative in the $x2$ direction. Uses same types of arguments as the $interpolate_value_2d$ function.
	
	
	\item \verb+get_x1_min()+ returns the minimum value of $x1$ in the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
	
	\item \verb+get_x1_max()+ returns the maximum value of $x1$ in the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
		
	\item \verb+get_x2_min()+ returns the minimum value of $x2$ in the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
	
	\item \verb+get_x2_max()+ returns the maximum value of $x2$ in the domain in which the spline object is defined. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
		
		\item \verb+get_x1_delta()+ returns the value of the spacing between the points used to compute the spline values in the $x1$ direction. This is determined from the extent of the domain and the number of cells used. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
		
		\item \verb+get_x2_delta()+ returns the value of the spacing between the points used to compute the spline values in the $x2$ direction. This is determined from the extent of the domain and the number of cells used. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}

	\item \verb+sll_delete()+ subroutine to free the resources of a given spline object. Arguments:
		\begin{description}
			\item[spline\_object:] a pointer to a previously initialized object of type \verb+sll_cubic_spline_2D+
		\end{description}
\end{description}
   

   

\subsection{Usage}
To use the module in a stand-alone way, include the line:\
\begin{verbatim}
     use sll_splines
\end{verbatim}
The following example is an extract from the module's unit test.
\begin{verbatim}
1     program spline_tester
2     #include "sll_working_precision.h"
3     #include "sll_assert.h"
4     #include "sll_memory.h"
5       use sll_splines
6       use numeric_constants
7       implicit none
8
9     #define NP 5000
10
11      sll_int32 :: err
12      sll_int32 :: i
13      type(sll_spline_1d), pointer :: sp1
14      type(sll_spline_1d), pointer :: sp2
15      sll_real64, allocatable, dimension(:) :: data
16      sll_real64 :: accumulator1, accumulator2
17      sll_real64 :: val
18
19      accumulator1 = 0.0_f64
20      accumulator2 = 0.0_f64
21    
22      SLL_ALLOCATE(data(NP), err)
23 
24      print *, 'initialize data array'
25      do i=1,NP
26        data(i) = sin((i-1)*sll_pi/real(NP-1,f64))
27      end do
28
29      sp1 =>  new_spline_1D( NP,         &
30                             0.0_f64,    &
31                             sll_pi,     &
32                             SLL_PERIODIC )
33      call compute_cubic_spline_1D( data, sp1 )
34      sp2 =>  new_spline_1D( NP, 0.0_f64,    &
35	                            sll_pi,         &	
36                             SLL_HERMITE, 
37                             1.0_f64, 
38                            -1.0_f64 )
39      call compute_cubic_spline_1D( data, sp2 )
40  
41      print *, 'cumulative errors at nodes: '
42      do i=1, NP-1
43         val = real(i-1,f64)*sll_pi/real(NP-1,f64)
44         accumulator1 = accumulator1 + abs(data(i) - &
45                        interpolate_value(val, sp1))
46      end do
47
48      print *, 'hermite case: '
49      do i=1, NP
50         val = real(i-1,f64)*sll_pi/real(NP-1,f64)
51         accumulator2 = accumulator2 + abs(data(i) - &
52                        interpolate_value(val, sp2))
53      end do
54      print *, 'Periodic case: '
55      print *, 'average error at the nodes = '
56      print *, accumulator1/real(NP,f64)
57      call delete_spline_1D(sp1)
58      if( accumulator1/real(NP,f64) < 1.0e-15 ) then 
59         print *, 'PASSED TEST'
60      else
61         print *, 'FAILED TEST'
62      end if
63      print *, '**************************** '
64      print *, 'Hermite case: '
65      print *, 'average error at the nodes = '
66      print *, accumulator2/real(NP,f64)
67      call delete_spline_1D(sp2)
68      if( accumulator2/real(NP,f64) < 1.0e-15 ) then 
69         print *, 'PASSED TEST'
70      else
71         print *, 'FAILED TEST'
72      end if
73    end program spline_tester
\end{verbatim}

Here we do not go in detail over every line but only highlight those lines in which we interact with the splines module
\begin{description}
\item[Line 5:]
Imports the spline module. The intent is to eventually not require this but to import a single module, say 'selalib' which will include all modules itself. For now, this is the way to include these individual capabilities.

\item[Lines 13 - 14: ]
Declaration of the spline pointers.

\item[Lines 29, 34:]
Allocation and partial initialization of the splines. Note the \verb+=>+ pointer assignment syntax.

\item[Lines 33, 39:]
Calculation of the spline coefficients. After this call the spline object becomes fully usable. Note that in the example we used both existing interfaces to call the initialization subroutine.
\item[Lines 45, 52:]
Value interpolation using the existing splines.

\item[Lines 57, 67:]
Destruction of spline objects.
\end{description}


\subsection{Status}
Unit-tested.

\section{Gauss-Legendre Integrator}

\subsection{Description}
This is a low-level mathematical utility that applies the Gauss-Legendre method to compute numeric integrals.  This module aims at providing a single interface to the process of integrating a function on a given interval.

\subsection{Exposed Interface}
To integrate the function \verb+f(x)+ (real-valued and of a single, real-valued argument \verb+x+) over the interval $[a, b]$, the simplest way is through a function call such as:
 \begin{verbatim}
      gauss_legendre_integrate_1D(f, a, b, n)
 \end{verbatim}
In the function above, \verb+n+ represents the desired number of \emph{Gauss} points used in the calculation:
\begin{equation}
\int_{-1}^1f(x) \mathrm{d} x \approx \sum_{k=1}^n w_kf(x_k)
\end{equation}

Presently, the implementation accepts values of \verb+degree+ between $2$ and $10$ inclusively. The function \verb+gauss_legendre_integrate_1D+ internally does the proper scaling of the points to adjust the integral over the desired interval.

The function \verb+gauss_legendre_integrate_1D+ is a generic interface and as such, it hides some alternative integrators, which are selected depending on the type of the passed arguments.  For instance, we have available the function
\begin{verbatim}
     gauss_legendre_integrate_interpolated_1D(f, spline, a, b, n)
\end{verbatim} 
which integrates a function represented by a spline object. The function \verb+f+ in this case is the spline interpolation function. It looks like this interface could be simplified and we could eliminate the first parameter and pass only the spline object. The only reason to leave the interpolation function as an argument is if we find some compelling reason to parametrize the interpolation function as well. 

It will be necessary to implement other integrators for functions with a different signature, such as two- or three-parameter functions. It might also be necessary to distinguish between one-dimensional and two- or 3-dimensional integration. While this is not yet implemented, here we lay out some suggestions on how to proceed in such cases.

For the class of integrals that are done in one-dimension, such as the above, the cleanest but somewhat more laborious approach appears to be to write a different integrator for every function signature that is needed. For instance, one may need to write specialized integrators for $f(x_1, x_2)$, $f(x_1, x_2, x_3)$ and so on, with the convention that the integral is carried out over, say, the first of the variables. The variables which are not integrated can be used as parameters. The alternative to this approach could be to write a single integrator that is able to receive multiple parameters, through the use of arrays or derived types, but the ugliness of this approach, and the need to basically write glue-code (pack/unpack the arrays or derived types with variables and parameters) every time one wants to integrate something are reasons to reject this approach.

\subsection{Usage}
As mentioned above, the name of the generic function that hides the specialized functions is \verb+gauss_legendre_integrate_1D+. The specialized functions can be individually called to avoid the overhead of the generic function call if desired. A one-dimensional function (user or Fortran) can be integrated by a call like:
\begin{verbatim}
     gauss_legendre_integral_1D( test_function, &
                                 0.0_f64,       &
                                 sll_pi/2.0,    &
                                 4 )
\end{verbatim}
A function that is represented by an underlying spline object can be called like:
\begin{verbatim}
     gauss_legendre_integral_interpolated_1D( interpolate_value,&
                                              sp1,              &
                                              0.0_f64,          &
                                              sll_pi,           &
                                              4)
\end{verbatim}
where sp1 is a spline object. It should be decided if this last case is indeed that interface that is wished, or if something more simplified should be implemented intstead.
\subsection{Status}
Unit-tested.


\section{FFT}
\subsection{Description}
The FFT module intends to provide an unified interface to native or external library FFT functions. This module plays a role analogous to the \emph{Collective} module, explained below, but in this case applied to FFT capabilities instead of a parallelization library like MPI. In this sense, the \verb+sll_fft+ module provides a set of types, functions and subroutines that can in principle be implemented with a choice of external libraries.

\subsection{Exposed Interface}
The interface to the FFT functions is inspired by the FFTW interface in which the FFT operation is carried out by the creation of a plan followed by the execution of this plan. The "plan" stores all relevant information (twiddle factor arrays, auxiliary arrays, etc.) that may be needed by a given type of FFT operation. The application of the plan executes the operation itself on a given data. Like all other native types in Selalib, the FFT plan is declared through a pointer, which must be allocated and initialized. To declare, call:

\begin{verbatim}
     type(sll_fft_plan), pointer :: fft_plan
\end{verbatim}
Followed by an initialization step:
\begin{verbatim}
     fft_plan => sll_new_fft( sample_number,  
                              data_type, 
                              fft_flags )
\end{verbatim}
Where the \verb+data_type+ parameter can take either of the values: \verb+FFT_REAL+ or \verb+FFT_COMPLEX+. Presently we only provide double precision transforms (i.e.: 64-bit floating precision numbers).  The \verb+fft_flags+ can take the values: \verb+FFT_NORMALIZE_FORWARD+ and/or \verb+FFT_NORMALIZE_INVERSE+. If no flags are present, an unnormalized FFT will be executed. The user may request that the FFT be normalized in both directions by combining the flags with a \verb+ + + sign.

To execute the FFT plan:

\begin{verbatim}

\end{verbatim}


\begin{description}
\item[sample\_number:] 
%This is the size of the array on which the number of points will be applied. Note that for an ordinary FFT, periodic boundary conditions are implied, and thus the last point in the array is not taken into account.
%\item[num\_cells:] 
%The number of cells of the grid that underlies the data array.
%\item[bc\_type:]
%Descriptor of the type of boundary condition to be imposed in the spline. Presently, one of \verb+PERIODIC_SPLINE+ or \verb+HERMITE_SPLINE+. These are really aliases to integer flags, but here we avoid the use of non-descriptive flags.
\item[spline:]
A pointer to the spline object to be filled or updated.
\end{description}

\subsection{Usage}
\subsection{Status}

\section{Collective Communications}
\subsection{Description}
Selalib applies the principle of modularization throughout all levels of abstraction of the library and aims at keeping third-party library modules as what they are: separate library modules. Therefore, in its current design, even a library like MPI has a single point of entry to Selalib. The collective communications module is such point of entry. We focus thus on the functionality offered by MPI, assign wrappers to its most desirable functionalities and write wrappers around them. These are the functions that are actually used throughout the program.  This allows to adjust the exposed interfaces, do additional error-checking and would even permit to completely change the means to parallelize a code, by being able to replace MPI in a single file if this were ever needed.
\subsection{Exposed Interface}
Fundamental type:
\begin{verbatim}
     sll_collective_t
\end{verbatim}
Constructors, destructors and access functions:
\begin{verbatim}
     sll_new_collective( parent_col )
     sll_delete_collective( col )
\end{verbatim}	
When the Selalib environment is activated, there exists, in exact analogy with \verb+MPI_COMM_WORLD+, a global named \verb+sll_world_collective+. At the beginning of a program execution, this is the only collective in existence. Further collectives can be created down the road. The above functions are responsible for the creation and destruction of such collectives. The following functions are used to access the values that a particular collective knows about.
\begin{verbatim}
     sll_get_collective_rank( col )
     sll_get_collective_size( col )
     sll_get_collective_color( col )
     sll_get_collective_comm( col )
\end{verbatim}
Since the wrapped library requires initialization, so does \verb+sll_collective+. To start and end the parallel environment, the user needs to call the functions:
\begin{verbatim}
     sll_boot_collective( )
     sll_halt_collective( )
\end{verbatim}
These functions would not be exposed at the top level, and would be hidden by a further call to something akin to \verb+boot_selalib+ and \verb+halt_selalib+.
Finally, the wrappers around the standard \verb+MPI+ capabilities are presently exposed through the following generic functions:
\begin{verbatim}
     sll_collective_bcast( col, buffer, size, root )
     sll_collective_gather( col, send_buf, send_sz, root, 
                            rec_buf )
     sll_collective_gatherv( col, send_buf, send_sz, recvcnts, 
                             displs, root, recv_buf )
     sll_collective_allgatherv( col, send_buf, send_sz, sizes, 
                                displs, rec_buf )
     sll_collective_scatter( col, send_buf, size, root, 
                             rec_buf )
     sll_collective_scatterv( col, send_buf, sizes, displs, 
                              rec_szs, root, rec_buf )
     sll_collective_all_reduce( col, send_buf, count, op, 
                                rec_buf )
\end{verbatim}
which presently stand for specialized versions that operate on specific types. For instance:
\begin{verbatim}
     sll_collective_all_to_allv_real( send_buf, 
                                      send_cnts, 
                                      send_displs, 
                                      recv_buf, 
                                      recv_cnts, 
                                      recv_displs, 
                                      col )
\end{verbatim}
\subsection{Usage}
To use the module as stand-alone, include the line:
\begin{verbatim}
     use sll_collective
\end{verbatim}
Any use of the module's functionalities must be preceeded by calling
\begin{verbatim}
     call sll_boot_collective()
\end{verbatim}
and to "turn off" the parallel capabilities, one should finish by a call to:
\begin{verbatim}
     call sll_halt_collective()
\end{verbatim}
This \emph{booting} of the parallel environment needs to be done only once in a program.

Some more specific examples are needed here...
\subsection{Status}
Several core functionalities tested, but no comprehensive unit test done yet

\section{Remapper}

\subsection{Description}
Written on top of \verb+sll_collective+, the remapper is a powerful facility that is capable of rearranging data in flexible and convenient ways in a parallel machine. It is meant to be a generalization of the `transposition', which users/developers of \emph{CALVI} team codes know and love. The main difference is is generality, as here we extend the idea to encompass something beyond a data transposition in 2D, to an operation that can be carried out in any number of dimensions. For instance, suppose that you start with a multidimensional array that has been domain decomposed and distributed among $N_p$ processors. The  layout of the data (that is, the description of what ranges of the data are contained in each processor) is specified by an instance of the type \verb+layout_XD_t+, (where \verb+X+ is the dimension of the data). The layout contains a notion of an $N_p$-sized collection of boxes, each box representing a contiguous chunk of the multidimensional array stored in each  node. If in the course of a computation, you wish to reconfigure the layout of the data (for example, if you wished to re-arrange data in a way that would permit launching serial algorithms locally in each node), then you would create and initialize a new layout descriptor with the target configuration (i.e.: you to define the box to be stored in each node). This is a conceptually simple but perhaps slightly verbose task. Then a call to the appropriate choice among:

\begin{verbatim}
     NEW_REMAPPER_PLAN_3D( initial_layout, 
                           target_layout, 
                           data_size_in_integer_sizes )
     NEW_REMAPPER_PLAN_4D( initial_layout, 
                           target_layout, 
                           data_size_in_integer_sizes )	
     NEW_REMAPPER_PLAN_5D( initial_layout, 
     	                     target_layout, 
                           data_size_in_integer_sizes )
\end{verbatim}
will yield an instance of the type \verb+remap_plan_3D_t+, or \verb+remap_plan_4D_t+ or \verb+remap_plan_5D+ , respectively, that will contain all the information necessary to actually carry out the data re-distribution. Finally, a call to 

\begin{verbatim}
     apply_remap_3D( plan, data_in, data_out )
     apply_remap_4D( plan, data_in, data_out )
     apply_remap_5D( plan, data_in, data_out )
\end{verbatim}
will actually redistribute \verb+data+ (as an out-of-place operation) according to \verb+plan+ in an optimized way\footnote{This is a very loaded comment. Some of the optimizations are carried out by the remapper, like the identification of the minimally-sized communicators to launch the exchanges, or the selection of the lower-level
communications functions (alltoall vs. alltoallv, for instance). Other optimizations would need to be triggered externally, by passing proper compilation flags to the MPI facilities. This would be problem-dependent.}. 

To appreciate the power of such facility, note that in principle, the construction of a (communications latency-limited) parallel quasi-neutral solver can be based exclusively on remapping operations. This is an important tool in any problem that would require global rearrangements of data. The remapper thus is able to present a single powerful abstraction that is general, reusable and completely hides most of the complications introduced by the data distribution. 

\begin{comment}
Each of these boxes is simply described by several pairs of limits:
\begin{verbatim}
[i_min, i_max], [j_min, j_max], [k_min, k_max], [l_min, l_max],
\end{verbatim}    
(and for a 5D case, also \verb+[m_min, m_max]+) that describe the indices of the $4D$ data contained in each processor.  
\end{comment}


\subsection{Exposed Interface}
The remapper offers the following descriptor types for parallel data layout, differing from one another only in the dimensionality of the data described:

\begin{verbatim}
     layout_3D_t
     layout_4D_t
     layout_5D_t
\end{verbatim}

(Note that for the remapper, we have forgone the use of the \verb+sll_+ prefix. This is as an example of the likely policy that the low- and mid-level reusable utilities should not be prefixed, thus being instantly available for any other development. Eventually a decision needs to be made and the choice implemented uniformly throughout the library.) These types are each accompanied by their own constructors, destructors and accessors. Specifically, the constructors are:

\begin{verbatim}
     new_layout_3D( collective )
     new_layout_4D( collective )
     new_layout_5D( collective )
\end{verbatim}

Note that each layout descriptor needs to be allocated by providing an instance of \verb+sll_collective_t+. This can be understood by thinking of the data layout as being associated with a given group of processors (the collective) and a specification of the data boxes contained in each one. After calling any of the \verb+new_layout+ functions, the returned instance becomes associated to the given collective and enough memory is allocated (size of the collective) to hold the boxes specification.

The destructors are:
\begin{verbatim}
     delete_layout_3D( layout )
     delete_layout_4D( layout )
     delete_layout_5D( layout )
\end{verbatim}

The access functions for the \verb+layout+ types are are always prefixed with the corresponding \verb+get_layout_XD+/\verb+set_layout_XD+ (where the '\verb+X+' denotes the dimensionality of the data), and they presuppose knowledge of the convention for ordering the indices as in \verb+i, j, k, l, m+, for the dimensions. Specifically, to get/set values inside the \verb+layout+ types we have available for 3D layouts:

\begin{verbatim}
     get_layout_3D_num_nodes( layout )
     get_layout_3D_box( layout, rank )
     
     get_layout_3D_i_min( layout, rank )
     get_layout_3D_i_max( layout, rank )
     get_layout_3D_j_min( layout, rank )
     get_layout_3D_j_max( layout, rank )
     get_layout_3D_k_min( layout, rank )
     get_layout_3D_k_max( layout, rank )
     
     set_layout_3D_i_min( layout, rank, val )
     set_layout_3D_i_max( layout, rank, val )
     set_layout_3D_j_min( layout, rank, val )
     set_layout_3D_j_max( layout, rank, val )
     set_layout_3D_k_min( layout, rank, val )
     set_layout_3D_k_max( layout, rank, val )
\end{verbatim}
As a very inelegant convenience, the layout type allows direct access to its collective reference.     
For 4D layouts:

\begin{verbatim}
     get_layout_4D_num_nodes( layout )
     get_layout_4D_box( layout, rank )
     
     get_layout_4D_i_min( layout, rank )
     get_layout_4D_i_max( layout, rank )
     get_layout_4D_j_min( layout, rank )
     get_layout_4D_j_max( layout, rank )
     get_layout_4D_k_min( layout, rank )
     get_layout_4D_k_max( layout, rank )
     get_layout_4D_l_min( layout, rank )
     get_layout_4D_l_max( layout, rank )
     
     set_layout_4D_i_min( layout, rank, val )
     set_layout_4D_i_max( layout, rank, val )
     set_layout_4D_j_min( layout, rank, val )
     set_layout_4D_j_max( layout, rank, val )
     set_layout_4D_k_min( layout, rank, val )
     set_layout_4D_k_max( layout, rank, val )
     set_layout_4D_l_min( layout, rank, val )
     set_layout_4D_l_max( layout, rank, val )
\end{verbatim}

And for 5D layouts:

\begin{verbatim}
     get_layout_5D_num_nodes( layout )
     get_layout_5D_box( layout, rank )
     
     get_layout_5D_i_min( layout, rank )
     get_layout_5D_i_max( layout, rank )
     get_layout_5D_j_min( layout, rank )
     get_layout_5D_j_max( layout, rank )
     get_layout_5D_k_min( layout, rank )
     get_layout_5D_k_max( layout, rank )
     get_layout_5D_l_min( layout, rank )
     get_layout_5D_l_max( layout, rank )
     get_layout_5D_m_min( layout, rank )
     get_layout_5D_m_max( layout, rank )
          
     set_layout_5D_i_min( layout, rank, val )
     set_layout_5D_i_max( layout, rank, val )
     set_layout_5D_j_min( layout, rank, val )
     set_layout_5D_j_max( layout, rank, val )
     set_layout_5D_k_min( layout, rank, val )
     set_layout_5D_k_max( layout, rank, val )
     set_layout_5D_l_min( layout, rank, val )
     set_layout_5D_l_max( layout, rank, val )
     set_layout_5D_m_min( layout, rank, val )
     set_layout_5D_m_max( layout, rank, val )
\end{verbatim}

The above functions define the interface that will allow you to declare and initialize the \verb+layout+ types as desired. This is where the work lies when using this module. Note that all the above functions could be coalesced into a set of functions of the type \verb+set_layout_X_XXX(layout, rank, val)+ if we choose to hide all the above functions behind a generic interface. The selection would be done automatically depending on the type of layout passed as an argument. 

The type \verb+remap_plan+ exists also in multiple flavors, depending on the dimensionality of the data to be remapped:

\begin{verbatim}
     remap_plan_3D_t
     remap_plan_4D_t
     remap_plan_5D_t
\end{verbatim}

The \verb+remap_plan_t+ type stores the locations of the memory buffers that will be involved in the communications, the specification of the data that will be sent and received, as well as the collective within which the communications will take place. There are, however, declaration functions available. The choice depends on the dimensionality of the data:

\begin{verbatim}
     NEW_REMAPPER_PLAN_3D( initial_layout, 
                           final_layout, 
                           array_name )
     NEW_REMAPPER_PLAN_4D( initial_layout, 
                           final_layout, 
                           array_name )
     NEW_REMAPPER_PLAN_5D( initial_layout, 
                           final_layout, 
                           array_name )
\end{verbatim}

Finally, the way to execute the plan on a particular data set is through a call of the appropriate subroutine (here presented as generic interfaces)

\begin{verbatim}
     apply_remap_3D( plan, data_in, data_out )
     apply_remap_4D( plan, data_in, data_out )
     apply_remap_5D( plan, data_in, data_out )
\end{verbatim}

\subsection{Usage}
For use in stand-alone way, use the line:
\begin{verbatim}
#include "sll_remap.h"
\end{verbatim}
While verbose, the best way to demonstrate the usage of the remapper is with a complete program. Below it, we examine the different statements.

\begin{verbatim}
1   program remap_test
2     use sll_collective
3   #include "sll_remap.h"
4   #include "sll_memory.h"
5   #include "sll_working_precision.h"
6   #include "misc_utils.h"
7     implicit none
8
9     ! Test of the 3D remapper takes a 3D array whose global 
10    ! size Nx*Ny*Nz, distributed among pi*pj*pk processors.
11    integer, dimension(:,:,:), allocatable :: a3
12    integer, dimension(:,:,:), allocatable :: b3
13 
14    ! Take a 3D array of dimensions 8X8X1
15    integer, parameter                 :: total_sz_i = 8
16    integer, parameter                 :: total_sz_j = 8
17    integer, parameter                 :: total_sz_k = 1
18  
19    ! the process mesh
20    integer, parameter                 :: pi = 4
21    integer, parameter                 :: pj = 4
22    integer, parameter                 :: pk = 1
23
24    ! Split into 16 processes, each with a local chunk 2X2X1
25    integer                            :: local_sz_i 
26    integer                            :: local_sz_j 
27    integer                            :: local_sz_k 
28    integer                            :: ierr
29    integer                            :: myrank
30    integer                            :: colsz  
31    integer                            :: i,j,k
32    integer                            :: i_min, i_max
33    integer                            :: j_min, j_max
34    integer                            :: k_min, k_max
35    integer                            :: node
36    integer, dimension(1:3)            :: gcoords
37  
38    ! Remap variables
39    type(layout_3D_t), pointer         :: conf3_init
40    type(layout_3D_t), pointer         :: conf3_final
41    type(remap_plan_3D_t), pointer     :: rmp3
42
43    ! Boot parallel layer
44    call sll_boot_collective()
45
46    ! Initialize and allocate the variables.
47    local_sz_i = total_sz_i/pi
48    local_sz_j = total_sz_j/pj
49    local_sz_k = total_sz_k/pk
50    SLL_ALLOCATE(a3(1:local_sz_i,1:local_sz_j,1:local_sz_k), ierr)
51    SLL_ALLOCATE(b3(1:local_sz_i,1:local_sz_j,1:local_sz_k), ierr)
52    myrank    = sll_get_collective_rank(sll_world_collective)
53    colsz     = sll_get_collective_size(sll_world_collective)
54
55    conf3_init     => new_layout_3D( sll_world_collective )
56    conf3_final    => new_layout_3D( sll_world_collective )
57    random_layout1 => new_layout_3D( sll_world_collective )
58
59    ! Initialize the layout
60    do k=0, pk-1
61       do j=0, pj-1
62          do i=0, pi-1
63             node = i+pi*(j+pj*k) ! linear index of node
64             i_min = i*local_sz_i + 1
65             i_max = i*local_sz_i + local_sz_i
66             j_min = j*local_sz_j + 1
67             j_max = j*local_sz_j + local_sz_j
68             k_min = k*local_sz_k + 1
69             k_max = k*local_sz_k + local_sz_k
70             call set_layout_i_min( conf3_init, node, i_min )
71             call set_layout_i_max( conf3_init, node, i_max )
72             call set_layout_j_min( conf3_init, node, j_min )
73             call set_layout_j_max( conf3_init, node, j_max )
74             call set_layout_k_min( conf3_init, node, k_min )
75             call set_layout_k_max( conf3_init, node, k_max )
76          end do
77       end do
78    end do
79      
80    ! Initialize the data using layout information.
81    do k=1, local_sz_k
82       do j=1, local_sz_j
83          do i=1, local_sz_i
84             gcoords= local_to_global_3D(conf3_init,(/i,j,k/))
85             a3(i,j,k) = gcoords(1) + &
86                  total_sz_i*((gcoords(2)-1) + &
87                  total_sz_j*(gcoords(3)-1))
88          end do
89       end do
90    end do
91
92    ! Initialize the final layout, in this case, just a 
93    ! transposition
94    do k=0, pk-1
95       do j=0, pj-1
96          do i=0, pi-1
97             node = i+pi*(j+pj*k) ! linear index of node
98             i_min = i*local_sz_i + 1
99             i_max = i*local_sz_i + local_sz_i
100            j_min = j*local_sz_j + 1
101            j_max = j*local_sz_j + local_sz_j
102            k_min = k*local_sz_k + 1
103            k_max = k*local_sz_k + local_sz_k
104            call set_layout_i_min( conf3_final, node, j_min )
105            call set_layout_i_max( conf3_final, node, j_max )
106            call set_layout_j_min( conf3_final, node, i_min )
107            call set_layout_j_max( conf3_final, node, i_max )
108            call set_layout_k_min( conf3_final, node, k_min )
109            call set_layout_k_max( conf3_final, node, k_max )
110         end do
111      end do
112   end do
113  
114   rmp3 => NEW_REMAPPER_PLAN_3D( conf3_init, conf3_final, a3 )
115   call apply_remap_3D( rmp3, a3, b3 )
116
117   ! At this moment, b3 contains the expected output
118   ! from the remap operation.
119  
120   ! Delete the layouts  
121   call delete_layout_3D( conf3_init )
122   call delete_layout_3D( conf3_final )
123
124    call sll_halt_collective()
125 
126  end program remap_test

\end{verbatim}

\begin{description}
\item[Lines 1 - 5:]
Required preamble at the time of this writing. Eventually this will be replaced by a single statement to include the whole library. Presently, we include various headers individually, so bear in mind that this is not the way this will end up being. Line 3 specifically loads the remapper facility. Here it is brought as a header file as the NEW\_REMAPPER\_PLAN\_XD() is implemented as a macro.


\item[Lines 9 - 12: ]
For this example we allocate two 3D arrays for the input and output of the remap operation.

\item[Lines 14 - 22: ]
Definition of the array size from a global perspective. In other words, the array to be remapped is a $8*8*1$ array, to be distributed on a processor mesh of dimensions $4*4*1$. 

\item[Lines 24 - 36]
Miscellaneous integer variables that we will use.

\item[Lines 38 - 41]
Pointers to the initial and final layouts and the remap plan.

\item[Line 44]
Presently we boot from collective. Eventually this will be replaced by a call to something like \verb+boot_selalib()+ or something similar, where we declare and initialize anything we need in a single call.

\item[Lines 46 - 57]
Initialization of the variables.

\item[Lines 59 - 78]
This is where the actual work is when using the remapper. We need to initialize a layout, in this case the initial configuration. We use the access functions \verb+set_layout_x_xxx( )+ to populate the fields. Here we obviously take into account the geometry of our `process mesh' to find out the rank of the process that we are initializing.

\item[Lines 80 - 90]
We need to initialize the data, here we choose simply to assign the index of the array, considered as a 1D array. Note the use of the helper function \verb+local_to_global_3D( layout, triplet )+. We exploit the knowledge of the global layout of the data to find out the global indices of a local 3-tuple.

\item[Lines 92 - 112]
The other main part of the work, the initialization of the target layout. In this case, we chose a simple transposition, which is achieved by switching \verb+i+ and \verb+j+.

\item[Lines 114 - 115]
Here we allocate and initialize the remap plan, using the initial and final configurations as input. The third argument is passed to inform the remapper of the type of data to be passed. The call to \verb+apply_remap_3D()+ is a call to a generic function, hence, a type-dependent sub-function must have been defined to be able to successfully make this call. At the time of this writing, only single precision integers and double precision floats have been implemented. 

\item[Line 116]
Here we apply the plan. This function is type-dependent due to the input/output arrays. Please refer to the implementation notes for some commentary on our options with this interface.

\item[Lines 122 - 125]
Cleanup. The layouts need to be deleted to prevent memory leaks. 

\end{description}

\subsection{Implementation Notes}
The biggest challenge with the remapper is to attain a desired level of genericity and to preserve the modularity of the library. These two problems are intimately related. Ideally, we should be able to apply a remap operation on data of any type, including user-derived types. Another requirement has been to confine a library like MPI to a single entry point into Selalib. This means that we do not want the MPI derived types to pollute the higher abstraction levels of the library: especially at the top level, we want to express our programs with the capabilities of the Fortran language alone.

These requirements were solved in the prototype version of the remapper through the use of a single datatype to represent all other types of data at the moment of assembling the exchange buffers and launching the MPI calls. In our case, we have chosen to represent all data as `integers'. This means that the exchange buffers that are stored in the remap plans are integer arrays. Thus, the design decision in the prototype has been to choose flexibility and ease of change over execution speed. In contrast with the C language, the constant call to the \verb+transfer()+ function to store and retrieve data from the exchange buffers carries with it a possibly significant execution time penalty.

The function \verb+NEW_REMAPPER_PLAN_XD()+ is by nature type-independent, as the design of the plan only depends on the layouts. However, it is also convenient to store the send/receive buffers in the plan, and the allocation of these buffers requires knowledge of the amount of memory required. This information is passed in the third argument. The macro will internally select an element of this array and determine its size in terms of the fundamental datatype being exchanged (i.e.: \verb+integer+). This way we now how much memory to allocate in the buffers.

Another means to achieve the illusion of genericity are Fortran's built-in features in this regard. For example, we can have specialized \verb+apply_remap_3D()+ functions for the most commonly used datatypes, all hidden behind the same generic name. These specialized functions would not depend on the current choice of using a single type for the exchange buffers, eliminating any penalty that we are definitively paying at present, with the calls to the \verb+transfer()+ intrinsic function. This solution would mean writing redundant code, something that could be addressed with preprocessor macros, but this would not be a solution for eliminating the penalizations of the \verb+transfer()+ intrinsic when we are exchanging derived types. A solution that can exchange these arbitrary data while not requiring the use of the MPI derived types at the higher levels is yet to be found. It could be that the Fortran way to solve this problem would be to accept the invasion of MPI at the higher levels...

\subsection{Status}

In testing.

\chapter{Top-Level Layer: Semi-Lagrangian Toolbox}










\section{Meshes}
\subsection{Description}
The mesh types aim at storing array data, but including additional information needed to put this data in context. There are several types of meshes:
\begin{description}
\item[cartesian mesh]: an N-D fully regular mesh defined by an N-D data array and additional parameters that define the domain (i.e.: xmin, xmax) and other parameters like the number of cells in each dimension and the spacing of the data (i.e.: delta). The services provided should be like (with corresponding name changes, indicating the dimensionality of the data):
\begin{itemize}
\item allocation(new) and initialization functions,
\item deletion,
\item a copy constructor,
\item computation of data interpolants (cubic splines for example),
\item \verb+get_value(mesh,x1,x2,...)+: where \verb+x1+, \verb+x2+,... belong to the corresponding interval \verb+(x1_min, x1_max)+, \verb+(x2_min, x2_max)+, etc., and which returns the interpolated value at the desired point. This operation launches spline interpolations under the hood.
\item \verb+get_node_value(mesh,i,j,...)+: analogous to \verb+get_value()+ but does not need to launch any interpolation as the indices are integers and the requested value falls on a mesh node. This is implemented by a macro.
\item \verb+set_node_value(mesh,i,j,...,val)+: sets the node datum at i,j,... with value. Implemented with a macro.
\end{itemize}
\end{description}
There are some pitfalls with the suggested interface:
\begin{itemize}
\item the naming convention could get a little complicated depending on the type of data stored in the array (scalar, multiple-valued, etc.), as we had originally intended with the field/vec naming convention.
\item The interface may need to directly expose its underlying data, or pointers to sections of it for certain operations, like FFT. The whole data field of a mesh could need to be set to a whole data array in one step, during the initialization, such as after a remap operation. At least in these cases, the access to the data might be safer given the nature of the operations.
\end{itemize}

\begin{description}
\item[structured mesh]: a structured mesh is a mapped cartesian mesh in which the coordinates are decoupled. An ND mesh data is stored as an ND array. In addition, however, we need N 1D arrays to store the actual coordinates of the node locations in each dimension. As an alternative, we could use N functions $x_1=f(\eta_1)$, $x_2=f(\eta_2)$, ... , $x_n=f(\eta_n)$, to represent each transformation. We follow the convention that $\eta_1$, $\eta_2$, etc.  are values in the $[0,1]$. The offered services ought to be:

\begin{itemize}
\item allocation, initialization, deletion and copy.
\item \verb+get_node_value(mesh, i, j, ... )+: which reads directly from the data array.
\item \verb+set_node_value(mesh, i, j, ... )+: which writes directly to the data array.
\item In an analogous way to the \verb+get_value()+ functions described above, we could provide something like \verb+get_value(mesh,+ $\eta_1$\verb+, +$\eta_2$\verb+)+. This would also trigger an interpolation step using uniform splines generated with the ND data. This would require the user to be \emph{thinking} in terms of the logical variables $\eta_i$. 
\item Similar functions could be provided such that the user could also request values at points $x_i$. For this, we could launch non-uniform splines, with the spacing determined by the $x_i$ arrays and the ND data.
\item This type may also need to grant direct access to the data array for use in operations like FFT and similar.
\end{itemize}

\item[tensor product mesh]: This is a mapped cartesian mesh in which the coordinates are coupled. That is, the mappings have the form: $x_1=f(\eta_1, \eta_2, ..., \eta_n)$, $x_2=f(\eta_1,\eta_2, ..., \eta_n)$, ... , $x_n=f(\eta_1,\eta_2, ..., \eta_n)$. The specification of this type of mesh requires an ND data array, N ND arrays that specify the transformations numerically, or N functions of arity N to specify the transformations. The services provided should be:
\begin{itemize}
\item allocation, initialization, deletion and copy.
\item \verb+get_node_value(mesh, i, j, ... )+: which reads directly from the data array.
\item \verb+set_node_value(mesh, i, j, ... )+: which writes directly to the data array.
\item \verb+get_value(mesh,+ $\eta_1$\verb+, +$\eta_2$\verb+, ... )+ which would also trigger uniform spline interpolations, and
\item \verb+get_value(mesh, x1, x2, ... )+, which would trigger nonuniform spline interpolations.
\end{itemize}
We may need to include other operations here which would entail inverse mappings (maybe also with splines), or NURBS or something else. Need to fill in the details more here.
\end{description}


\subsection{Exposed Interface}

\subsection{Usage}

\subsection{Status}



\section{Scalar Fields}
\subsection{Description}
The physical quantities of interest are normally defined in a physical space. For instance, the electric potential $\phi(\vec{x})$ is specified by a function on the $\vec{x}$ variables ($x,y,z$). Even in simple problems the borders of the physical domain may have relatively complicated shapes which make the solution of differential equations more difficult. Great flexibility (possibly at the expense of efficiency) can be gained by transferring the data from the physical space to a representation in a logical space in which the underlying grid that we use for the numerical solution is always uniform. In such uniform grid, the borders have a much simpler (straight line) representation that may aid the solution of the equations. This means that it is convenient to permit the alternative representation of the data on variables on a physical space ($\vec{x}$) or on a logical space ($\vec{\eta}$). For these reasons, the scalar field should be thought of data plus a coordinate transformation. 

(place picture of an example coordinate transformation here.)

Consider a scalar field and the services that it should offer to permit us to use it in our logical grid:
\begin{enumerate}
  \item The scalar field is a derived type.
  \item The type contains a simple array to store the data, i.e.: the values of the fields on a collection of points. Both, logical mesh values or physical mesh values can be stored in the same array.
  \item The type contains an object that fully specifies the associated coordinate transformation (a mapped mesh). The transformation should provide all the needed services to permit moving the representation of the data from the physical space to the logical space and vice-versa:
  \begin{enumerate}
     \item something
     \item something else
   \end{enumerate}
\end{enumerate}





\section{Quasi-Neutral Equation Solver}
\subsection{Description}
Here we present a simplified but hopefully reasonably clear step-by-step derivation of the quasi-neutral equation (the gyrokinetic Poisson equation) which this module solves. The intent is to make clear some of the assumptions that are built into this model. We follow the general argument given by Krommes (cite reference here for "Nonlinear gyrokinetics: a powerful tool for the description of microturbulence in magnetized plasmas").

The model is based on the idea that the fast gyrations of particles around the magnetic field lines can be averaged away while still preserving the most important long-term physics (hence the name of this type of approach: gyrokinetics). The simplest model that we will look into first deals directly in the distribution function of the gyrocenters, instead of the particles'. 

We start with the Poisson equation:

\begin{equation}
-\nabla ^2 \phi = \frac{1}{\epsilon_0}\rho,
\end{equation}
where $\phi$ is the electric potential, $\rho$ is the volumetric charge density and $\epsilon_0$ is the permittivity of free space. The main assumptions built into the model are introduced through the treatment of $\rho$. We decompose the charge density in its two main constituents: the contribution by the ions ($\rho_i$) and the electrons' ($\rho_e$). As mentioned earlier, the main idea behind gyrokinetics is the averaging of the fast particle motions around the field lines, hence some of the effects that occur on longer time-scales are explicitly introduced into the model, for example by particle drifts (e.g.: $\vec{E}\times\vec{B}$, polarization drift, etc.). In doing so, we allow ourselves to further separate the charge density into a polarization charge and a charge at the particles' gyrocenters (gyrocenters do not polarize). Thus, Poisson's equation becomes

\begin{equation} \label{eq:poisson_2}
-\nabla ^2 \phi = \frac{1}{\epsilon_0}(\rho^G_i + \rho^{pol}_i - \rho^G_e - \rho^{pol}_e),
\end{equation}
where the indices $G$, $pol$, $i$ and $e$ indicate \emph{gyrocenters}, \emph{polarization}, \emph{ions} and \emph{electrons} respectively. The polarization drift velocity, whose derivation can be found in introductory plasma physics texts is given by

\begin{equation}
\vec{v}^{pol} = \pm \frac{1}{\omega_{ci}B}\frac{\partial \vec{E}_{\perp}}{\partial t}.
\end{equation}
Here $\omega_{ci}$ is the ion cyclotron frequency, $B$ is the magnitude of the local magnetic field and $\vec{E}_{\perp}$ is the electric field perpendicular to the magnetic field. The plus/minus sign in the equation applies to positive and negative particles respectively. Heuristically, the polarization charge obeys a continuity equation:

\begin{equation} \label{eq:rho_pol_continuity}
\frac{\partial \rho^{pol} }{\partial t} = - \nabla \cdot \vec{j}^{pol} = - \nabla \cdot (nZe \vec{v}^{pol})=- \nabla \cdot \bigg( n Ze \frac{1}{\omega_{ci}B}\frac{\partial \vec{E}_{\perp}}{\partial t}\bigg) .
\end{equation}

Here, $Z$ is the charge state of the ions under consideration (obviously 1 for a hydrogen-burning fusion plasma), $e$ is the electron charge and $n$ is the particle density per unit volume. As long as none of the factors of the time derivative depends itself on time, we can integrate immediately and arrive at an expression for $\rho^{pol}$:

\begin{equation} \label{eq:rho_pol}
\rho^{pol}(\vec{x}) = \nabla \cdot \bigg( \frac{n_i(\vec{x})Ze}{\omega_{ci}(\vec{x}) B(\vec{x}) }\nabla_{\perp}\phi(\vec{x},t) \bigg).
\end{equation}

Here we have introduced the assumption of $n_i$, the ion particle density,  being independent of time. In equation (\ref{eq:rho_pol}), we can consider that the differential operators act only in the directions perpendicular to the magnetic field, as these are the only terms that will survive the taking of the divergence. Finally, by multiplying by the proper unit factors and using the relation

\begin{equation}
\omega_p = \bigg( \frac{ne^2} {\epsilon_0 m} \bigg)^{\frac{1}{2}}
\end{equation}
we can recast equation (\ref{eq:rho_pol}) into

\begin{equation} \label{eq:rho_pol_epsilon}
\rho^{pol}(\vec{x}) = \epsilon_0 \nabla_{\perp} \cdot \big( \varepsilon^G(\vec{x})\nabla_{\perp}\phi(\vec{x},t) \big).
\end{equation}
where 

\begin{equation}
\varepsilon^G(\vec{x}) \equiv \frac{\omega^2_{pi}(\vec{x})}{\omega^2_{ci}(\vec{x})}
\end{equation}
is called the \emph{dielectric constant of the gyrokinetic vacuum}. With equation (\ref{eq:rho_pol_epsilon}), and neglecting the polarization of the electrons, the modified Poisson equation (\ref{eq:poisson_2}) can be written as:

\begin{equation}
-\nabla ^2 \phi(\vec{x},t) - \nabla_{\perp} \cdot \big(\varepsilon ^G(\vec{x},t)\nabla_{\perp} \phi(\vec{x},t) \big) = \frac{1}{\epsilon_0}(\rho^G_i - \rho^G_e).
\end{equation}
In fusion applications, $\varepsilon^G >> 1$ thus we neglect the ordinary laplacian term on the left-hand side. 

The charge density of the electrons also receives a special treatment. The basic assumption here is that the electrons can move very quickly along a magnetic field line and thus are able to rapidly react to electric potential variations through changes in the electron particle density. Thus, it is assumed that along a field line, the electrons obey the Boltzmann relation:

\begin{equation}  \label{eq:boltzmann}
n_e(\vec{x},t) = \bar{n}_e(\vec{x},0) \exp \bigg(\frac{e}{k_BT_e}(\phi(\vec{x},t) - <\phi(\vec{x},t)>_{\ell})\bigg).
\end{equation}
In equation (\ref{eq:boltzmann}), $n_e(\vec{x},t)$ is the instantaneous electron particle density, $\bar{n}_e(\vec{x})$ is the average electron density along the magnetic field line, $k_B$ is Boltzmann's constant, $T_e$ is the electron temperature and the $< \cdot >_{\ell}$ average is taken along the magnetic field line. By making yet another assumption of very small deviations from the average electric potential, the previous equation can be linearized:

\begin{equation}  \label{eq:boltzmann_linear}
n_e(\vec{x},t) = \bar{n}_e(\vec{x},0) \bigg(1+\frac{e}{k_BT_e}(\phi(\vec{x},t) - <\phi(\vec{x},t)>_{\ell})\bigg).
\end{equation}
At the risk of being too sloppy, we will equate the electron particle density with the electron gyrocenter density. A more careful step would involve gyroaveraging directly the original electron distribution function. With this assumption, our modified poisson becomes:

\begin{equation}
- \nabla_{\perp} \cdot \big(\varepsilon ^G(\vec{x},t)\nabla_{\perp} \phi(\vec{x},t) \big) = \frac{1}{\epsilon_0}\bigg(\rho^G_i - \bar{\rho}_{e0}^G\Big(1+\frac{e}{k_BT_e}(\phi(\vec{x},t) - <\phi(\vec{x},t)>_{\ell})\Big)\bigg).
\end{equation}
Rearranging terms and using the relation:
\begin{equation} \label{eq:debye_length}
\lambda_D=\bigg(\frac{\epsilon_0k_BT_e}{ne^2}\bigg)^\frac{1}{2}=\bigg(\frac{\epsilon_0k_BT_e}{\rho e}\bigg)^\frac{1}{2},
\end{equation}
we arrive at:
\begin{equation} \label{eq:gk_poisson}
- \nabla_{\perp} \cdot \big(\varepsilon ^G(\vec{x},t)\nabla_{\perp} \phi(\vec{x},t) \big)+\frac{1}{\bar{\lambda}_{D0}} (\phi(\vec{x},t) - <\phi(\vec{x},t)>_{\ell})= \frac{1}{\epsilon_0}\Big(\rho^G_i - \bar{\rho}_{e0}^G\Big).
\end{equation}
But for a normalization of the variables, equation (\ref{eq:gk_poisson}) is virtually the same as the one stated in the report by Latu (list here reference for "Scalable Quasineutral solver for gyrokinetic simultion"). Equation (\ref{eq:gk_poisson}) is not yet ready to solve due to the presence of the $<\phi(\vec{x},t)>$ term. We need to average the solution we seek, after all. To obtain an additional equation that will help us find this term, we take the average of both sides of the equation in the same sense that we have been averaging before: along a magnetic field line (note that in practice, due to ergodicity, this line may extend and fill a surface or even worse.) The barred quantities have already been averaged so we can get them out of the averaging operator when necessary. Averages of averages remain unchanged and thus we arrive at:

\begin{equation} \label{eq:gk_poisson_aux}
- \nabla_{\perp} \cdot \big(<\varepsilon ^G(\vec{x},t)\nabla_{\perp} \phi(\vec{x},t)>_{\ell} \big)= \frac{1}{\epsilon_0}(<\rho^G_i>_{\ell} - <\bar{\rho}_{e0}^G>_{\ell}).
\end{equation}
By making two final assumptions: that the quantities involved in the calculation of $\varepsilon^G(\vec{x},t)$ are not time-dependent but given by the initial ion distribution, and that this quantity does not vary along the domain of the average procedure (the magnetic field line), we can extract $\varepsilon^G(\vec{x},t)$ from the average operator, yielding the auxiliary equation that we need to compute $<\phi(\vec{x},t)>_{\ell}$:

\begin{equation} \label{eq:gk_poisson_aux}
- \nabla_{\perp} \cdot \big(\varepsilon ^G\nabla_{\perp} <\phi(\vec{x},t)>_{\ell} \big)= \frac{1}{\epsilon_0}(<\rho^G_i>_{\ell} - <\bar{\rho}_{e0}^G>_{\ell}).
\end{equation}
The average ion charge density can be computed from $\rho^G_i(\vec{x},t)$ which is input data for the solver. To compute the average of the electron density we need to explicitly invoke the initial quasineutrality condition, i.e.: $\rho_i = \rho_e$. With this, $<\bar{\rho}^G_{e0}>_{\ell} = <\bar{\rho}^G_{i0}>_{\ell}$ and we are able to compute all the quantities involved based on the initial ion distribution profile.

Once we calculate $<\phi(\vec{x},t)>_{\ell}$ with equation (\ref{eq:gk_poisson_aux}) we can use this to solve the final version of our quasineutral equation, after introducing all the assumptions:

\begin{equation} \label{eq:gk_poisson_final}
- \nabla_{\perp} \cdot \big(\bar{\varepsilon}^G(\vec{x},0)\nabla_{\perp} \phi(\vec{x},t) \big)+\frac{1}{\bar{\lambda}_D} (\phi(\vec{x},t) - <\phi(\vec{x},t)>_{\ell})= \frac{1}{\epsilon_0}(\rho^G_i - \bar{\rho}_{i0}^G).
\end{equation}


 
\subsection{Exposed Interface}
Fundamental type: None. It is a function that operates on other top-level types. Function:
\begin{verbatim}
     sll_solve_quasi_neutral_equation( electron_T_profile_2D,
                                       initial_rho_ion_profile_2D,
                                       charge_density,
                                       phi )
\end{verbatim}
\subsection{Usage}
\subsection{Status}


\section{Particle Distribution Function}
\subsection{Description}
\subsection{Exposed Interface}
Fundamental type:
\begin{verbatim}
     sll_distribution_function_t
\end{verbatim}
All the fundamental types in the library are implemented as pointers. This choice has been made to ease the addition of Python bindings, in case that an even higher-level interface is desired some day.

Constructor and destructor:
\begin{verbatim}
     sll_new_distribution_function( nr, ntheta, nphi, nvpar, mu )
     sll_delete_distribution_function( f )
\end{verbatim}
The constructor essentially limits itself to allocating the memory for the type. An initialization step is required afterwards:
\begin{verbatim}
     sll_initialize_df( boundary_type_r, 
                        boundary_type_vpar, 
                        species_charge )
\end{verbatim}
The accessors that get/set a particular value of a distribution function on a node are defined as macros to be able to keep a single interface while not risking a penalization when used in critical loops. Other queries on this type are implemented as ordinary functions. (Need to define this better, for instance, if some query functions would operate on integer arguments and/or real coordinates.)
\begin{verbatim}
     SLL_GET_DF_VAL( i, j, k, l, df )
     SLL_SET_DF_VAL( val, i, j, k, l, df )
     sll_interpolate_df( r, theta, phi, vpar, mu )
     sll_compute_derivative( f, r, theta, phi, vpar, mu )
     sll_get_df_nr( df )
     sll_get_df_nphi( df )
     sll_get_df_ntheta( df )
     sll_get_df_nvpar( df )
     sll_get_df_mu( df )
\end{verbatim}
The type also offers the services:
\begin{verbatim}
     sll_compute_moments( df, ... )
\end{verbatim}

\subsection{Usage}
\subsection{Status}

\section{Advection Field}
\subsection{Description}
\subsection{Exposed Interface}
Fundamental type:
\begin{verbatim}
     sll_advection_field_3D_t
\end{verbatim}
This implies that one of the options is to have multiple representations, for 3D, 2D, 1D. 
\subsection{Usage}
\subsection{Status}

\section{Advection}
\subsection{Description}
\subsection{Exposed Interface}
Fundamental type: None. This is a function that operates on multiple top-level types. Function:
\begin{verbatim}
     sll_advect( distribution_function, 
     	           advection_field, 
                 dt, 
                 space_mesh
                 scheme )
\end{verbatim}
Above, \verb+scheme+ is the functional parametrization of the various methods in use (PSM, BSL, ...) and for which we need a standardized interface. The above assumes that we can devise a standard functional interface.
\subsection{Usage}
\subsection{Status}

\begin{comment}

\begin{thebibliography}{9}
  % type bibliography here
\end{thebibliography}


\end{comment}

\end{document}